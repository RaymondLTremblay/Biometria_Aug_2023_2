[["index.html", "Biometria Chapter 1 Introducción al curso de Biometría 1.1 Libro obligatorio:", " Biometria 2023-08-30 Chapter 1 Introducción al curso de Biometría Instructor: Raymond L. Tremblay, PhD Oficina: NL 104 Teléfono: (787) 850-9497 (dept de biología) Coreo electronico: raymond.tremblay_at_upr_dot_edu 1.0.1 Horario de clase Presentación de temas y discusion: M, J at 9:00-10:50am (80 mins) (NOTE: Necesita traer su laptop!) Hora de consulta con Estudiantes: L &amp; W 1:00 - 4:00pm 1.1 Libro obligatorio: Aquí dos sitios donde pueden conseguir el libro Havel et al - Introductory Biological Statistics, 4 edition Havel et al - Introductory Biological Statistics, 4 edition 1.1.1 Libros sugeridos Garrett Grolemund, Hadley Wickham. R for Data Science En Ingles. Garrett Grolemund, Hadley Wickham. R para Ciencia de Datos En Español. Tremblay y Hernández-Serrano, 2018. • Artículos revisados por pares serán asignados para fomentar el método de utilizar estas herramientas en ciencias. 1.1.2 Programados R- free statistical programming language RStudio MSExcel, Numbers o Google Sheet 1.1.3 Prerequisitos BIOL 3011-3013: Biología General y Laboratorio primer semestre BIOL 3012-3014: Biología General y Laboratorio segundo semestre 1.1.4 Descripción del curso Estudio de diferentes técnicas estadísticas con aplicación a la Biología. Se enfatizará en la estadística descriptiva, análisis de regresiones y correlaciones, pruebas de hipótesis paramétricas y no paramétricas y análisis de frecuencias y varianza. Se hará énfasis en los supuestos de las pruebas, para seleccionar cual método estadístico es adecuado para el diseño experimental y la distribución de los datos. Además, se utilizarán las computadoras como mecanismos para facilitar y agilizar el cómputo y análisis estadístico. 1.1.5 Objetivos del curso Al finalizar el curso el estudiante podrá: Discutir la importancia de la estadística en los estudios biológicos. Ordenar datos biológicos en forma lógica. Diferenciar entre los diferentes tipos de datos biológicos. Diferenciar los diferentes tipos de escalas biológicas. Organizar y resumir datos en forma de tablas. Confeccionar polígonos de frecuencia. Creación de gráficas para demostrar patrones. Hacer uso adecuado de las diferentes estadísticas descriptivas. Describir las diferentes medidas de tendencia central. Basado en las medidas de tendencia central, inferir algunas de las características de la muestra bajo estudio. Determinar cuándo se deben calcular en forma grupal las medidas de tendencia central y dispersión de la muestra. Calcular probabilidades en situaciones específicas. Establecer la diferencia entre distribuciones discretas y continuas. Formular una hipótesis nula y alterna, adecuada para una situación en particular. Distinguir de acuerdo al tipo de datos recolectados cuándo utilizar pruebas paramétricas o pruebas no paramétricas. Evaluar los supuestos de las pruebas, tal como distribución normal e igualdad de varianza Evaluar la hipótesis nula y determinar el grado de significación de esta hipótesis haciendo uso de los diferentes análisis estadísticos. Confeccionar tablas de contingencia y establecer homogeneidad. Determinar cuándo se debe utilizar un análisis de regresión. Calcular coeficientes de regresión. Determinar intervalos de confianza y significación de una regresión. Calcular el coeficiente de correlación. Realizar comparaciones entre coeficientes de correlación simples. Desarrollar y analizar diseños experimentales utilizando técnicas de muestreo y recolección de datos apropiados. Determinar el error de muestra. Conocer y aplicar las pruebas básicas en estadísticas. Evaluar situaciones experimentales y poder desarrollar un diseño experimental adecuado y lógico para analizar el problema y llegar a conclusiones. Se hará énfasis en el uso de programados estadísticos para calcular los índices y probar hipótesis. Los programa de computadora puede incluir R. 1.1.6 Puntuacion: Este curso sera evaluado con los siguiente items: Item Valor Ejercicios práctico (4-6 total) 30% Pruebas cortas (una por semana) 15% Participación 10% Examen parcial # 1 (fecha TBD) 15% Examen parcial # 2 (fecha TBD) 15% Examen Final (fecha TBD) 10% NOTE: Escala de Notas: A (100 to 90) B (89 to 80) C (79 to 70) D (69 to 60) F (&lt; 60) 1.1.7 Examenes: Habrá dos examen parciales y un examen final comprensivo. Estos exámenes serán de selecciones múltiples, pareo, respuesta corta, y análisis de conceptos. El examen final será comprensivo (incluye todos los temas del semestre). En este examen final se hará énfasis en la comprensión y aplicaciones de los supuestos de las pruebas y la capacidad de seleccionar la prueba correcta basado en el diseño experimental y los supuestos. Si el examen es vitrual es obligatorio tener la camera prendida durante todo el exámen. No es permitido usar el celular, Ud. tendrá que demostrar que el celular este detrás de uds antes de comenzar el examen 1.1.8 Conferencias En la clase las notas serán basado primeramente en la participación y algunas pruebas cortas. Su participación es esencial para el aprendizaje (y para un ambiente positivo). Aprender NO es un proceso pasivo: los estudiantes deben participar haciendo preguntas y discutir el material con su conocimiento anterior (Su bagaje de conocimiento). 1.1.9 Ejercicios Los ejercicios están enfocado en la aplicación de conceptos y métodos discutido en la clase y solución de problemas. Se hará un esfuerza de usar datos reales para demostrar como trabajar con los análisis, tablas, y gráficos en R, RStudio y RMarkdown. Típicamente, tendrán solamente una semana para hacer los ejercicios y entregarlos en formato .html. 1.1.10 Faltar a clase y examen: Los trabajos cortos y pruebas cortas NO se reponen. Si falta a la clase es su responsabilidad hablar con los otros estudiantes para saber lo que se discutió en la clase. Los examen se reponen solamente por una escusa valida. 1.1.11 Derechos de Estudiantes con Impedimentos La UPR-Humacao cumple con las leyes ADA (Americans with Disabilities Act) y 51 (Servicios Educativos Integrales para Personas con Impedimentos) para garantizar igualdad en el acceso a la educación y servicios. Estudiantes con impedimentos: informe al (la) profesor(a) de cada curso sobre sus necesidades especiales y/o de acomodo razonable para el curso, en la tarjeta de información de la primera semana y visite la Oficina de Servicios para la Población con Impedimentos (SERPI) a la brevedad posible. Se mantendrá la confidencialidad. 1.1.12 Integridad academica La Universidad de Puerto Rico promueve los más altos estándares de integridad académica y científica. El Artículo 6.2 del Reglamento General de Estudiantes de la Universidad de Puerto Rico (Certificación Núm. 13, 2009-2010, de la Junta de Síndicos) establece que la deshonestidad académica incluye, pero no se limita a: acciones fraudulentas, la obtención de notas o grados académicos valiéndose de falsas o fraudulentas simulaciones, copiar total o parcialmente la labor académica de otra persona, plagiar total o parcialmente el trabajo de otra persona, copiar total o parcialmente las respuestas de otra persona a las preguntas de un examen, haciendo o consiguiendo que otro tome en su nombre cualquier prueba o examen oral o escrito, así como la ayuda o facilitación para que otra persona incurra en la referida conducta. Cualquiera de estas acciones estará sujeta a sanciones disciplinarias en conformidad con el procedimiento disciplinario establecido en el Reglamento General de Estudiantes de la UPR vigente. 1.1.13 Comentario sobre grabar videos y/o audio de las clases Los estudiantes no PUEDEN grabar la clase por forma de video o audio sin el permiso del profesor. Algunos estudiantes con necesidades especiales pueden hablar con el profesor para pedir el permiso. La solicitud y aprobación del permiso tiene que ser por escrito (por ejemplo por email). 1.1.14 Espacio libre de acoso sexual La Universidad de Puerto Rico prohíbe el descrimen por razón de sexo y género en todas sus modalidades, incluyendo el hostigamiento sexual. Según la Política Institucional contra el hostigamiento sexual, en la Universidad de Puerto Rico, Cert. Núm. 130 (2014-2015) de la Junta de Gobierno, si un(a) estudiante está siendo o fue afectado por conductas relacionadas a hostigamiento sexual, puede acudir ante la Oficina del Procurador Estudiantil, el Decanato de Estudiantes o el Coordinador de Cumplimiento con Título IX para una orientación o presentar una querella. 1.1.15 Protocolo de la Clase Los teléfonos mobiles serán apagado durante la clase. Si necesita una calculadora traerla al salón. El teléfono no debería esta visible durante la clase al menos que pide permiso al instructor. Recuerda que que se usara computadoras portátiles en cada sesión. "],["introducción-a-la-biometria.html", "Chapter 2 Introducción a la Biometria 2.1 El libro de la clase 2.2 El proceso de investigación: 2.3 El primer paso: 2.4 El segundo paso 2.5 El tercer paso: 2.6 El cuarto paso: 2.7 El quinto paso: 2.8 El sexto paso: 2.9 Tipo de error de interpretación en estadística 2.10 Cuando que una hipótesis no es una hipótesis? 2.11 Variables Independientes y Dependientes 2.12 Niveles de mediciones", " Chapter 2 Introducción a la Biometria 2.1 El libro de la clase Introductory Biological Statistics by Havel, Hampton and Meiners Presione en el titulo para dirigirlo a Amazon. Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; 2.2 El proceso de investigación: En este curso se estará enfatizando los análisis cuantitativo, esto es simplemente que analizamos los datos para llegar a una conclusión o interpretación sobre un tema. Naturalmente el proceso de seleccionar los datos puede ser un reto grande. Como uno selecciona los datos y el desarrollo de la investigación depende del diseño experimental. El diseño es el procedimiento de como uno recolecta los datos y como los vamos a analizar. En este curso no estaremos evaluando métodos cualitativos de análisis. Este método cuanlitativo se refiere a evaluar principalmente opiniones, motivaciones o razones que influencia o impacta una situación. En los métodos cuantitativos es necesario que los resultados sean de una forma o otra numéricos o categóricos. El proceso de investigación cuantitativo tiene múltiples pasos y podemos visualizar los pasos con un diagrama de flujo. Figure 2.1: El proceso de Investigación 2.3 El primer paso: Todo comienza con una pregunta que te llama la intención. Esta pregunta proviene de haber observado tu ambiente. Puede que sea algo muy sencillo (por ejemplo: si la cantidad de estudiantes registrado en una sección impacta su rendimiento), o puede ser una pregunta más complicada (por ejemplo cual es el impacto de la lactancia sobre el desarrollo de las células, organos, la bioquímica y inteligencia de los niños). 2.4 El segundo paso El próximo paso es desarrollar una hipótesis. Hay dos tipos de hipótesis, la hipótesis nula y la hipótesis alterna. SIEMPRE uno comprueba la hipótesis NULA. La nula en la forma más sencilla, es que los grupos son iguales. En otra palabra, si regresamos a la pregunta del primer paso, el rendimiento de los estudiantes es irrelevante de la cantidad de estudiantes en el salón en otra palabra es igual si hay pocos o muchos estudiantes. La hipótesis alterna es que “que la cantidad de estudiante en un salón impacta el rendimiento de los estudiantes”. Hay otros tipos de hipótesis nula que veremos más tarde. Si se acepta la hipótesis nula esto quiere decir que NO hay evidencia que los grupos sean diferentes. Si se rechaza la hipótesis nula es que hay evidencia que los dos grupos sean diferentes. 2.5 El tercer paso: Ahora hay que definir cual son las variables (datos) que se van a recolectar para evaluar la hipótesis. Por ejemplo, cuantos grupos de estudiantes se seleccionará (2, 3, 10 salones?), La información se recolectará de cuantos estudiantes por salones (todos, la mitad, los que se aparece, o se seleccionará los estudiantes al azar, y si selecciona al azar cual es el mecanismo para seleccionarlos de esta forma). Cual sera el indice de “rendimiento” (el entusiasmo de cada estudiante, la nota de un examen, de un trabajo, la nota final). Si se selecciona la nota final la información sera la nota numérica o alfabética (A, B, C, D, o F). Tomando la información anterior en consideración esto determinará el diseño experimental y las pruebas estadísticas que se deberá utiliza en el quinto paso. 2.6 El cuarto paso: Recolectar los datos. Este se debe hacer de una forma sistemática, con la información bien apuntado y subir la información en una hoja de calculo (spreadsheet), como MS Excel, Google Sheet y Numbers. Es mi sugerencia de NUNCA utilizar un programa como SPSS o JMP para poner los datos, ya que con estos programas si en el futuro se quiere tener acceso a los datos, y no tiene el programado o el programado ha cambiado de versión muchas veces los datos no se pueden leer (experiencia personal). 2.7 El quinto paso: En este paso se hará los gráficos y los análisis estadísticos para evaluar la hipótesis. 2.8 El sexto paso: Aceptar o rechazar la hipótesis NULA. 2.9 Tipo de error de interpretación en estadística El concepto básico en estadística, y probablemente el más difícil a captar es que en el mundo existe la verdad, pero cuando uno recolecta datos, no necesariamente los datos de la muestra representa la verdad o se acerca a la realidad. Por consecuencia siempre hay una posibilidad de que los datos nos engaña, y si nos engaña estamos haciendo un error en rechazar o aceptar la hipótesis nula. Por consecuencia aun que uno tome todas las precauciones para tener un diseño experimental adecuado es posible que los datos no representan el universo de los datos (la verdad). Típicamente se rechaza la hipótesis nula si el valor de p es menor de 0.05 (p &lt; 0.05). No es necesario que el valor sea menor de 0.05 para rechazar la hipótesis, en cierta condiciones el valor crítico pudiese ser mayor o menor de 0.05. El valor de p represente la probabilidad de rechazar la hipótesis nula cuando se debería aceptar. Por consecuencia un valor de p = 0.05, significa que hay 5% de probabilidad de cometer un error en que rechazamos la hipótesis cuando se debería aceptar si repetimos la investigación 100 veces (una razón de 1:20). Entonces este representa un tipo de error posible, frecuentemente nominado tipo de error 1 o alfa. En otra palabras significa la probabilidad de rechazar la hipótesis cuando uno debería aceptar la hipótesis. El otro tipo de error 2 o beta representa el error de aceptar la hipótesis nula cuando se debería haber rechazado. Los tres términos usado en estadística para de los dos tipos de errores Tipo de error I, alfa, falso positivos Tipo de error II, beta, falso negativos Aquí un gráfico de los tipos de errores. El gráfico representa los dos tipos de error y las dos condiciones en que no se hace un error. Figure 2.2: El proceso de Investigación Ahora vamos a considerar un ejemplo básico de preguntas que se podría evaluar. En este tiempo moderno un tipo de programas a la televisión bien común son los “Reality Shows”. Donde típicamente participa individuos supuestamente “normal” que no sean actores profesionales. Aquí una lista de algunos de los “Reality Shows”. 2.9.1 Consideramos los Reality Shows: Kardashians The Bachelorette Survivors Big Brother Shark Tank Skin Wars Hell’s Kitchen 2.9.2 Personalidad de las personas Uno se podría preguntar que tipo de persona son seleccionado para participar en estos tipos de programas. Una hipótesis que son gente con tipo de personalidad bien específica o que sean personas “normales”. Una hipótesis es que son gente que cumple con unas características tal como Trastorno de personalidad narcisista (TPN): estas personas de vez en cuando caracterizado como megalomanía, demuestran un patrón a largo plazo de comportamiento anormal caracterizado por sentimientos exagerados de importancia personal, necesidad excesiva de admiración y falta de empatía. En un ejemplo de Field et al. 2014 se demuestra la siguiente información sobre personas que solicitaron ser parte de uno de estos Reality Show que se llama Big Brother. Una hipótesis es que los productores de estos Reality Shows seleccionan gente con características de TPN más a menudo que las gente que no tienen esta condición. Podemos comprobar esto recolectando datos de los que solicitan y los que fueron aceptado o no a participar en Big Brother (United Kingdom). Se entrevistaron 7662 personas para seleccionar 12, a cada uno se le hizo una prueba si tenia síntomas de TPN. *** No TNP TPN Total Seleccionado 3 9 12 Rechazado 6805 845 7650 Total 6808 854 7662 Lo que uno observa es que la gente que son identificado que tiene características que cumple con TPN son más propenso a ser seleccionado para participar en el programa. Si fuese que la selección hubiese sido al azar, uno esperaría solamente 1 o 2 personas al máximo con la condición de TPN, no 9 personas. Más tarde aprenderemos como calcular el valor esperado exacto. 2.10 Cuando que una hipótesis no es una hipótesis? 2.10.1 Una hipótesis tiene que ser falsificable Esto quiere decir hay que tener un mecanismo para determinar la veracidad de una expresión. Por ejemplo en las 4 expresiones siguiente hay 2 que no pueden ser falsificable. El concepto de hipótesis falsificable proviene del filósofo Karl Popper en su libro Logik der Forschung (1934), traducido al español La lógica de la investigación científica. Ahora toma el tiempo de evaluar las siguientes expresiones y trate de determinar si son hipótesis falsificable. Desafortunademente, en el vocabulario popular el términos hipótesis y teoría se usan para describir cualquier pensamiento que la gente QUISIERA que se verídico. También se hace hipótesis o mejor dicho expresiones que no son falsificable. En nuestra sociedad donde cualquier persona se puede llamar un especialista en un tema los comentarios no falsificable dominan y resulta en confusión para la gente. Es importante en ciencia que los temas, las áreas de investigación sean falsificable. 2.10.2 Ejercicio 1 Lin Manuel es el mejor actor del mundo Todos la cisnes son blancos El aumento en producción de semillas en una planta X aumenta con el tamaño poblacional de esta especie. Los Beatles vendieron más discos que cualquier otro grupo artístico. 2.10.3 Evaluación de las expresiones falsificables Lin Manuel es el mejor actor del mundo. Esta expresión no es una hipótesis falsificable porque el concepto de mejor es uno que es basado en un juicio individual. En otra palabra como se mide “mejor, y quien toma la decisión sobre este medida cualitativa. Si Ud. proviene de una cultura diferente la apreciación a la música cambia dramáticamente. Todos los cisnes son blancos El problema con esta expresión es la palabra “Todos”. En ningún momento aun que uno trate nunca se podría encontrar “Todos” los cisnes para evaluar sin son blancos o no. Por consecuencia no es falsificable. El concepto de “Todos” aquí asume que ni uno no sera evaluado, que es imposible. El aumento en producción de semillas en una planta X aumenta el tamaño poblacional de esta especie. Este es una hipótesis falsificable por que uno puede hacer un experimento para evaluar la relación que hay entre la producción de semillas y el tamaño poblacional de una especie de plantas. Los Beatles vendieron más discos que cualquier otro grupo artístico. Este es una hipótesis falsificable porque se puede contabilizar la cantidad de discos vendidos por los Beatles y otros grupos y determinar si es cierto o no. 2.11 Variables Independientes y Dependientes -La variable Independiente: es la variable que impacta (teóricamente) la variable dependiente (puede ser que no impacta el resultado). Típicamente la x en un modelo es la variable independiente. -La variable Dependiente: es la variable que recibe el efecto (teóricamente) de la variable independiente. La variable dependiente depende de la variable independiente. Las y’s en un modelo son las variables dependientes. 2.12 Niveles de mediciones 2.12.1 Variables continuas Las variables con datos continuos: Son valores que son contiguos o por lo menos existe o pudiese existir los valores intermedios. Ejemplo 1 la distancia entre el valor 13 y 15 es igual que 101 y 103, hay dos unidades que los separa. Aunque no se haya observado el 14 ni el 102 en un recogido de datos estos valores tienen potencialmente existir, en otra palabra estos valores son posibles en el universo de los datos. Ejemplo 2 Si se mide el tamaño de una célula biológicas en micrómetros (µm, \\(10^{-6}\\)). Los valores intermedios y contiguos existen. Por ejemplo, el largo de las células de Escherichia coli (E. coli) adulta son de 5.27µm en promedio con una desviación estándar de 0.87µm. Esto significa que hay células de diferentes tamaños que van de menos de 2µm a más de 10µm de largo, y todos los valores pueden existir en este rango (ref: https://doi.org/10.1098/rsos.160417). Más tarde veremos como se puede llegar a la conclusión que las células varían entre 2µm a más de 10µm de largo, cuando uno tiene solamente el promedio y la desviación estándar. Ejemplo 3 El número de hermanos, si por ejemplo yo pregunto a seis estudiantes cuantos hermanos tiene. Yo podría tener la siguiente lista. Aunque que no hubo ningún estudiante que tenga 1 hermano o 6 hermanos, es posible esta alternativas. Note algo especial aquí es que nadie puede tener 2.4 hermanos, los valores tienen que ser números enteros. Cuando son conteos así, la distribución de los datos provienen de una distribución Poisson (veremos más tarde). Números de hermanos (0, 2, 5, 3, 8, 4) 2.12.2 Variables Discretas Categórica o Discreta Variables Nominales Hombres y Mujeres Omnívoro, vegetariano, vegano, carnívoro Variable Ordinal Datos donde hay un orden en los valores primero, segundo, tercero, etc. A, B, C, D, F (nota de estudiantes) pequeño, mediano, grande Variable Binomial Tiene solamente dos alternativas Vivo o muerto Vive en PR o No vive en PR Esta embrazada o No esta embarazada Tiene flores o no tiene flores "],["población-y-muestreos.html", "Chapter 3 Población y Muestreos 3.1 ¿Qué es la estadística? 3.2 El concepto de población 3.3 El concepto de muestreo 3.4 Griego y Latin 3.5 La verdad versus un estimado 3.6 Muestreos al azar 3.7 Error de muestreo: Exactitud y Precisión", " Chapter 3 Población y Muestreos Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; 3.1 ¿Qué es la estadística? Usando la definición de Snedecor y Cochran (1989) la estadística son las técnicas para la “recolección, análisis y la habilidad de tener una conclusión de los datos”. También pudiésemos decir que la estadística es el estudio de la incertidumbre. 3.2 El concepto de población Estos conceptos en estadística es sumamente diferente a la visión popular. En el concepto popular, social y geográfico una población es un conjunto de individuos de una especie o un concepto nacionalista (por ejemplos los Argentinos, o puertoriqueños). Típicamente se refiere a un grupo de individuos en un país, estado. El concepto de población en estadística es diferente en que se refiere a TODOS en el universo. Por consecuencia se fuésemos hacer un estudio de la población de puertoriqueños, tendríamos que incluir a todos ellos irrelevante de donde vive en el planeta. Por consecuencia el concepto de población en estadística siempre se refiere a todos los individuos sin que falte ni uno. Pudiésemos modificar nuestro estudio y decir que se va a estudiar una población más reducida. Por ejemplo la población de los puertoriqueños que viven en Puerto Rico en tal fecha. Aun así seria imposible recolectar datos de cada uno, porque siempre habrá algún individuo que no vamos a poder recolectar los datos. Por consecuencia el concepto de población es uno teórico. 3.3 El concepto de muestreo Un muestreo es el subgrupo de la población, donde el objetivo es que este muestro sea representativo de la población. Por ejemplo uno hace una recolección de información para saber cual es el nivel de estrés durante la pandemia de COVID-19 que tuvo los estudiantes universitarios. Seria un trabajo fenomenal recolectar datos sobre TODOS los estudiantes, pero su podría recolectar información sobre un subgrupo de ellos con la espera que los datos represente la población de estudiantes universitarios. 3.4 Griego y Latin Cuando uno quiere referir a la población/parámetro uno utiliza las letras del alfabeto griego y cuando nos referimos a un muestreo se usa la letra del alfabeto en latín. En la siguiente tabla se observa algunos de las variables que veremos en los módulos siguientes. En los próximos módulos regresaremos al significado de estos parámetros. Code library(gt) library(knitr) library(kableExtra) df &lt;- data.frame(variable = c(&quot;Promedio&quot;, &quot;Mediana&quot;,&quot;Varianza&quot;, &quot;Desviación Estandar&quot;, &quot;Proporción&quot;), Griego = c(&quot;$$\\\\mu$$&quot;, &quot;$$\\\\theta$$&quot;, &quot;$$\\\\sigma_{ }^2$$&quot;,&quot;$$\\\\sigma$$&quot;, &quot;$$p$$&quot;), Latin = c(&quot;$$\\\\bar{x}$$&quot;,&quot;$$M$$&quot;,&quot;$$s_{ }^2$$&quot;,&quot;$$s$$&quot; ,&quot;$$\\\\hat{p}$$&quot;)) kable(df, escape=FALSE) variable Griego Latin Promedio \\[\\mu\\] \\[\\bar{x}\\] Mediana \\[\\theta\\] \\[M\\] Varianza \\[\\sigma_{ }^2\\] \\[s_{ }^2\\] Desviación Estandar \\[\\sigma\\] \\[s\\] Proporción \\[p\\] \\[\\hat{p}\\] 3.5 La verdad versus un estimado Cuando uno hace una investigación esta buscando la “verdad” en otra palabra estamos a la búsqueda de la información de la población. Desafortunadamente, raramente podemos tener TODA los datos, por consecuencia esperamos que la muestra sea una buena representación de la “verdad”. Se espera que el promedio de la muestra se acerca a promedio del universo (la verdad). Matemáticamente uno lo puede escribir de la siguiente manera \\(\\overline{x}\\approx\\mu\\). El gran problema en la ciencia es que nunca estamos 100% seguro de los trabajos de investigación porque nunca sabemos el \\(\\mu\\). Este valor es casi siempre desconocido. 3.6 Muestreos al azar Una de las áreas de estudio importante es saber organizar un estudio para responder a unas preguntas y que no sea sesgado (en ingles “bias”). Cuando se selecciona los datos necesitamos asegurar que los datos sean representativos de la población de interés, el \\(\\mu\\). Si por ejemplo queremos saber el nivel de colesterol en la población de puertoriqueños que viven en Puerto Rico el diseño del muestreo tiene que tomar en cuenta ese grupo y la muestra tiene que representar ese grupo. Pregunta corta: Explica el sesgo de los diferentes métodos, como se podría mejorar el muestreo? ¿Cual de las siguientes alternativas es un mejor diseño experimental para deteminar el nivel de colestrerol de los puertoriqueños que viven en Puerto Rico? Se muestrea estudiantes de la clase de biometría de la UPRH Se muestrea paciente que llegan a la oficina de un medico Se muestrea paciente que llegan a la sala de emergencia Se muestrea gente de multiples edades Se muestrea gente de multiples edades y distribuido por toda la isla 3.7 Error de muestreo: Exactitud y Precisión 3.7.1 La exactitud se refiere a cuan cerca es el valor medido al valor real de la variable de interes. Cuan es el largo de la hoja 3.7.2 La precisión es un estimado de cuan cerca cada valor es uno del otro. Hablando de la mismo individuo o variable. "],["inferencias-y-hipótesis.html", "Chapter 4 Inferencias y Hipótesis 4.1 Introducción 4.2 Ejemplo 1: 4.3 Ejemplo 2: 4.4 Inferencias en estadística 4.5 Hipótesis 4.6 El valor de p 4.7 Los errores de tipo I y tipo II 4.8 El poder de las pruebas inferenciales y lo parámetros que lo influencia", " Chapter 4 Inferencias y Hipótesis Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; 4.1 Introducción Los parámetros versus un muestreo: En algunos instancia se podría calcular el parámetro (por ejemplo el promedio) en otra palabra la población (todos los individuos sin que falte ni uno). Si es así tenemos todos los datos. Por ejemplo si la población es cuantos médicos fueron infectado por el COVID-19 en un hospital especifico entre una fechas delimitada es probable que se puede conseguir la información de cada un los médicos, y se podría calcular la proporción de infectado. Pero cuando la población es más grande será necesario tener solamente una muestra de la población, si se usa un método al azar de recolección de los datos uno podría inferir cual es el estado basado en las estadística recolectada. 4.2 Ejemplo 1: Por ejemplo en un estudio hecho por la Dra. Patricia Burrowes sobre la frecuencia de una infección común de los coquí ella evaluó la presencia del hongo sobre la piel de estos anfibios y encontró que los individuos en bosque nublado eran más frecuentemente infectado que los del bosque enano. Ella y sus estudiantes muestrearon 299 individuos del bosque nublado y 130 del bosque enano, este esfuerzo fue muy grande. Encontrar los coqui en el campo no fácil y no hay manera de conseguir todas las pequeñas ranas. Costo potencial en aptitud evolutiva de Batrachochytrium dendrobatidis en Eleutherodactylus coqui, y comentarios sobre el riesgo de infección relacionado con el ambiente”. El tamaño corporal (longitud hocico a cloaca) en adultos de Eleutherodactylus coqui infectados y no infectados con Batrachochytrium dendrobatidis (Bd) fue comparado para determinar el costo potencial en aptitud evolutiva de quitridiomicosis en poblaciones resistentes. Los estudios fueron realizados en dos tipos de bosque a diferentes elevaciones, Bosque Nublado (650 m) y Bosque Nublado Enano (850 m), en El Yunque, Puerto Rico. Nuestros resultados demuestran que los machos infectados con Bd son significativamente más pequeños que los no infectados en el Bosque Nuboso, sin embargo no sucede lo mismo en el Bosque Nublado Enano. Aunque las hembras que están infectadas por Bd también son más pequeñas que las no infectadas, este efecto no es estadísticamente significativo. La prevalencia de Bd y la probabilidad de infección por este hongo son significativamente más altas en el Bosque Nublado (44.1%) que en el Bosque Nublado Enano (20.7%) para ambos sexos. Reportamos las diferencias en factores ambientales en estos dos tipos de bosque en Puerto Rico y discutimos las implicaciones en el crecimiento de Bd y la vulnerabilidad de las ranas a la infección por este patógeno. &gt; &gt; &gt; Burrowes, P. A., A. V. Longo, and C. A. Rodríguez. 2008b. Potential fitness cost of Batrachochytrium dendrobatidis in Eletherodactylus coqui, and comments on environment-related risk of infection. Herpetotropicos 4:51-57. 4.3 Ejemplo 2: En este segundo ejemplo se demuestra la eficiencia de dos vacunas para proteger del virus papiloma humano (VPH) que es una causa principal del cáncer del útero. Hay un estimado que 25% de los adultos están infectado por HPV en un momento en su vida (Lowndes, doi: 10.1017/S0950268805005728) y que este cáncer es el segundo más común en el mundo (Bosch et al. 2002, doi: 10.1136/jcp.55.4.244). El siguiente ejemplo demuestra que las vacunas pueden ser muy efectiva. ¿Qué tan eficaces son las vacunas contra el VPH? Las vacunas contra el VPH son altamente eficaces para prevenir la infección por los tipos de VPH a los que atacan cuando las vacunas se administran antes de la exposición inicial al virus — es decir, antes de que el individuo tenga actividad sexual. En los estudios que llevaron a la aprobación de Gardasil y de Cervarix, se encontró que estas vacunas proveen casi 100 % de protección contra infecciones persistentes del cuello uterino por los tipos 16 y 18 de VPH y contra los cambios celulares del cuello uterino que pueden causar estas infecciones persistentes. Gardasil 9 es tan eficaz como Gardasil para la prevención de las enfermedades causadas por los cuatro tipos de VPH (6, 11, 16 y 18), según reacciones similares de anticuerpos en participantes de estudios clínicos. Los estudios que llevaron a la aprobación de Gardasil 9 encontraron que es casi 100 % eficaz en la prevención de enfermedades cervicales (de cuello uterino), de vulva y de vagina causadas por los otros cinco tipos de VPH (31, 33, 45, 52 y 58) a los que se dirige (4). En un documento de posición de 2017, la Organización Mundial de la Salud declaró que las vacunas contra el VPH tienen una eficacia equivalente (5). Se ha encontrado que Cervarix provee protección parcial contra algunos otros tipos de VPH que pueden también causar cáncer pero que no están incluidos en la vacuna, un fenómeno llamado protección cruzada (6). &gt; Fuente de información: https://www.cancer.gov/espanol/cancer/causas-prevencion/riesgo/germenes-infecciosos/hoja-informativa-vacuna-vph 4.4 Inferencias en estadística El concepto de inferencias en estadística se refiere al proceso de hacer conclusiones basado en un muestreo. Por ejemplo en el primer ejemplo de la infección de hongos en los coquis, uno podría inferir que la proporción de ranas infectada será igual (o muy similar) en otros bosques nublados y enanos de Puerto Rico. 4.5 Hipótesis En la sección 6.2 del libro de Havel et al. leer y evaluar la tabla 6.2 para tener unos ejemplos de expresiones que no son una hipótesis y lo que es son. NOTA: importante es el autor menciona aquí son las hipótesis alterna, en otra palabra los que uno piensa que podría ocurrir. Pero esa no es la hipótesis que se prueba, lo que se prueba es la hipótesis NULA, Ho. Cuando se dice la hipótesis NULA es que no hay diferencias entre los grupos. Vea la tabla 6.2 del libro para más ejemplos. Ejemplo de hipotesis Nula y Alterna NULA, Ho ALTERNA, Ha No es una hipótesis 1 Tratamiento con la vacuna de Salk no tiene efecto sobre el riesgo de infección de polio en niños El efecto de la vacuna Salk reduce el riesgo de infección de polio en los niños El polio es malo 2 Los Beatles no vendieron más discos que cualquier otros grupos de rock Los Beatles vendieron más discos que cualquier otro grupo de rock La música de los Beatles es obsoleta 4.6 El valor de p El valor de p es la probabilidad de tener una estadística tan extrema si la hipótesis es verdad (en otra palabra la Ho es la correcta). Uno podría decir que es un indice de la evidencia CONTRA la hipótesis NULA. PERO NOTA es incorrecto decir que es la probabilidad que la Ho es correcta. Uno dice si el valor de p&gt;0.05 que no hay evidencia para rechazar la hipotesis nula (no dice que la hipotesis nula es correcta). Antes de comenzar a hacer el estudio se debería a priori tener una decisión cual sera el nivel de alpha, \\(\\alpha\\) para rechazar la hipótesis nula. Típicamente el valor critico de \\(\\alpha\\) es 0.05 o 5%. Esto quiere decir que si uno repite el experimento 100 veces 5 veces la investigación nos va a dar una resultado equivocado. Que se rechaza la Ho cuando se debería aceptar. Esto una vez en cada 20 experimentos con las mismas condiciones. En muchas ramas de investigación como la física el nivel de \\(\\alpha\\) es frecuentemente 0.01 o menos. 4.7 Los errores de tipo I y tipo II Vea el modulo anterior. 4.8 El poder de las pruebas inferenciales y lo parámetros que lo influencia Si la hipótesis nula es falsa es probable que se podría rechazar con cierta confianza. El complemento de beta, \\((1-\\beta)\\) es la prueba de poder. La prueba de poder es la probabilidad de correctamente rechazar la hipótesis nula cuando es falsa. Para aclara la \\(\\beta\\) es la probabilidad de cometer un error tipo II. El Poder (the Power) es \\((1-\\beta)\\) es la probabilidad de correctamente rechazar una hipótesis nula falsa. Evalúa el siguiente gráfico: La prueba de poder es influenciada por tres propriedades. El nivel del tipo de error I, o sea el \\(\\alpha\\). La diferencia entre dos o más promedios que queremos evaluar. El tamaño de muestra (n). La linea vertical entrecortada representa el valor critico. El área gris obscuro representa el error \\(\\alpha\\), la probabilidad de rechazar la hipótesis nula cuando debería aceptar la hipótesis nula. El área gris liviano representa el error \\(\\beta\\). Una ilustración de como el \\(\\alpha\\) afecta el \\(\\beta\\)” "],["historia-breve-de-la-estadística.html", "Chapter 5 Historia breve de la estadística 5.1 La dama degustando té 5.2 Definición de lo que es la estadística 5.3 Introducción a la Historía de la Estadística. 5.4 Gertrude Mary Cox 5.5 Algunos personas importantes 5.6 Lista de estadísticos 5.7 Formula", " Chapter 5 Historia breve de la estadística Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; 5.1 La dama degustando té Era una tarde de verano en Cambridge, Inglaterra, a finales de la década de 1920. Un grupo de profesores universitarios, sus esposas y algunos invitados estaban sentados alrededor de una mesa al aire libre para tomar el té de la tarde. Una de las mujeres insistía en que el té era diferente dependiendo de si el té se vertía en la leche o si la leche se vertía en el té. Las mentes científicas entre los hombres se burlaron de esto como una tontería. ¿Cual podría ser la diferencia? No podían concebir ninguna diferencia en la química de las mezclas que pudieran existir. Un hombre delgado y bajo, con anteojos y una barba de Vandyke que empezaba a ponerse gris, se abalanzó sobre el problema. “Probemos esta propuesta”, dijo emocionado. Comenzó a esbozar un experimento en el que a la señora que insistía en que había una diferencia se le presentaría una secuencia de tazas de té, en algunas de las cuales se había vertido la leche en el té y en otras se había vertido el té en la taza de leche. Cuento del libro de “The Lady Tasting Tea: How Statitics Revolutionized Science in the Twentieth Century” por David Salslburg. Traducido por la pagina de Google Translation. Así comienza el libro de Salsburg (2001), para describir el comportamiento de los científicos cuando están animados de su tema y el deseo de resolver un enigma. Esa persona con barba de Vandyke era Ronald Aylmer Fisher (1890 -1962) es reconocido como responsable de la estadística moderna y una de las personas más importante en el área en el siglo 20. Su contribuciones han tenido un impacto en muchas áreas incluyendo la genética mendeliana y la selección natural. 5.2 Definición de lo que es la estadística La estadística es un área de la ciencia de datos que utiliza valores numéricos para evaluar patrones y inferir situaciones futuras. Esta definición es sencilla, pero incluye muchos temas pero lo más importante es el componente de utilizar datos, resumiendo estos en indices o parámetros y utilizar estos para predecir/inferir el futuro. La palabra estadística usado en el termino más o menos similar a su definición de hoy probablemente origina del alemán Statistik por Gottfried Achenwall (1749). Donde el termino era para la descripción de datos del estado. Es solamente en 1791 por Sir John Sinclair que el termino comenzó a ser utilizado para la descripción de conjuntos de datos en general sin ser limitado a datos de un estado/pais. 5.3 Introducción a la Historía de la Estadística. Al principio en el siglo 18 el termino estadística era designar la colección información sobre la población y la economía de diferentes regiones o países. En este periodo el objetivo era tabular la información, por ejemplo cuanta gente en un área, cuantas vacas hay, cuanta gente son parte de la nobleza. Por ejemplo uno de las primeras encuesta para determinar la estadística de una población fue hecha por John Gaunt (1662) titulado Natural and Political Observations Made upon the Bills of Mortality y puede encontrar el libro original aquí http://www.neonatology.org/pdf/graunt.pdf. En el libro expone que 1/3 parte de los niños antes de la edad de 16 mueren en Londres, Inglaterra. Aquí un extracto de una de estas tablas de las causas de enfermedades y mortandad en Londres en el año 1632. Note que antes de este trabajo esto datos era bien raro y inexistente en la mayoría de las ciudades o países. Note algunos causas principales de mortandad, “Aged” (628), que la persona es de edad mayor, y “Abortive and Stillborn” que natimuerto (445). Algunos se considerara raros hoy en día es morir de “grief” o sea de tristeza (11). Figure 5.1: Gaunt Disease Tables El otro componente importante de la estadística fue el desarrollo de las probabilidades en el siglo 17 y 18. La gente le gustaba (como hoy en día) hacer apuestos y jugar cartas para dinero. Entonces mucha gente trataba de entender las diferentes probabilidades de ganar en estos juegos de azar para poder aumentar su probabilidad de ganar en estos juegos. 5.4 Gertrude Mary Cox Trabajo presentado por Abimelys Anaya (estudiante de la Universidad de Puerto Rico en Humacao) Gertrude Mary Cox fue una destacada e importante estadística estadounidense. Nació el 13 de enero de 1900 en una granja cerca a Dayton, Iowa; y falleció a los 78 años, el 17 de octubre de 1978 en Durham, Carolina del Norte, a causa de leucemia. Compartiendo su hogar con 3 hermanos, se dice que su familia era muy unida, pero Cox era específicamente más cercana a su madre, Hemma, de quién heredó su pasión por ayudar a los demás. Cursó sus primeros estudios en la llamada Perry High School de la misma ciudad. Su amor por los deportes competitivos, hizo que formara parte del equipo de baloncesto en dicha escuela. No fue hasta 1925, luego de haber trabajado un tiempo como diaconisa de la Iglesia Metodista, que sintió interés en continuar estudios graduados en Iowa State College en Ames con concentración en matemáticas, debido a que su cargo en la iglesia requería un grado universitario. Logrando así en 1931, alcanzar una maestría en estadística. Desde ese mismo año hasta el 1933, terminó estudios de posgrado en estadística psicológica en la Universidad de California. Posteriormente, regresa a Iowa, donde participó en la inauguración del Laboratorio de Estadística y comienza su investigación en base al diseño experimental. Fue dicha carrera y el empeño depositado en la misma, quien le permitió dejar una gran aportación en procesos que utilizamos y que conocemos hoy día de esta rama de la ciencia. 5.4.1 Primera dama en Estadística En 1939, la nombraron profesora asistente en Iowa State College y, en 1940, dirigió el primer departamento de Estadística Experimental en la Escuela de Agricultura de la Universidad de Carolina del Norte. Esto la convirtió en la primera mujer directora del recinto. Además, Cox fue la primera mujer jefa del Instituto de Estadística de la Universidad de Carolina del Norte en 1944. Un año más tarde, participó como editora principal de la revista Biometrics durante 10 años, y fundó, en 1947, la ¨International Biometric Society¨. Además, se convirtió en presidenta de la ASA (American Society of Anesthesiologists) en 1956. 5.4.2 Revista Biometrics La revista7 fue publicada por la Sociedad Internacional de Biometría en 1945, originalmente bajo el título de Biometrics Bulletin. Sin embargo, en 1947, su nombre fue acortado. Su objetivo principal consiste en publicar artículos sobre la aplicación de la estadística y las matemáticas a las ciencias biológicas. Según una encuesta realizada por especialistas en biometría, obtuvo el quinto lugar entre 40 revistas existentes de estadítica. 5.4.3 Libro: Diseños Experimentales ¿Qué es el diseño experimental? Este consiste en la identificación y cuantificación de las causas de un efecto provocado sobre otra variable de interés durante un estudio experimental. En 1950, Gertrude M. Cox junto a William Cochran, publicó Experimental Design, libro utilizado por años, y que actualmente permanece accesible, como primera referencia para el diseño experimental. En este, podemos encontrar la expansión de sus notas mimeografiadas de las clases de diseño que brindaba a sus estudiantes. El libro enfatiza tres principios: (1) los estadísticos deben participar en la investigación desde las etapas de planificación, es decir, primeros pasos, el establecimiento de los objetivos del experimento y la planificación del análisis; (2) aleatorizar todo lo que se pueda aleatorizar; y (3) utilizar el bloqueo, siempre que sea posible, para reducir los efectos de variabilidad, donde los bloques son grupos homogéneos de unidades experimentales. Según menciona Sharon L. Lohr en un artículo para ¨Notices of the American Mathematical Society¨4, en él ¨podemos encontrar planos detallados para el cuadrado latino, factorial, factorial fraccional, parcela dividida, celosía, bloque incompleto balanceado y otros diseños. Cada descripción de diseño comenzaba con ejemplos, seguida de una discusión sobre cuándo el diseño era adecuado e instrucciones detalladas de cómo realizar la aleatorización. Luego, vino uno o más estudios de casos detallados, que muestran por qué ese diseño había sido elegido para cada experimento y cómo había sido aleatorizado, tomando al lector paso a paso a través de los cálculos necesarios para construir el análisis de varianza y estimar los errores estándar para diferencias de medias de tratamiento. Los autores también discutieron cómo estimar la eficiencia del diseño en relación con un diseño completamente aleatorio y cómo hacer los cálculos para la estructura desequilibrada que resultó cuando uno o más ejecuciones experimentales tenían datos faltantes¨. 5.4.4 Últimas aportaciones Gertrude M. Cox se retiró en 1960 del Instituto de Estadística, para dirigir la División de Investigación Estadística del RTI (Research Triangle Institute), donde fue asesora desde el 1965. Finalmente, se dedicó a distribuir sus conocimientos en estadística al exterior. Realizó 23 viajes internacionales, entre los cuales se encontraban los países de Egipto y Tailandia. Otros reconocimientos 1944 - Socia de la Asociación Americana de Estadísticas y del Instituto de Estadísticas Matemáticas. 1949 - Primera mujer electa en el Instituto Internacional de Estadística. 1957 - Socia de honor de ¨Royal Statistical Society¨. 1959 - Recibe premio O. Max Gardner por parte de la Universidad de Carolina del Norte por su “contribución al bienestar de la raza humana”. 1975 - Electa en la Academia Nacional de Ciencias. 1977 - La universidad de Carolina del Norte, creó una beca de investigación de $200,000 en su honor. Defendió el uso de computadoras electrónicas para el trabajo estadístico. Sin lugar a dudas, fue pionera de lo que actualmente nos permite, de manera fácil, realizar investigaciones cuantitativas y que son, y han sido desde entonces, de suma importancia para nuestro entendimiento en las ciencias biológicas. 5.4.5 Referencias 1 Anderson, R.L. (1900-1978). Gertrude Mary Cox. Recuperado el 13 de septiembre de 2020, de http://www.nasonline.org/publications/biographical-memoirs/memoir-pdfs/cox-gertrude.pdf 2 Biometrics (journal). (2020). Recuperado el 13 de septiembre de 2020, de https://en.wikipedia.org/wiki/Biometrics_(journal) 3 Gertrude Cox. (2020). Recuperado el 13 de septiembre de 2020, de https://es.wikipedia.org/wiki/Gertrude_Cox 4 Lohr, S.L. (2019). Gertrude M. Cox and Statistical Design. Recuperado el 13 de septiembre de 2020, de https://www.ams.org/journals/notices/201903/rnoti-p317.pdf 5 Mujeres con ciencia. (2014). Gertrude Cox, la primera dama de la Estadística. Recuperado el 13 de septiembre de 2020, de https://mujeresconciencia.com/2014/06/09/gertrude-cox-la-primera-dama-de-la-estadistica/ 6 Universidad de Colima. (2020). Diseño experimental. Recuperado el 13 de septiembre de 2020, de https://recursos.ucol.mx/tesis/diseno_experimental.php 7 Welsh, A., Ghosh, D., Brewer, M. y Molenberghs, G. (1999-2020). Biometrics, Journal of the International Biometric Society. Recuperado el 13 de septiembre de 2020, de https://onlinelibrary.wiley.com/journal/15410420 5.5 Algunos personas importantes Trabajo grupo de 2: 10 puntos. PARTE de las destrezas que estará aprendiendo en adición de conocer un estadístico es como preparar un documento en .Rmd para hacer una documento. Se someterá tanto el documento en .html y .Rmd en MSTeam. Se seleccionará uno de las personas abajo y se hará una pequeña biografía sobre esta persona (3 paginas). Debe incluir diferentes componentes. Información personal de la persona Su carrera de estudio Su aportación a la estadística Cual método estadístico desarrolló (seleccioné uno para explicar, aunque puede mencionar múltiples). Por qué este método fue innovador Cuantos papers a publicado (busca en Google scholar) Pon una formulas matemáticas con explicaciones de una de las aportaciones en estadística. fotos/pintura de la persona literatura citada El trabajo debería ser montado en .Rmd 5.6 Lista de estadísticos Florence Nightingale Gertrude Mary Cox Enid Charles Grace Wahba Ronald Fisher Reverand Thomas Bayes John Tukey Karl Pearson Carl Gauss Bradley Efron Andrey Nikolayevich Kolmogorov Pierre-Simon Laplace George Box Francis Galton Andrey Markov Samuel S. Wilks 5.7 Formula Vea este enlace. https://rpruim.github.io/s341/S19/from-class/MathinRmd.html Localizado en el centro y una linea parte \\[\\sum_{n=1}^{10} n^2\\] Localizado en la misma linea \\(\\sum_{n=1}^{10} n^2\\) Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; Code library(ggplot2) library(Hmisc) library(gridExtra) # Un paquete para organizar las figuras de ggplot2 "],["medida-de-tendencia-central.html", "Chapter 6 Medida de tendencia central 6.1 Calculando el promedio 6.2 Cuando el promedio no esta localizado en el centro 6.3 La mediana 6.4 Con n impares 6.5 Con n pares 6.6 La moda 6.7 Cuando es que el promedio, mediana y moda son iguales? 6.8 Distribución cuando los tres valores de tendencia centrtal no son iguales. 6.9 Variables binomial", " Chapter 6 Medida de tendencia central La medidas de tendencia central se llaman así, porque el valor indica la distribución de los datos y los indices tiende a estar en el centro de la distribución. Hay por lo menos 16 tipos de medidas de tendencias centrales https://en.wikipedia.org/wiki/Central_tendency. En este curso estaremos solamente mencionado 3 de estas medidas. El promedio a arithmetico La mediana La moda 6.1 Calculando el promedio Aquí creamos una lista de datos con la función c( ) y con la función mean podemos calcular el promedio. El promedio es la suma de los valores divido por la cantidad de valores en la lista. \\[\\bar{x}=\\frac{\\sum_{i=1}^{n}x_i}n\\] Code x=c(0,1,2,3,4,5,6,7,8,9,10) mean(x) ## [1] 5 6.2 Cuando el promedio no esta localizado en el centro Digamos que yo tengo la cantidad de semillas producida por 11 plantas, la primera no produjo semillas, la segunda 2 semillas y subsiguientemente hasta la ultima que tuvo una producción de 1000 semillas. Nota que en este caso el promedio no se encuentra el el centro de los datos, por consecuencia NO es un buen indicador de la tendencia central de los datos. Cuando esto ocurre uno no debería usar el promedio para describir la tendencia central de los datos. Code x=c(0,1,2,3,4,5,6,7,8,9,1000) sum(x)/length(x) ## [1] 95 Code mean(x) ## [1] 95 6.3 La mediana 6.4 Con n impares Cuando el promedio no es indice adecuado de la tendencia central tenemos dos alternativas, la mediana y la moda. La mediana es el valor en el centro después de haber organizado los datos del más pequeño al más grande. \\[Mediana\\ =\\frac{\\left({x}_{n+1}\\right)^{th}}{2}\\] Donde n es la cantidad de valores en orden del más pequeño al grande. Por consecuencia se selecciona el valor en el centro de todos los valores. Lo que la función de mediana hace es poner los valores en orden y después determina cual es el valor en el centro. Aquí para demostrar los que hace la función 1) creo un una lista de valores, 2) pongo los datos en orden 3) y mirando los valores en orden vemos que el valor 6 es el valor en el centro. Pero este paso no es necesario ya que la función median lo hace automaticamente. Code b=c(247,0,3,43626,26,23,1,2,4,5,24,6,7) b=sort(b) length(b) ## [1] 13 Code median(b) ## [1] 6 6.5 Con n pares Cuando hay una cantidad de datos pares, los dos valores en el centro son sumado y el promedio es calculado. \\[Mediana\\ =\\frac{1}{2}* (\\frac{\\left({x}_{n+1}\\right)^{th}}{2}+\\frac{\\left({x}_{n+1}\\right)^{th}}{2})\\] En el siguiente caso tanto el valor de 6 y 7 se encuentra en el centro, por consecuencia la mediana es el promedio de estos valores. Code b=c(247,0,3,43626,26,23,1,2,4,5,24,6,7,7) b=sort(b) b ## [1] 0 1 2 3 4 5 6 7 7 23 24 26 ## [13] 247 43626 Code median(b) ## [1] 6.5 6.6 La moda La moda es el valor más común. Parta encontrar la moda, correr una función ya que no existe ningun paquete que tiene esa alternativa. Code # Create mode() function to calculate mode mode &lt;- function(x, na.rm = FALSE) { if(na.rm){ #if na.rm is TRUE, remove NA values from input x x = x[!is.na(x)] } val &lt;- unique(x) return(val[which.max(tabulate(match(x, val)))]) } Ya pueden ahora usar la mode para encontrar la moda del conjunto de datos. Lo que vemos es que el valor de 7 es el más comun en la lista de datos. Code mode(b) ## [1] 7 6.7 Cuando es que el promedio, mediana y moda son iguales? Los tres valores de tendencia central son iguales cuando la distribución es normal, conocida también como en forma de campana. Aquí preparo un lista de datos con distribución normal, y evaluamos donde están los tres valores de tendencia central. Se usa la función rpois, para crear un conjunto de datos al azar con 100000, datos, un promedio de 100. Code df=rpois(5000, 100) df1=data.frame(df) head(df1, n=2) ## df ## 1 113 ## 2 106 Lo que uno observa es que los tres valores son muy cercano uno del otro. Code #mean(df1$df) #median(df1$df) #mode(df1$df) Podemos visualizar estos datos usamos dos gráfico, En el gráfico de la izquierda se ve una distribución normal con las tres lineas (promedio, mediana y moda). En el gráfico de la derecha se observa la misma información pero solamente los valores entre 96 y 101. Se observa que la mediana y el promedio son igual y la moda varia un poco, se encuentra donde la barra es más alta. Se observa que los tres valores son cerca del centro. Code pro=mean(df1$df) med=median(df1$df) mod99=mode(df1$df) mod99 ## [1] 102 Code a=ggplot(df1, aes(df))+ geom_histogram(fill=&quot;orange&quot;, colour=&quot;white&quot;, binwidth = 1)+ geom_vline(aes(xintercept = pro), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = med), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = mod99), colour=&quot;green&quot;)+ theme(legend.position = &quot;none&quot;) a Code b=ggplot(df1, aes(df))+ geom_histogram(fill=&quot;orange&quot;, colour=&quot;white&quot;, binwidth = 1)+ geom_vline(aes(xintercept = pro), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = med), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = mod99), colour=&quot;green&quot;)+ xlim(94,105)+ theme(legend.position = &quot;none&quot;) Code gridExtra::grid.arrange(a,b, ncol=1) 6.8 Distribución cuando los tres valores de tendencia centrtal no son iguales. En estas distribuciones uno observa que hay exceso de vaslores pequeños o grande. Esto resulta en que los tres indices de tendencias centrales no se encuentra cerca uno del otro. Code library(tidyverse) dfb1=round(rbeta(10000, 3,1, ncp = 0),3) dfb1=tibble(dfb1) #head(dfb) df2= round(rbeta(10000, 1,3, ncp = 0),3) df2=tibble(df2) #head(df2) ¿Cual es la linea de promedio, moda y mediana en cada gráfico? Code mea=mean(dfb1$dfb1) med=median(dfb1$dfb1) mod=statip::mfv1(dfb1$dfb1) meab=mean(df2$df2) medb=median(df2$df2) modb=statip::mfv1(df2$df2) SesgadoDerecho=ggplot(dfb1, aes(dfb1))+ geom_histogram(fill=&quot;orange&quot;, colour=&quot;white&quot;)+ geom_vline(aes(xintercept = mea), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = med), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = mod), colour=&quot;green&quot;)+ theme(legend.position = &quot;none&quot;) SesgadoIzquierda=ggplot(df2, aes(df2))+ geom_histogram(fill=&quot;orange&quot;, colour=&quot;white&quot;)+ geom_vline(aes(xintercept = meab), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = medb), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = modb), colour=&quot;green&quot;)+ theme(legend.position = &quot;none&quot;) SesgadoDerecho Code SesgadoIzquierda Code library(ggpubr) #ggarrange(c,d, nrow=2, ncol=1) library(grid) #grid.arrange(rectGrob(), rectGrob()) #marrangeGrob(c,d, nrow=2) Code #c #d #library(scater) #multiplot(c,d, ncol=2) 6.9 Variables binomial En el siguiente ejemplo podemos ver claramente que las medidas de tendencias central no son adecuada. Primero producimos un conjunto de datos que tiene solamente dos alternativas 0 y 1. Para facilitar los datos e imaginar lo que quiere decir estos datos que cuando es un 0 la persona no tiene hijos y cuando es un 1 tiene hijos. Code dfBin=replicate(10000,rbinom(length(.6), size=1,prob =0.6)) dfBin=data.frame(dfBin) head(dfBin) ## dfBin ## 1 0 ## 2 1 ## 3 1 ## 4 0 ## 5 1 ## 6 0 Ahora vamos a producir el gráfico. Lo que uno observa es que el promedio esta en el centro cerca de .6, pero no hay ningún dato cerca del promedio. El promedio no representa la “tendencia central” de la distribución. Code mea=mean(dfBin$dfBin) med=median(dfBin$dfBin) mod=mode(dfBin$dfBin) mea ## [1] 0.5999 Code ggplot(dfBin, aes(dfBin))+ geom_histogram(fill=&quot;orange&quot;, colour=&quot;white&quot;)+ geom_vline(aes(xintercept = mea), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = med), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = mod), colour=&quot;green&quot;)+ theme(legend.position = &quot;none&quot;) 6.9.1 Preguntas de practica sobre medidas de tendencias central. ¿Cuando es que el promedio, mediana y moda son iguales? ¿Cual es la moda de esta conjunto de datos? Code x=c(3,5,2,3,6,7,8,9, 1) x ## [1] 3 5 2 3 6 7 8 9 1 ¿Cual es la mediana de este conjunto de datos? Eso son la cantidad de cursos Code y=c(3,5,2,3,6,7,8,9, 1) y ## [1] 3 5 2 3 6 7 8 9 1 ¿Cual es la mediana de este conjunto de datos? Code y=c(3,5,2,3,6,7,8,9, 1, 6) sort(y) ## [1] 1 2 3 3 5 6 6 7 8 9 Para describir la medida central de este conjunto de datos, se debería usar el promedio, mediana o moda? Code z=c(1,2,2,3,4,10, 100, 1000) z ## [1] 1 2 2 3 4 10 100 1000 ¿Cual es la moda de las siguientes datos. Número de hijos que tienen estudiantes universitarios Code Numero_hijos=c(1,0,0,0,0,0,0,0,0,0,1,3) Numero_hijos ## [1] 1 0 0 0 0 0 0 0 0 0 1 3 "],["medidas_de_dispersión.html", "Chapter 7 Medidas_de_dispersión 7.1 Qué es la dispersión en estadística 7.2 Vizualizando la dispersión 7.3 El rango 7.4 Mínimo y máximo 7.5 Ejemplo de la clase 7.6 La varianza 7.7 Calcular la varianza con var() 7.8 La desviación estandar 7.9 El rango intertcuartil. 7.10 El error estandard 7.11 El intervalo de confianza de 95% del promedio 7.12 El intervalos de confianza de los datos 7.13 Rangos incluidos en intervalos de confianza 7.14 Ejemplo del intervalo de confianza 7.15 Otro ejemplo de los intevalos de confianzas 7.16 Ejercicios de practica para entender el concepto de Medidas de dispersión", " Chapter 7 Medidas_de_dispersión ## [1] &quot;2023-08-30&quot; Code library(ggplot2) library(Hmisc) library(gridExtra) # Un paquete para organizar las figuras de ggplot2 library(gt) library(tidyverse) 7.1 Qué es la dispersión en estadística Las medidas o indices de dispersión, son indicadores de cuan variable los datos son uno del otro. Si todos los valores tienen el mismo valor no hay dispersión. Hay múltiples indices de dispersión vamos a evaluar solamente algunos de estos indices, para más información pueden ir al siguiente enlace https://en.wikipedia.org/wiki/Statistical_dispersion. Los indices que estaremos estudiando son los siguientes el rango la varianza la desviación estándar el error estándar el rango intercuartil el intervalo de confianza de 95% 7.2 Vizualizando la dispersión Primero miramos un gráfico donde tenemos datos donde el promedio es igual pero la dispersiones son diferentes. Lo que uno observa es que en la distribución azul los datos son más similares uno al otro y la distribución roja los valores son más diferentes. En el primer conjunto de datos se usa 500 valores con un promedio de 100 y una desviación estándar de 10, en el segundo se produce un conjunto de datos de 500 valores con un promedio de 100 y una desviación estándar de 30. Code set.seed(8690) # esto es para que los valores se queda igual a cada vez que se corre el analisis a=rnorm(5000, 100, 10) # la función para generar datos al azar con una distribución normal dfa=data.frame(a) head(dfa, n=10) ## a ## 1 122.45061 ## 2 96.32812 ## 3 97.62805 ## 4 104.08504 ## 5 87.87156 ## 6 96.03265 ## 7 95.25282 ## 8 93.10139 ## 9 120.29985 ## 10 110.93526 Code # r is for random # norm =distribución normal #a b=rnorm(500, 100, 50) dfb=data.frame(b) Code library(ggplot2) ggplot(dfa, aes(a))+ geom_density(fill=&quot;blue&quot;)+ geom_density(dfb, mapping=aes(b,fill=&quot;red&quot;, alpha=.5 ))+ theme(legend.position = &quot;none&quot;) + geom_vline(aes(xintercept = 100, colour=&quot;red&quot;)) Code ggsave(&quot;Graficos/dispersion.png&quot;) 7.3 El rango El rango son los valores mínimo y valor máximo de un conjunto de datos. Se usa la función range(). Usamos los dos conjuntos de datos ya creado anteriormente para visualizar los rangos de la distribuciones de los gráficos. Lo que uno observa es que el valor mínimo del primer conjunto de datos es 59.17 y el máximo es 137.12. Para el segundo conjunto de datos el valor mínimo es 1.86 y el máximo es 203.88. Code range(dfa$a) ## [1] 67.77126 133.87095 Code range(dfb$b) ## [1] -80.68499 251.11763 7.4 Mínimo y máximo El rango de una distribución es lo mismo que el minimo y maximo Code min(dfa$a) ## [1] 67.77126 Code max(dfa$a) ## [1] 133.8709 Code min(dfa$b) ## [1] Inf Code max(dfa$b) ## [1] -Inf 7.5 Ejemplo de la clase 7.5.1 Cual es el rango de la Edad de los padres de los Estudiantes Code Edad=c(57,50,43,39,54,50,59,49, 57,51,43,47) Edad ## [1] 57 50 43 39 54 50 59 49 57 51 43 47 Code Edad_df=data.frame(Edad) Edad_df ## Edad ## 1 57 ## 2 50 ## 3 43 ## 4 39 ## 5 54 ## 6 50 ## 7 59 ## 8 49 ## 9 57 ## 10 51 ## 11 43 ## 12 47 Code range(Edad) ## [1] 39 59 Code range(Edad_df$Edad) ## [1] 39 59 Code Dist_V=c(14, 71, 16, 43, 32, 17.1, 11, 53, 16.2, 47, 18.2, 39, 9, 16.2) df=data.frame(Dist_V) # para poner los datos un un data frame df ## Dist_V ## 1 14.0 ## 2 71.0 ## 3 16.0 ## 4 43.0 ## 5 32.0 ## 6 17.1 ## 7 11.0 ## 8 53.0 ## 9 16.2 ## 10 47.0 ## 11 18.2 ## 12 39.0 ## 13 9.0 ## 14 16.2 Caluclar la varianza Code var(df$Dist_V) ## [1] 359.3963 Desviación estandard Code sd(df$Dist_V) ## [1] 18.95775 Error estandard Code error_e= sd(df$Dist_V)/sqrt(length(df$Dist_V)) error_e ## [1] 5.066672 95% de la distribución Code Limite_inferior_a=mean(df$Dist_V)-(error_e*1.96) Limite_superior_a=mean(df$Dist_V)+(error_e*1.96) Limite_inferior_a ## [1] 18.83361 Code Limite_superior_a ## [1] 38.69496 7.6 La varianza Los pasos para calcular la varianza son los siguientes tener un conjunto de datos, aquí lo llamamos Data convertir esta lista en un data frame Calcular el promedio de los datos restar el promedio de cada valor y cuadralos Sumar y restas de n-1, done n es la cantidad de datos el numerador se llama la suma de los cuadrados = SS \\[{ s }^{ 2 }=\\frac { \\sum { { ({ x }_{ i }-\\bar { x } })^{ 2 } } }{ n-1 }=\\frac{SS}{n-1}\\] Code library(tidyverse) Data=c(1,2,3,4,5,6) Data_df=data.frame(Data) Data_df ## Data ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 Code Data_df$mean_Data=mean(Data) # Aqui se añade el promedio a cada fila Data_df ## Data mean_Data ## 1 1 3.5 ## 2 2 3.5 ## 3 3 3.5 ## 4 4 3.5 ## 5 5 3.5 ## 6 6 3.5 Code Data_df$Diff=Data_df$Data-Data_df$mean_Data # Calcular la diferencia entre el promedio y el valor x sum(Data_df$Diff) # si los valores no se cuadra la suma sera zero. ## [1] 0 Code Data_df$SS=(Data_df$Data-Data_df$mean_Data)^2 # SS para la suma de los cuadrados Data_df ## Data mean_Data Diff SS ## 1 1 3.5 -2.5 6.25 ## 2 2 3.5 -1.5 2.25 ## 3 3 3.5 -0.5 0.25 ## 4 4 3.5 0.5 0.25 ## 5 5 3.5 1.5 2.25 ## 6 6 3.5 2.5 6.25 Code sum(Data_df$SS) ## [1] 17.5 7.6.1 Este indice se llama la desviación del promedio que es la suma de los cuadrados 7.7 Calcular la varianza con var() Ahora la manera fácil de hacer los análisis, usar la función var, y no hay que hacer ninguno de los pasos anteriores. Pero es importante que sepa como es el procedimiento de calcular la varianza. Nota que la varianza es un indice de la diferencia entre el promedio y cada valor. El otro paso es que los valores tienen que estar cuadrada las diferencias sino la suma sera de cero. Se usa el variancas cuando tenemos confianzas que los datos provienen de una distribución normal y que los datos que uno tiene no están sesgados. Code var(Data) ## [1] 3.5 7.8 La desviación estandar La varianza es un indice que no esta en la misma unidad que los valores recolectado, por ejemplo si se recolecta los datos en centímetros, la varianza es en centímetros cuadrados. Por consecuencia no es necesariamente el mejor para describir la dispersión. Entonces hay que sacar la raíz cuadra de la varianza. La desviación estándar es un indice que se usa para describir la dispersión de una población, en otra palabra cuan diferentes son los datos uno del otro. Se usa el desviación estándar cuando tenemos confianzas que los datos provienen de una distribución normal y que los datos que uno tiene no están sesgados. \\[{ s }=\\sqrt { \\frac { \\sum { { ({ x }_{ i }-\\bar { x } })^{ 2 } } }{ n-1 } }\\] o más sencillo \\[s=\\sqrt{s^2}\\] la función sd, “standard deviation” es sumamente facil de calcular en R. Code sd(Data_df$Data) # deviación estandard ## [1] 1.870829 7.9 El rango intertcuartil. La función básica es quantile si lo dejamos sin más instrucción calcula los siguientes probabilidades 0%, 25%, 50% (mediana), 75%, 100%. Pero si uno quiere los valores que se encuentra en una posición especifica hay que usar type =1 como se ve en el segundo ejemplo. Hay 9 tipos de cuantiles con esta función, estos se encuentra definido en RStudio. Añade quantile en el artea de help y vera las otras alternativas. Code quantile(Data) # la función básica (0%, 25%, 50% (mediana), 75%, 100%) ## 0% 25% 50% 75% 100% ## 1.00 2.25 3.50 4.75 6.00 Code # Seleccionar los cuantiles específicos. quantile(Data, probs = c(0.025, 0.25, 0.50,.75, .975)) ## 2.5% 25% 50% 75% 97.5% ## 1.125 2.250 3.500 4.750 5.875 Para explicar estos conceptos mejor visualizamos los datos i x[i] Mediana Cuartiles 1 03 2 19 3 27 4 33 Q1=33 5 52 6 60 7 77 8 87 Q2=87 9 99 10 101 11 122 12 137 Q3=137 13 140 14 142 15 150 Ahora usamos la función quantile con el type=1 de calcular los cuartiles y ver si tenemos los mismos resultados. Code dat=c(3,19,27,33,52,60,77,87,99,101,122,137,140,142,150) quantile(dat, type =1) ## 0% 25% 50% 75% 100% ## 3 33 87 137 150 Code sd(dat) ## [1] 49.2145 7.10 El error estandard El termino correcto es el error de las desviación estándar pero típicamente acortado a error estándar. El indice de error estándar es para describir cual es la posible dispersión del promedio. En otra palabra cuan confiado estamos con el estimado del promedio. Más grande el error estándar menos confiado estamos con el promedio. Se usa el error estándar cuando tenemos confianzas que los datos provienen de una distribución normal y que los datos que uno tiene no están sesgados. La formula de error estándar es la siguiente usando la desviación estándar \\[s_{\\overline{x}}=\\frac{s}{\\sqrt{n}}\\] o usando la varianza, donde la n es la cantidad de datos \\[s_{\\overline{x}}=\\sqrt{\\frac{s^2}{n}}\\] Ahora si usamos los datos enseñado al principio del modulo. Calculamos error estándar de ambas distribución. er= error estándar. No hay función en R para calcular el error estándar, por consecuencia hay que crear la formula para calcular el indice. Vemos que cuando hay más dispersión el error estándar es más grande. Code length(dfa$a) ## [1] 5000 Code es_a= sd(dfa$a)/sqrt(length(dfa$a)) es_b= sd(dfb$b)/sqrt(length(dfb$b)) es_a ## [1] 0.1405601 Code es_b ## [1] 2.204251 7.11 El intervalo de confianza de 95% del promedio Ya que hemos calculado el error estándar podemos calcular la dispersión de los promedios. Esto quiere decir que si uno repite la recolección de datos el promedio tiene un 95% de probabilidad estar en este rango. Uno calcula los limites de la dispersión de los promedios usando la siguientes formulas. \\[Limite\\ 95\\%\\ ariba=\\ \\overline{x}\\ +\\left(ES\\ \\cdot\\ 1.96\\right)\\] \\[Limite\\ 95\\%\\ abajo=\\ \\overline{x}\\ -\\left(ES\\ \\cdot\\ 1.96\\right)\\] Code Limite_inferior_a=mean(dfa$a)-(es_a*1.96) Limite_superior_a=mean(dfa$a)+(es_a*1.96) Limite_inferior_a # limite inferior 95% ## [1] 99.73334 Code mean(dfa$a) # El promedio ## [1] 100.0088 Code Limite_superior_a # el limite superior 95% ## [1] 100.2843 Code Limite_inferior_b=mean(dfb$b)-(es_b*1.96) Limite_superior_b=mean(dfb$b)+(es_b*1.96) mean_b=mean(dfb$b) Limite_inferior_b ## [1] 94.81576 Code mean(dfb$b) ## [1] 99.13609 Code Limite_superior_b ## [1] 103.4564 Visualizando el intervalos de confianza del promedio. Lo que uno observa es que primero el promedio puede ser en localidad diferentes porque el conjunto de datos fue menos en el segundo gráfico. Además vemos que el intervalo de 95% de confianza del promedio en el segundo es más amplio. Code CI_a1=ggplot(dfa, aes(a))+ geom_histogram(fill=&quot;blue&quot;, colour=&quot;white&quot;,alpha=.5, binwidth = 2)+ theme(legend.position = &quot;none&quot;) + geom_vline(aes(xintercept = 100), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = Limite_inferior_a), colour=&quot;black&quot;)+ geom_vline(aes(xintercept = Limite_superior_a), colour=&quot;black&quot;) ggsave(&quot;Graficos/CI_a1.png&quot;) Code CI_b=ggplot(dfb, aes(b))+ geom_histogram(fill=&quot;blue&quot;, colour=&quot;white&quot;, alpha=.5, binwidth = 5)+ theme(legend.position = &quot;none&quot;) + geom_vline(aes(xintercept =mean_b), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = Limite_inferior_b), colour=&quot;black&quot;)+ geom_vline(aes(xintercept = Limite_superior_b), colour=&quot;black&quot;) ggsave(&quot;Graficos/CI_b.png&quot;) Code #library(easyGgplot2) #ggplot2.multiplot(CI_b.png,CI_b.png, cols=2) 7.12 El intervalos de confianza de los datos Para tener una idea de la distribución de los datos y cual es el porcentaje de valores que esté incluido (asumiendo una distribución normal). Podemos crear un gráfico que demuestra el porcentaje incluidos basado en la desviación estándar. Nota aquí no es la dispersión del promedio pero la dispersión de los datos en la población. 7.13 Rangos incluidos en intervalos de confianza Cálculos el promedio y la desviación estándar de los datos. Lo haremos por genero. Si uno calcula el rango de promedio ± 1 sd, esto incluye 68.2% de los datos, si incluimos el promedio ± 2 sd incluye 95.6% de los datos, Rangos incluidos en intervalos de confianza sd rango inluido 0 el promedio ±1 68.2% ±2 95.6% ±3 99.7% ±4 99.99% 7.14 Ejemplo del intervalo de confianza 7.14.1 El intervalo de confianza de colesterol en los Iranis Comenzamos con evaluar el intervalo de confianza de los datos con datos teóricos. Por ejemplo el nivel de colesterol en el plasma varia en los humanos. En el siguiente articulo Plasma total cholesterol level and some related factors in northern Iranian people. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3783780/ Usamos los datos para las mujeres con un promedio de 196.7 y una desviación estándar de 39.11. Con estos datos asumimos que esto provienen de una distribución normal y que representa las mujeres en resto del mundo. Code # Creamos un conjunto de datos para los análisis Col=rnorm(200000, 196.7, 39.11) Col=data.frame(Col) promCol=Col%&gt;% summarise(Mean=mean(Col)) sdCol=Col%&gt;% summarise(sd=sd(Col)) Visualizar los datos: Uds conoce su nivel de colesterol total? Donde se encuentra en esta distribución? Se encuentra en el 68%? Nota que la suma de todos los porcentaje es igual a 100%. Code library(grid) library(gtable) lims &lt;- c(28, 350) breaks.major2&lt;-c(0, 79, 118, 157, 197, 235, 274, 314) breaks.minor2= c(79, 118, 157,197, 235, 274, 314,379) breaks.comb &lt;- sort(c(breaks.major2, breaks.minor2-1.0E-6)) labels.comb&lt;- c(0, 79, &quot;\\n-3sd&quot;, 118, &quot;\\n-2sd&quot;, 157, &quot;\\n-1sd&quot;, 197, &quot;\\npromedio&quot;, 235, &quot;\\n+1sd&quot;,274, &quot;\\n+2sd&quot;, 314,&quot;\\n+3sd&quot;, 379) Code Colesterol_Inter=Col%&gt;% ggplot(aes(Col))+ geom_histogram(fill=&quot;blue&quot;, colour=&quot;white&quot;,alpha=.5, binwidth = 5)+ theme(legend.position = &quot;none&quot;)+ geom_vline(xintercept=as.numeric(promCol), colour=&quot;black&quot;)+ geom_vline(aes(xintercept = as.numeric(promCol-sdCol)), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = as.numeric(promCol+sdCol)), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = as.numeric(promCol-2*sdCol)), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = as.numeric(promCol+2*sdCol)), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = as.numeric(promCol-3*sdCol)), colour=&quot;orange&quot;)+ geom_vline(aes(xintercept = as.numeric(promCol+3*sdCol)), colour=&quot;orange&quot;)+ scale_x_continuous(expand=c(0,0), limit=lims, minor_breaks=breaks.minor2, breaks=breaks.comb, labels=labels.comb)+ xlab(&quot;Nivel de colesterol&quot;)+ annotate(&quot;text&quot;, x=180, y = 10000, label=&quot;34.1%&quot;)+ annotate(&quot;text&quot;, x=210, y = 10000, label=&quot;34.1%&quot;)+ annotate(&quot;text&quot;, x=140, y = 10000, label=&quot;13.6%&quot;)+ annotate(&quot;text&quot;, x=250, y = 10000, label=&quot;13.6%&quot;)+ annotate(&quot;text&quot;, x=90, y = 10000, label=&quot;2.1%&quot;)+ annotate(&quot;text&quot;, x=295, y = 10000, label=&quot;2.1%&quot;)+ annotate(&quot;text&quot;, x=70, y = 10000, label=&quot;0.1%&quot;)+ annotate(&quot;text&quot;, x=330, y = 10000, label=&quot;0.1%&quot;) Colesterol_Inter Code ggsave(&quot;Graficos/Colesterol_Inter.png&quot;) 7.15 Otro ejemplo de los intevalos de confianzas 7.15.1 La altura de los humanos Para evaluar el 95% de intervalo de confianza usaremos datos de la alturas de 500 adultos. Estos datos fueron bajado del siguiente website. Están disponible en debajo la pestaña de “Los Datos”. https://www.kaggle.com/yersever/500-person-gender-height-weight-bodymassindex/data Code library(readr) library(gt) Alturas_Humanos &lt;- read_csv(&quot;Data_files_csv/Alturas_Humanos.csv&quot;) gt(head(Alturas_Humanos)) #fzkzxgcbyu table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #fzkzxgcbyu thead, #fzkzxgcbyu tbody, #fzkzxgcbyu tfoot, #fzkzxgcbyu tr, #fzkzxgcbyu td, #fzkzxgcbyu th { border-style: none; } #fzkzxgcbyu p { margin: 0; padding: 0; } #fzkzxgcbyu .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #fzkzxgcbyu .gt_caption { padding-top: 4px; padding-bottom: 4px; } #fzkzxgcbyu .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #fzkzxgcbyu .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #fzkzxgcbyu .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fzkzxgcbyu .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fzkzxgcbyu .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #fzkzxgcbyu .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #fzkzxgcbyu .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #fzkzxgcbyu .gt_column_spanner_outer:first-child { padding-left: 0; } #fzkzxgcbyu .gt_column_spanner_outer:last-child { padding-right: 0; } #fzkzxgcbyu .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #fzkzxgcbyu .gt_spanner_row { border-bottom-style: hidden; } #fzkzxgcbyu .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #fzkzxgcbyu .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #fzkzxgcbyu .gt_from_md > :first-child { margin-top: 0; } #fzkzxgcbyu .gt_from_md > :last-child { margin-bottom: 0; } #fzkzxgcbyu .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #fzkzxgcbyu .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #fzkzxgcbyu .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #fzkzxgcbyu .gt_row_group_first td { border-top-width: 2px; } #fzkzxgcbyu .gt_row_group_first th { border-top-width: 2px; } #fzkzxgcbyu .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fzkzxgcbyu .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #fzkzxgcbyu .gt_first_summary_row.thick { border-top-width: 2px; } #fzkzxgcbyu .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fzkzxgcbyu .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #fzkzxgcbyu .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #fzkzxgcbyu .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #fzkzxgcbyu .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #fzkzxgcbyu .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #fzkzxgcbyu .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fzkzxgcbyu .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fzkzxgcbyu .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #fzkzxgcbyu .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #fzkzxgcbyu .gt_left { text-align: left; } #fzkzxgcbyu .gt_center { text-align: center; } #fzkzxgcbyu .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #fzkzxgcbyu .gt_font_normal { font-weight: normal; } #fzkzxgcbyu .gt_font_bold { font-weight: bold; } #fzkzxgcbyu .gt_font_italic { font-style: italic; } #fzkzxgcbyu .gt_super { font-size: 65%; } #fzkzxgcbyu .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #fzkzxgcbyu .gt_asterisk { font-size: 100%; vertical-align: 0; } #fzkzxgcbyu .gt_indent_1 { text-indent: 5px; } #fzkzxgcbyu .gt_indent_2 { text-indent: 10px; } #fzkzxgcbyu .gt_indent_3 { text-indent: 15px; } #fzkzxgcbyu .gt_indent_4 { text-indent: 20px; } #fzkzxgcbyu .gt_indent_5 { text-indent: 25px; } Genero Altura_cm Peso_kg Hombres 174 96 Hombres 189 87 Mujer 185 110 Mujer 195 104 Hombres 149 61 Hombres 189 104 Calculamos los promedios y las desviación estándar para añadirlos al gráfico Code library(tidyverse) head(Alturas_Humanos) ## # A tibble: 6 × 3 ## Genero Altura_cm Peso_kg ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Hombres 174 96 ## 2 Hombres 189 87 ## 3 Mujer 185 110 ## 4 Mujer 195 104 ## 5 Hombres 149 61 ## 6 Hombres 189 104 Code length(Alturas_Humanos$Genero) ## [1] 500 Code # Parametros para las Mujeres promM=Alturas_Humanos%&gt;% dplyr::select(Genero, Altura_cm)%&gt;% filter(Genero==&quot;Mujer&quot;)%&gt;% summarise(MeanM=mean(Altura_cm)) promM ## # A tibble: 1 × 1 ## MeanM ## &lt;dbl&gt; ## 1 170. Code sdM=Alturas_Humanos%&gt;% dplyr::select(Genero, Altura_cm)%&gt;% filter(Genero==&quot;Mujer&quot;)%&gt;% summarise(sd=sd(Altura_cm)) sdM ## # A tibble: 1 × 1 ## sd ## &lt;dbl&gt; ## 1 15.7 Code # Parametros para las Hombres promH=Alturas_Humanos%&gt;% dplyr::select(Genero, Altura_cm)%&gt;% filter(Genero==&quot;Hombres&quot;)%&gt;% summarise(Mean=mean(Altura_cm)) sdH=Alturas_Humanos%&gt;% dplyr::select(Genero, Altura_cm)%&gt;% filter(Genero==&quot;Hombres&quot;)%&gt;% summarise(sd=sd(Altura_cm)) Aquí el gráfico de la distribución de los datos con un histograma, y promedio (negro), el rango de 68% entre las barras azules y el de 95% entre las barras roja. Code Alturas_Mujer=Alturas_Humanos%&gt;% dplyr::select(Genero, Altura_cm)%&gt;% filter(Genero==&quot;Mujer&quot;)%&gt;% ggplot(aes(Altura_cm))+ geom_histogram(fill=&quot;blue&quot;, colour=&quot;yellow&quot;,alpha=.5)+ theme(legend.position = &quot;none&quot;)+ geom_vline(xintercept=as.numeric(promM), colour=&quot;black&quot;)+ geom_vline(aes(xintercept = as.numeric(promM-sdM)), colour=&quot;blue&quot;, size=1)+ geom_vline(aes(xintercept = as.numeric(promM+sdM)), colour=&quot;blue&quot;)+ geom_vline(aes(xintercept = as.numeric(promM-2*sdM)), colour=&quot;red&quot;)+ geom_vline(aes(xintercept = as.numeric(promM+2*sdM)), colour=&quot;red&quot;) ggsave(&quot;Graficos/Alturas_Mujer.jpeg&quot;) # .png, .tiff, etc 7.16 Ejercicios de practica para entender el concepto de Medidas de dispersión 7.16.1 Ejercicio 1: Ahora prepara el mismo gráfico para los hombres. 7.16.2 Ejercicio 2: Calcula los siguientes indices de dispersión el rango la varianza la desviación estándar el error estándar el rango intercuartil el intervalo de confianza de 95% La cantidad de pisos de los edificios más alto del mundo. 88, 88, 110, 88, 80, 69, 102, 78, 70, 55, 79, 85, 80, 100, 60, 90, 77, 55, 75, 55, 54, 60, 75, 64, 105, 56, 71, 70, 65, 72 "],["estadística-descriptiva.html", "Chapter 8 Estadística Descriptiva 8.1 Estadistica descriptiva 8.2 Analisis con muchos datos 8.3 Remover los NA del análisis 8.4 Resumen estadístico de una variable 8.5 Resumen Estadístico de multiples variables 8.6 Los Cuantiles 8.7 El indice de Oblicuidad: Skewness 8.8 El indice de Curtosis: Kurtosis", " Chapter 8 Estadística Descriptiva Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; Activar los Paquetes Code library(ggplot2) # paquete para visualizar los datos library(ggversa) # paquete para diferentes conjuntos de datos library(modeest) # paquete para calcular la moda library(pastecs) # paquete para análisis tiempo-espacial usado en ecología library(psych) # paquete para análisis psicométrica, psicológica y de personalidad library(knitr) # un grupo de función para incluyendo tablas bonitas con kable. library(tidyverse) library(gridExtra) library(e1071) 8.1 Estadistica descriptiva En los módulos de “Medidas de Tendencias Central” y “Medidas de Dispersión” se explicó donde proviene estos parámetros y como calcular estos. En este módulo aprenderemos diferentes funciones como calcular estos parámetros individualmente y herramienta como calcular todos y otros parámetros todo juntos. Los indices que veremos aquí incluye el promedio la mediana la desviación estándar el mínimo el máximo los cuantiles el indice Oblicuidad (en ingles “Skewness”) el indice de Curtosis ( en ingles “Kurtosis”) Aqui creamos un conjunto de datos de 100 datos con un promedio de 100 y una desviación estándar de 10. Nota que la función set.seed() es que el comienzo la simulación sea igual a cada vez que se corre, y se el mismo resultado. Esto se añade solamente cuando uno esta enseñando y que los resultados sean consistente. Code x=rnorm(100, 100, 10) #(100 datos, x=100, sd=10) x=data.frame(x) head(x) ## x ## 1 110.44564 ## 2 96.11388 ## 3 101.97822 ## 4 111.76182 ## 5 118.75482 ## 6 104.62023 Code mean(x$x) # el promedio ## [1] 100.0398 Code sd(x$x) # la desviación estándar ## [1] 9.932391 Code min(x$x) # el valor mínimo ## [1] 77.74019 Code max(x$x) # el valor máximo ## [1] 123.6114 Quiz 1: Usa R y construye una lista o data frame con los siguientes datos y calcular el promedio. Contesta en MSTeam Form con tu respuesta. 4, 6, 7, 3, 9, 10, 19, 52. 8.2 Analisis con muchos datos Usaremos datos que hemos visto en el modulo Producción de Gráficos. Se necesita el archivo DownloadFestival que se encuentra debajo la pestaña de Los Datos. El ejemplo proviene de Field et al. (2014). Una bióloga estaba preocupado por los posibles efectos sobre la salud de los que particpan a un festivales de música. Entonces, un año fue al Download Festival en el Reino Unido (Download Festival UK). Ella midió la higiene del los que participaron al concierto n= 810 durante el festival de 3 días. Cada día intentaba encontrar a todas las personas que censó el primer día. Los valores asignado fueron de 0 a 4 sobre el nivel de limpieza por como olia los participantes 0 = hueles como un cadáver. 4 = hueles a rosas dulces en un fresco día de primavera Code library(readr) DownloadFestival &lt;- read_csv(&quot;Data_files_csv/DownloadFestival.csv&quot;) dlf=DownloadFestival #usamos un nombre más corta para facilitar head(dlf) # ver las 3 primeras filas ## # A tibble: 6 × 5 ## ticknumb gender day1 day2 day3 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2111 Male 2.64 1.35 1.61 ## 2 2229 Female 0.97 1.41 0.29 ## 3 2338 Male 0.84 NA NA ## 4 2384 Female 3.03 NA NA ## 5 2401 Female 0.88 0.08 NA ## 6 2405 Male 0.85 NA NA 8.3 Remover los NA del análisis Con los datos de los participantes al festival como en algunos diá hay participantes donde no tienen los datos se añadió un NA, es estos casos para que el análisis se logra hay que añadir a la función na.rm=TRUE que significa remover la NA. Para dar se cuenta remueve na.rm=TRUE cuando se usa el “día2” o “día3”, y evalúa que pasa. Code mean(dlf$day2, na.rm=TRUE) # na.rm= na remove ## [1] 0.9609091 Code sd(dlf$day1, na.rm=TRUE) ## [1] 0.9444949 Code min(dlf$day1, na.rm=TRUE) ## [1] 0.02 Code max(dlf$day1, na.rm=TRUE) ## [1] 20.02 Code median(dlf$day1, na.rm=TRUE) ## [1] 1.79 8.4 Resumen estadístico de una variable Para ver los estadístico mencionado arriba (menos la moda, oblicuidad y curtosis) se puede usar la función stat.desc() del paquete pastecs. Para facilitar la lectura de los valores se usa la función “round(x, 3), el tres en esta caso representa la cantidad de valores significativos que se demuestra. Si no usamos round() los valores aparece en notación científicas. Nota que hay muchos más parámetros calculados. Aparece en la lista en orden el valor mínimo: min(), el valor máximo: max(), la mediana: median, el promedio: mean, la desviación estándar; std.dev entre otros. Code library(pastecs) stat.desc(dlf[,c(&quot;day1&quot;)]) ## day1 ## nbr.val 8.100000e+02 ## nbr.null 0.000000e+00 ## nbr.na 0.000000e+00 ## min 2.000000e-02 ## max 2.002000e+01 ## range 2.000000e+01 ## sum 1.452620e+03 ## median 1.790000e+00 ## mean 1.793358e+00 ## SE.mean 3.318617e-02 ## CI.mean.0.95 6.514115e-02 ## var 8.920705e-01 ## std.dev 9.444949e-01 ## coef.var 5.266627e-01 Code round(stat.desc(dlf[,c(&quot;day1&quot;)]), 2) ## day1 ## nbr.val 810.00 ## nbr.null 0.00 ## nbr.na 0.00 ## min 0.02 ## max 20.02 ## range 20.00 ## sum 1452.62 ## median 1.79 ## mean 1.79 ## SE.mean 0.03 ## CI.mean.0.95 0.07 ## var 0.89 ## std.dev 0.94 ## coef.var 0.53 8.5 Resumen Estadístico de multiples variables Si uno quiere evaluar múltiples variables continua todas juntos se puede usar la misma función pero el componente c() se añade todas las variables de interés. Code round(stat.desc(dlf[,c(&quot;day1&quot;,&quot;day2&quot;,&quot;day3&quot;)], basic=FALSE,norm=TRUE), digits=3) # round reduce a 3 valores significativo ## day1 day2 day3 ## median 1.790 0.790 0.760 ## mean 1.793 0.961 0.977 ## SE.mean 0.033 0.044 0.064 ## CI.mean.0.95 0.065 0.087 0.127 ## var 0.892 0.520 0.504 ## std.dev 0.944 0.721 0.710 ## coef.var 0.527 0.750 0.727 ## skewness 8.833 1.083 1.008 ## skew.2SE 51.407 3.612 2.309 ## kurtosis 168.967 0.755 0.595 ## kurt.2SE 492.314 1.265 0.686 ## normtest.W 0.654 0.908 0.908 ## normtest.p 0.000 0.000 0.000 Quiz 3: Usa R usa el data.frame Camas_Hospital en el paquete ggversa. Contesta en MSTeam Form con tu respuesta. Selecciona la variable Camas que representa el “número de camas por 1000 personas en muchos países. ¿Cual es el rango (range)? 8.6 Los Cuantiles Los cuantiles son los valores a intervalos específicos de una variable aleatoria continua. Los cuantiles son frecuentemente una mejor interpretación de la distribución cuando los valores no tienen una distribución normal. Típicamente, la distribución se divide en 4 partes con las siguientes partes (los cuantiles 0.25, 0.50 = la mediana, 0.75) y se define como cuartiles. Para meas detalle pueden ver el siguiente enlace https://en.wikipedia.org/wiki/Quantile. En el siguiente ejemplo se demuestra como tulizar la función quantiles y seleccionar los cuantiles deseados con el comopnente de probs=c(x,x,x). Code quantile(dlf$day1,probs=c(0.05, 0.1, 0.25, 0.5, 0.75, 0.95, 0.99), na.rm=TRUE) ## 5% 10% 25% 50% 75% 95% 99% ## 0.5945 0.8490 1.3125 1.7900 2.2300 2.9100 3.3200 Se puede usar también la función describe en el paquete pshych que le da automáticamente estos cuantiles. Code describe(dlf$day1) ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 810 1.79 0.94 1.79 1.77 0.7 0.02 20.02 20 8.83 168.97 0.03 8.7 El indice de Oblicuidad: Skewness El indice de oblicuidad es un indice que describe la simetría en una distribución alrededor de su promedio. Otra manera de describirlo es el tercer momento, por que los datos se poner a un exponente elevado al ^3. La formula es la siguiente. Lo que se darán cuenta es muy similar a la varianza pero note que las diferencias se poner al ^3. Para meas información vea este enlace https://en.wikipedia.org/wiki/Skewness. \\[\\frac{1}{N}\\sum_{i=}^N\\left(\\frac{x_i-\\overline{x}}{\\sigma}\\right)^3\\] Primero voy a crear tres conjuntos de datos con distribución normal oblicuidad a la izquierda oblicuidad a la derecha Code normal=rnorm(100000, .5, .15) obliz=rbeta(100000, 1.5,5) obldr=rbeta(100000, 5.5,2) normal=as.tibble(normal) obliz=as.tibble(obliz) obldr=as.tibble(obldr) Ahora unimos los data frames y se añade nombres a las columnas Code df=cbind(normal, obliz, obldr) head(df, n=2) ## value value value ## 1 0.3593956 0.1288732 0.5454791 ## 2 0.6649285 0.1578481 0.8598856 Code df &lt;- setNames(df, c(&quot;normal&quot;,&quot;obliz&quot;,&quot;obldr&quot;)) head(df, n=2) ## normal obliz obldr ## 1 0.3593956 0.1288732 0.5454791 ## 2 0.6649285 0.1578481 0.8598856 El próximo paso es apilar cada columna una sobre la otra. La razón que queremos esto es que deseamos reproducir las variables en un mismo gráfico Code library(tidyverse) df2=df%&gt;% gather(key = &quot;Distribución&quot;, value=&quot;valor&quot;, c(normal, obliz, obldr)) head(df2, n=3) ## Distribución valor ## 1 normal 0.3593956 ## 2 normal 0.6649285 ## 3 normal 0.5922829 Code # unique(df2$Distribución) # función para ver el nombre de las variables en la columna Distribución Ahora vamos a ver los datos un gráfico. Vemos que la distribución de los datos son muy diferentes, tanto la distribución en azul y verde están sesgado a unos valores y tienen una cola o valores más grande (azul) o pequeños (verde) que si fuese una distribución normal. Code ggplot(df2, (aes(valor, colour=Distribución)))+ geom_density()+ xlim(-.01,1) Code ggsave(&quot;Graficos/Skewness.png&quot;) Ahora se calcula el indice de oblicuidad y comparamos los valores. Como regla cuando el nivel de oblicuidad esta entre -0.5 y 0.5 se considera dentro de una distribución simétrica (normal). -1.0 y -0.5 o entre 0.5 y 1.o los valores tienen una oblicuidad moderada. Menor de -1.0 o mayor de 1.0 los datos tienen una oblicuidad grande. Ahora evaluamos la oblicuidad de los tres gráficos. se usa la función de skewness en el paquete e1071 Para los datos de una distribución normal el valor es muy cerca a cero. Para los datos sesgado a la izquierda el indice de oblicuidad es positivo y el sesgado a derecha es negativo. Code library(e1071) e1071::skewness(normal$value) # la oblicuidad de los datos de una distribución normal ## [1] 0.006368452 Code e1071::skewness(obliz$value) # la oblicuidad de los datos sesgado a la izquierda ## [1] 0.8262887 Code e1071::skewness(obldr$value) # la oblicuidad de los datos sesgado a la derecha ## [1] -0.6486796 8.8 El indice de Curtosis: Kurtosis El indice de curtosis es un índice que describe la cola de la una distribución alrededor de su promedio. Otra manera de describirlo es el cuarto momento, por que los datos se poner a un exponente elevado al ^4. El curtosis mide la propensidad de tener daos atípicos. La formula es la siguiente. Lo que se darán cuenta es muy similar a la varianza pero note que las diferencias se poner al ^4. Para más información vea este enlace https://www.wikiwand.com/en/Kurtosis. \\[\\frac{1}{N}\\sum_{i=}^N\\left(\\frac{x_i-\\overline{x}}{\\sigma}\\right)^4\\] Primero voy a crear cuatro conjuntos de datos con distribución normal con distribución normal, con cola reducida con distribución normal, con cola extendida distribución uniforme Code library(PearsonDS) library(rmutil) momentsR=c(mean=0, variance=1, skewness=0, kurtosis=2) momentsE=c(mean=0, variance=1, skewness=0, kurtosis=4) normalR=rpearson(100000, moments=momentsR) normalE=rpearson(100000, moments=momentsE) Unif=runif(100000, -2,2) normal=rnorm(100000, 0,1) laplace=rlaplace(500000, m=0, s=1) normal=as.tibble(normal) normalR=as.tibble(normalR) normalE=as.tibble(normalE) Unif=as.tibble(Unif) laplace=as.tibble(laplace) Ahora unimos los data frames y se añade nombres a las columnas Code df=cbind(normal, normalR, normalE, Unif, laplace) head(df, n=2) ## value value value value value ## 1 0.5988411 1.708884 -2.8346486 1.062104 -0.177971 ## 2 -0.5381463 -1.145072 0.2195933 -1.907250 -2.433041 Code df &lt;- setNames(df, c(&quot;normal&quot;,&quot;normalR&quot;,&quot;normalE&quot;, &quot;Unif&quot;, &quot;laplace&quot;)) head(df, n=2) ## normal normalR normalE Unif laplace ## 1 0.5988411 1.708884 -2.8346486 1.062104 -0.177971 ## 2 -0.5381463 -1.145072 0.2195933 -1.907250 -2.433041 El próximo paso es apilar cada columna una sobre la otra. La razón que queremos esto es que deseamos reproducir las variables en un mismo gráfico Code library(tidyverse) df2=df%&gt;% gather(key = &quot;Distribución&quot;, value=&quot;valor&quot;, c(normal, normalR, normalE, Unif, laplace)) head(df2, n=3) ## Distribución valor ## 1 normal 0.5988411 ## 2 normal -0.5381463 ## 3 normal 0.9216448 Code # unique(df2$Distribución) #función para ver el nombre de las variables en la columna Distribución Ahora vamos a ver los datos en un gráfico. Vemos que la distribución de los datos son muy diferentes, Tiene que concentrar no en el pico de la distribución pero las colas de los datos. Nota la distribución normal que es de color amarillo, y comparar si la colas están por debajo o por encima de esta distribución normal. Tanto la distribución uniforme (color rosa) y normal reducido (normalR, color azul) las curvas pasan de bajo la curva normal. Al contrarío la linea verde y roja son distribuciones que pasan por encima de la curva normal, entonces las colas son más predominante. Code whole=ggplot(df2, (aes(valor, colour=Distribución)))+ geom_density(adjust=5)+ xlim(-5,5) ggsave(&quot;Graficos/curtosis_whole.png&quot;) sub=ggplot(df2, (aes(valor, colour=Distribución)))+ geom_density()+ theme_bw() + scale_x_continuous(limits=c(-5, 1)) + scale_y_continuous(limits=c(0, .1)) + theme(legend.position= &quot;none&quot;) ggsave(&quot;Graficos/curtosis.png&quot;) sub + annotation_custom( ggplotGrob(whole), xmin = -1.8, xmax = 1.4, ymin = 0.005, ymax = 0.075) Ahora se calcula el indice de curtosis y comparamos los valores. Como regla el nivel de curtosis esta significativo si los valores de curtosis se enuentra en los siguientes rangos, y se acerca cero no hay curtosis (lo que uno espera para una distribución normal. Menor de -1.0 los datos están muy aplanados (Uniforme, normalR). Mayor de 1.0 (la distribución de Laplace). Ahora evaluamos la oblicuidad de los tres gráficos. se usa la función de kurtosis en el paquete e1071 Para los datos de una distribución normal el valor es muy cerca a cero. Para los datos que tienen exceso de cola el valor de curtosis es negativos y cuando el valor de curtosis es positivo hay exceso de datos en la cola. Code library(e1071) e1071::kurtosis(normal$value) # curtosis de los datos de una distribución normal ## [1] -0.009931754 Code e1071::kurtosis(normalR$value) # curtosis de los datos restringido ## [1] -1.008095 Code e1071::kurtosis(normalE$value) # curtosis de los datos con más colas ## [1] 1.142044 Code e1071::kurtosis(Unif$value) # curtosis de distribución informe, falta de colas ## [1] -1.203061 Code e1071::kurtosis(laplace$value) # curtosis de distribución Laplace, exceso de colas ## [1] 3.058468 Quiz 1 Quiz 2 Quiz 3 Code dfNormal=data.frame(data=rnorm(1000000)) head(dfNormal) ## data ## 1 0.6659112 ## 2 1.5452524 ## 3 1.0483245 ## 4 0.6581135 ## 5 1.2423059 ## 6 -1.4123176 Code ggplot(dfNormal, aes(data))+ geom_histogram(colour=&quot;white&quot;, fill=&quot;orange&quot;)+ xlim(-4, 4) Code ggsave(&quot;Normal.png&quot;) "],["gráficos.html", "Chapter 9 Gráficos 9.1 Gráficos Básicos con ggplot2 9.2 Como crear una gráfica de regresión lineal usando ggplot 9.3 Regresión lineal 9.4 Añadiendo color por grupo y otras bellezas 9.5 Salvar gráficos con ggsave 9.6 Regresión simple con puntos 9.7 Regresión simple con puntos y intervalo de confianza 9.8 Regresión lineal por grupo. 9.9 Histogramas 9.10 Gráficos de caja box plots 9.11 Gráfico de caja por grupo 9.12 Detección valores sesgados o átipicos. 9.13 Gráficos de línea y intervalo de errores 9.14 La función stat_summary para calcular indices sumativos. 9.15 Diagrama de tallo y hoja", " Chapter 9 Gráficos Code library(ggplot2) 9.1 Gráficos Básicos con ggplot2 Este modulo es una introducción corta para la visualización de los datos. El paquete principal que se usa es el ggplot2. La visualización de datos es un área especializado y no se podrá hacer justicia al tema al mismo tiempo que se estudia la estadística. Aquí se presenta es una introducción breve del tema. La visualización ayuda a entender los datos ya que la dispersión de ellos impacta que prueba se puede utilizar y el significado de los analisis. La información utilizada en este documento proviene en parte del libro Discovering Statistics using R por Andy Field, Jeremy Miles y Zoë Field (2014). 9.2 Como crear una gráfica de regresión lineal usando ggplot Subir los datos “Exam Anxiety” Los archivos de datos que se usan en el libro se encuentran en este enlace, https://studysites.sagepub.com/dsur/study/articles.htm Seleccionar el archivo Exam Anxiety. Note que los datos a la hoja de datos tienen que abrirlo en Excel o otro programa y salvarlo en formato .csv antes de seguir los proximos pasos. El siguiente paso es poner el archivo de datos en su proyecto de RStudio. *** ## Subir los datos a RStudio Code library(readr) Exam_Anxiety &lt;- read_csv(&quot;Data_files_csv/Exam Anxiety.csv&quot;) Para visualizar las primeras y ultimas 6 filas usar head() y tail() respectivamente. Code head(Exam_Anxiety) ## # A tibble: 6 × 5 ## Code Revise Exam Anxiety Gender ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 4 40 86.3 Male ## 2 2 11 65 88.7 Female ## 3 3 27 80 70.2 Male ## 4 4 53 80 61.3 Male ## 5 5 4 40 89.5 Male ## 6 6 22 70 60.5 Female Code tail(Exam_Anxiety) ## # A tibble: 6 × 5 ## Code Revise Exam Anxiety Gender ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 98 23 70 75.8 Male ## 2 99 13 55 71.0 Female ## 3 100 14 75 78.2 Female ## 4 101 1 2 82.3 Male ## 5 102 9 40 79.0 Male ## 6 103 20 50 91.1 Female Parta ver el nombre de las variables en el archivo se usa la función names. Vemos que hay cinco columnas, el Code que se refiere a un código que identifica el estudiante, Revise el tiempo que el estudiante estudio antes de tomar el examen, Exam la nota del estidiante, Anxiety, un indice de anxiedad antes de tomar el examen, Gender el genero del estudiante. Code names(Exam_Anxiety) ## [1] &quot;Code&quot; &quot;Revise&quot; &quot;Exam&quot; &quot;Anxiety&quot; &quot;Gender&quot; 9.3 Regresión lineal El primer gráfico es crear una regresión lineal. Para producir una regresión lineal se necesita dos variables con datos continuos Seleccionamos dos variables continua, el nivel de ansiedad y la nota del examen. Para hacer una regresión lineal que sigue el patrón de y=mx+b, hay que utilizar la función geom_smooth(method=lm), la función lm se refiere a modelo lineal o ingles linear model. Nota que con el programa ggplot2, hay que primero identificar de donde proviene los datos Exam_Anxiety, despúes que hay identificar cual; son las variables de este archivo que se van a utilizar, en este caso y=Exam, x=Anxiety. El proximoo paso es determinar que tipo de gráfico, y este caso es una regresión lineal. Code ggplot(Exam_Anxiety, aes(y=Exam, x=Anxiety))+ geom_smooth(method=lm, colour=&quot;red&quot;)+ geom_point()# linear model 9.4 Añadiendo color por grupo y otras bellezas En este archivo utilizaremos un archivo que se usa muy comúnmente en los análisis de R, para demostrar un análisis o como hacer gráfico. El archivo se llama iris y contiene información sobre el tamaño de características florales de tres especies del genero Iris. En este gráfico se añade cuatro componente suplementarios, 1) un puntos para cada par de valores Sepal.Length, Petal.Length, 2) se cambia los nombres de las leyendas en y y x con la función labs() = labels, 3) se añade un titulo al gráfico con ggtitle(), 4) Note que cada especies tiene un color distinto, esto fue muy fácil incluir añadiendo la función col=Species, lo que esto significa es que para cada especies de planta se pone un color diferente. Code tail(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 145 6.7 3.3 5.7 2.5 virginica ## 146 6.7 3.0 5.2 2.3 virginica ## 147 6.3 2.5 5.0 1.9 virginica ## 148 6.5 3.0 5.2 2.0 virginica ## 149 6.2 3.4 5.4 2.3 virginica ## 150 5.9 3.0 5.1 1.8 virginica Code ggplot(iris, aes(Sepal.Length, Petal.Length,colour=Species)) + geom_point(aes(col = Species)) + geom_smooth(method=&quot;lm&quot;) + labs(x = &quot;El largo del Sepalo&quot;, y = &quot;El largo del Petalo&quot;)+ ggtitle(&quot;Basic geom_point and linear regression&quot;)+ rlt_theme 9.5 Salvar gráficos con ggsave Como salvar un gráfico para usarlo en otros programados o presentación por ejemplo de MS Power Point. Se usa la función ggsave(). se pone en comilla el nombre que se quiere dar a la figura y se identifica que tipo de archivo se quiere crear, por ejemplo (.tiff, .png, .pdf). Nota que se salvo en un archivo que se llama “Graficos”, es no es necesario, si no lo incluye sera salvado en el proyecto. Code ggsave(&quot;Iris_size.png&quot;) # .tiff, .png, .jpeg, .jpg 9.6 Regresión simple con puntos Code scatter &lt;- ggplot(Exam_Anxiety, aes(Anxiety, Exam)) scatter + geom_point(shape=20, colour=&quot;red&quot;) + geom_smooth(method = &quot;lm&quot;, colour = &quot;blue&quot;, se = F) + # se = F, remueve el intervalo de confianza labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) 9.7 Regresión simple con puntos y intervalo de confianza Code scatter &lt;- ggplot(Exam_Anxiety, aes(Anxiety, Exam)) scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;Red&quot;)+ labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) 9.7.1 Cambio de color del intervalo de confianza Code scatter &lt;- ggplot(Exam_Anxiety, aes(Anxiety, Exam)) scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;Red&quot;, alpha = 0.2, fill = &quot;orange&quot;) + labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) 9.8 Regresión lineal por grupo. Para separar y tener una linea por grupo se usa la función colour y se añade la variable de factor. En este caso la variable Gender para separar entre hombres y mujer. Se enseña también la función ggtitle() para añadir un titulo al gráfico. Code ggplot(Exam_Anxiety, aes(y=Exam, x=Anxiety, colour=Gender))+ geom_point(colour=&quot;coral&quot;)+ geom_smooth(method=&quot;lm&quot;) + # lm (linear model) es para modelos lineales labs(x = &quot;Exam Anxiety Score&quot;, y = &quot;Exam Performance %&quot;)+ ggtitle(&quot;Basic geom_point and linear regression&quot;) 9.9 Histogramas Un histograma es un gráfico que representa la frecuencia de los valores de un conjunto de datos. pro consecuencia es el eje de x se encuentra una variable continua y en el eje de y la frecuencia. La frecuencia es lo mismo que el cantidad de veces que aparece los valores en x en el conjunto de datos. Se necesita el archivo DownloadFestival que se encuentra debajo la pestaña de Los Datos. El ejemplo proviene de Field et al. (2014). Una bióloga estaba preocupado por los posibles efectos sobre la salud de los que particpan a un festivales de música. Entonces, un año fue al Download Festival en el Reino Unido (Download Festival UK). Ella midió la higiene del los que participaron al concierto n= 810 durante el festival de 3 días. Cada día intentaba encontrar a todas las personas que censó el primer día. Los valores asignado fueron de 0 a 4 sobre el nivel de limpieza por como olia los participantes + 0 = hueles como un cadáver. + 4 = hueles a rosas dulces en un fresco día de primavera La hipótesis es que la higiene personal de los asistentes al concierto disminuiría dramáticamente durante los 3 días del festival. Code library(readr) DownloadFestival &lt;- read_csv(&quot;Data_files_csv/DownloadFestival.csv&quot;) FD=DownloadFestival Construyendo histogramas y detectando valores atípicos. Nota los valores NA, estos son los participantes que no se pudieron encontrar en los siguientes días. Code head(FD, n=2) ## # A tibble: 2 × 5 ## ticknumb gender day1 day2 day3 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2111 Male 2.64 1.35 1.61 ## 2 2229 Female 0.97 1.41 0.29 Code tail(FD) ## # A tibble: 6 × 5 ## ticknumb gender day1 day2 day3 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4749 Female 0.52 NA NA ## 2 4756 Female 2.91 0.94 NA ## 3 4758 Female 2.61 1.44 NA ## 4 4759 Female 1.47 NA NA ## 5 4760 Male 1.28 NA NA ## 6 4765 Female 1.26 NA NA Nota que aquí vemos el resultado, y encontramos un problema. Hay participantes que tienen valores que no son entre 0 y 4, que es la escala de higiene. Aunque es difícil ver, pero debido que el gráfico se extiende mayor de 4, es un indice de un problema ya que sabemos que los valores pueden estar solamente entre 0 y 4. Code ggplot(FD, aes(day1))+ geom_histogram(colour=&quot;white&quot;, fill=&quot;steelblue&quot;) + labs(x = &quot;Hygiene (Day 1 of Festival)&quot;, y = &quot;Frequency&quot;) Evaluar los datos resumidos, para detectar porque el gráfico se extiende a valores mayor de 4. Nota que el día 1, el valor máximo es de 20. Este probablemente fue un error de poner los datos un la hoja de Excel. Lo que se puede hacer es remover este participante del analisis. Code summary(DownloadFestival) ## ticknumb gender day1 day2 ## Min. :2111 Length:810 Min. : 0.020 Min. :0.0000 ## 1st Qu.:3096 Class :character 1st Qu.: 1.312 1st Qu.:0.4100 ## Median :3620 Mode :character Median : 1.790 Median :0.7900 ## Mean :3616 Mean : 1.793 Mean :0.9609 ## 3rd Qu.:4155 3rd Qu.: 2.230 3rd Qu.:1.3500 ## Max. :4765 Max. :20.020 Max. :3.4400 ## NA&#39;s :546 ## day3 ## Min. :0.0200 ## 1st Qu.:0.4400 ## Median :0.7600 ## Mean :0.9765 ## 3rd Qu.:1.5250 ## Max. :3.4100 ## NA&#39;s :687 Se puede remueve valores de un conjunto de datos usando la función subset( ) y en este caso de la columna day1 se selecciona solamente los valores menor de 5, de esta forma eliminamos el valore de 20. Usamos otra vez summary( ) para asegurarnos que se solucionó el problema. Ahora vemos que el valor máximo es 3.69. Code Festivalday1=subset(DownloadFestival, day1&lt;5) summary(Festivalday1) ## ticknumb gender day1 day2 ## Min. :2111 Length:809 Min. :0.020 Min. :0.0000 ## 1st Qu.:3096 Class :character 1st Qu.:1.310 1st Qu.:0.4100 ## Median :3620 Mode :character Median :1.790 Median :0.7900 ## Mean :3616 Mean :1.771 Mean :0.9553 ## 3rd Qu.:4154 3rd Qu.:2.230 3rd Qu.:1.3350 ## Max. :4765 Max. :3.690 Max. :3.4400 ## NA&#39;s :546 ## day3 ## Min. :0.0200 ## 1st Qu.:0.4400 ## Median :0.7600 ## Mean :0.9765 ## 3rd Qu.:1.5250 ## Max. :3.4100 ## NA&#39;s :686 Ahora usando el nuevo data frame hacemos el gráfico otra vez Code festivalHistogram &lt;- ggplot(Festivalday1, aes(day1)) festivalHistogram + geom_histogram(fill=&quot;orange&quot;, colour=&quot;white&quot;) + labs(x = &quot;Hygiene (Day 1 of Festival)&quot;, y = &quot;Frequency&quot;) 9.10 Gráficos de caja box plots Para crear un gráfico de caja se usa la función geom_boxplot(), si hay solamente un grupo en x se pone x=1 y en la y la variable continua. Code festivalBoxplot &lt;- ggplot(Festivalday1, aes(x=1,y=day1)) festivalBoxplot + geom_boxplot() + labs(x = &quot;Gender&quot;, y = &quot;Hygiene (Day 1 of Festival)&quot;) 9.11 Gráfico de caja por grupo Para producir un gráfico de caja por multiples grupos en x se añade la variable categorica y en la y la variable continua. Si se quiere un color diferente por caja se usa la función color con el nombre en de la variable en x. Code festivalBoxplot &lt;- ggplot(Festivalday1, aes(x=gender,y=day2, colour=gender)) festivalBoxplot + geom_point()+ geom_boxplot(fill=&quot;yellow&quot;, alpha=0.1) + labs(x = &quot;Genero&quot;, y = &quot;Higiene (Día 2 del Festival)&quot;) 9.12 Detección valores sesgados o átipicos. En la función abajo denominado Valoressesgados uno puede determinar el porciento de valores que son sesgados. Note que aquí la función no existe y se construye una función para calcularlos porcentajes. Si selecionamos uno de las columnas, el dia 3 del concierto. Vemos que hay 4% de los valores que estén por fuera del intervalo de 95%, y 2.4% de los valores que estén por encima del intervalo de confianza de 99%. Code Valoressesgados&lt;-function(variable, digits = 2){ zvariable&lt;-(variable-mean(variable, na.rm = TRUE))/sd(variable, na.rm = TRUE) IC95&lt;-abs(zvariable) &gt;= 1.96 # error de 95% IC99&lt;-abs(zvariable) &gt;= 2.58 # error de 99% IC999&lt;-abs(zvariable) &gt;= 3.29 # error de 99.9% ncases&lt;-length(na.omit(zvariable)) percentaje95&lt;-round(100*length(subset(IC95, IC95 == TRUE))/ncases, digits) percentaje99&lt;-round(100*length(subset(IC99, IC99 == TRUE))/ncases, digits) percentaje999&lt;-round(100*length(subset(IC999, IC999 == TRUE))/ncases, digits) cat(&quot;Valor absoluto z-score mayor de 1.96 = &quot;, percentaje95, &quot;%&quot;, &quot;\\n&quot;) cat(&quot;Valor absoluto z-score mayor de 2.58 = &quot;, percentaje99, &quot;%&quot;, &quot;\\n&quot;) cat(&quot;Valor absoluto z-score mayor de 3.29 = &quot;, percentaje999, &quot;%&quot;, &quot;\\n&quot;) } Valoressesgados(FD$day3) ## Valor absoluto z-score mayor de 1.96 = 4.07 % ## Valor absoluto z-score mayor de 2.58 = 2.44 % ## Valor absoluto z-score mayor de 3.29 = 0.81 % 9.13 Gráficos de línea y intervalo de errores Learn how to reformat data in the correct type of data frame (as the original data set is not in the correct format) with the function “stack” How to add the mean of the variable with “stat_summary” How to connect the mean with a line and change color How to add the error bars and color (The 95% confidence intervals, created with the stat_summary() function and the “mean_cl_boot” argument are bootstrap confidence intervals using the smean.cl.boot() function in Hmisc) Installar la library(Hmisc) Code library(Hmisc) # Se necesita este paquete para poner los intervalos de confianza library(readr) Hiccups &lt;- read_csv(&quot;Data_files_csv/Hiccups.csv&quot;) head(Hiccups, n=2) ## # A tibble: 2 × 4 ## Baseline Tongue Carotid Rectum ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 15 9 7 2 ## 2 13 18 7 4 Es necesario re-organizar los datos, ya que las 4 diferentes variables están diferentes columnas, necesitamos que están todos los datos en una columna. Se usa la función stack. Subseguientemente, se asigna un nombre nuevo a las columnas Code hiccups&lt;-stack(Hiccups) # organizar los datos en dos columnas con la función **stack** names(hiccups)=c(&quot;Num_Hiccups&quot;,&quot;Intervention&quot;) # Cambiar el nombre de las columnas head(hiccups) ## Num_Hiccups Intervention ## 1 15 Baseline ## 2 13 Baseline ## 3 9 Baseline ## 4 7 Baseline ## 5 11 Baseline ## 6 14 Baseline 9.14 La función stat_summary para calcular indices sumativos. Nota aquí que el promedio, mean es añadido como un punto y que están uniido tambien por una linea, están añadido al eje de y con la función fun.y. Los intervalos de confianza se añaden con la función fun.data=mean_cl_boot y geom=“errorbar. Code ggplot(hiccups, aes(y=Num_Hiccups,x=Intervention))+ stat_summary(fun.y = &quot;mean&quot;, geom = &quot;point&quot;) + stat_summary(fun.y = &quot;mean&quot;, geom = &quot;line&quot;, aes(group = 1),colour = &quot;Red&quot;, linetype = &quot;dashed&quot;) + stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2, colour=&quot;blue&quot;) + labs(x = &quot;Intervention&quot;, y = &quot;Mean Number of Hiccups&quot;) 9.15 Diagrama de tallo y hoja Este diagrama demuestra la cantidad de datos usando el metodo sugerido por John Tukey Code stem(Exam_Anxiety$Anxiety) ## ## The decimal point is 1 digit(s) to the right of the | ## ## 0 | 0 ## 0 | ## 1 | 0 ## 1 | ## 2 | 0 ## 2 | 7 ## 3 | ## 3 | 57 ## 4 | 4 ## 4 | ## 5 | 113 ## 5 | 79 ## 6 | 1122444 ## 6 | 5588999 ## 7 | 00112222333334 ## 7 | 5556666778899999 ## 8 | 111111222222223344 ## 8 | 555555556667889 ## 9 | 00001112344 ## 9 | 568 Code ggplot(Exam_Anxiety, aes(Anxiety))+ geom_histogram() Stem leaf for two groups Code #library(aplpack) Code #stem.leaf(co2) #stem.leaf.backback(Exam_Anxiety$Anxiety[1:30],Exam_Anxiety$Anxiety[31:60]) "],["supuestos.html", "Chapter 10 Supuestos 10.1 ¿Qué son supuestos? 10.2 Homogeneidad de varianza 10.3 Gráficos de cajas condicionales 10.4 Homogeneidad de varianza en modelos de regresión 10.5 Los residuales de Student para detectar valores sesgados 10.6 Valores sesgados con la Distancia de Cook, Di 10.7 Causas principales de los valores sesgados 10.8 Supuesto de normalidad 10.9 qplot 10.10 geom_qq y geom_qq_line 10.11 La distribución normal 10.12 stat_function 10.13 Visualizando la distribuciones con geom_density 10.14 Colinealidad entre covariables con ggpairs 10.15 Seleción de parámetros para correlaciones cuando hay NA 10.16 Uso de GGally para ver correlaciones", " Chapter 10 Supuestos Añadir los siguientes paquetes, Nota la función de pacman para intalar los paquetes. Esta función hace que si le falta un paquete en la lista lo va a instalar sin hacer tener que hacerlo uno por uno. Si quiere hacerlo separado remueve el # antes de install.packages Code #----Install and Load Packages----- #install.packages(&quot;car&quot;, dependencies = TRUE) #install.packages(&quot;ggplot2&quot;) #install.packages(&quot;pastecs&quot;) #install.packages(&quot;psych&quot;) if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(car, pastecs, psych, ggplot2, ggversa, knitr, GGally, tidyverse, kableExtra, reshape2, ggcorrplot, gridExtra) # Activar los paquetes library(ggversa) # un paquete con datos library(knitr) library(GGally) library(tidyverse) library(kableExtra) library(reshape2) library(ggcorrplot) library(gridExtra) library(car) # Companion to applied regression library(ggplot2) # Data Visualization library(pastecs) # Space time Ecological Series library(psych) # Procedures for Psychological, psychometric and Personality Research 10.1 ¿Qué son supuestos? La ética en estadística basado en comprobar y cumplir con los supuestos de las pruebas estadística que se usan. La gran mayoría de las pruebas tradicional asume que los datos cumple con algunos supuestos, algunos típicos son. Distribución normal Igualdad de varianza = Homogeneidad de Varianza Simetría de las distribuciones Datos recolectado al azar Cuando no se cumple con los supuestos estamos aumentando la probabilidad de tipo de error 1, es decir rechazar la hipótesis nula cuando se debería aceptar o tipo de error 2, cuando se debería aceptar la alterna cuando se debería rechazar. Por consecuencia es primodial que cada investigador cumple con evaluar los supuestos de las pruebas que usa y si no cumple que busca métodos alternos. Por ejemplo se puede utilizar métodos de análisis no paramétrica, tambien estadística bayesiana o robusta o como alternativas. En el siguiente modulo se habla de como asegurar que los datos cumple con los supuestos básico de las pruebas paramétricas que incluye t-test, ANOVA entre otros. Note que aquí el énfasis en este modulo es de evaluar los supuestos con herramientas visual, hay herramientas estadística que son son disponible para cada una de estos supuestos. Vea la sección de estadística para estas alterativas para detalles más completos. 10.2 Homogeneidad de varianza La homogeneidad de varianza es un supuesto primordial en el análisis de varianza (ANOVA) y sus vertientes. Este mismo supuesto es también importante en el análisis de regresión simple y multivariable; por ejemplo, en el análisis discriminante (discriminant function analysis en inglés). Utilizaremos los datos de la Becasa de Mar Limosa haemastica, un ave migrante de las costas de las marismas de Argentina, de la base de datos Godwits. Para determinar si la razón de adquisición de comida es diferente entre sexo, tiempo del año, y la combinación de estas dos variables (en otras palabras, las interacciones entre ambas), hay que asumir lo siguiente: 1ro. la varianza en las observaciones entre sexo es similar, 2do. la variación en las tres estaciones es similar, y 3ro. la variación entre los grupos por sexo es similar. 10.3 Gráficos de cajas condicionales Para el ejemplo BecasaDeMar, se removieron algunos datos del análisis como se explica a continuación. En la variable SEX, hay tres categorías: 0 = sexo no identificado, 1 = hembra, y 2 = macho. Se removió la categoría de no identificado usando la siguiente función which: BecasaDeMar=BecasaDeMar[-which(BecasaDeMar$SEX=={0}),] Note aquí el - (el signo de resta) antes de which. El siguiente paso, después de remover los individuos no identificados por sexo, es cambiar el nombre de los niveles 1 y 2 a hembra y macho respectivamente. Para evaluar la homogeneidad de varianza entre las estaciones también se le asigna el nombre del periodo: Verano, Pre-migración e Invierno. Por ejemplo, con relación al supuesto de homogeneidad, en la figura se nota que hay un poco de variación en la varianza de ciertos grupos, pero en general no habría que preocuparse de una desigualdad como tal, aunque los 4 individuos identificados como puntos en la gráfica en el periodo de verano deberían ser evaluados con más detenimiento para asegurarse que los datos están correctos y que representen datos biológicamente posibles y no error en la toma de los datos o cuando se entraron en la hoja de datos. 10.3.1 Selección de los datos Code BecasaDeMar=Godwits # en el paquete ggversa head(BecasaDeMar) ## RECORD DAY MONTH YEAR LOCATION AGE SEX PERIOD mgconsumed ## 1 1 5 1 97 0 0 0 0 0.07 ## 2 2 5 1 97 0 0 0 0 0.16 ## 3 3 5 1 97 0 0 0 0 0.25 ## 4 4 5 1 97 0 0 0 0 0.07 ## 5 5 5 1 97 0 0 0 0 0.14 ## 6 6 5 1 97 0 0 0 0 0.26 Code BecasaDeMar=BecasaDeMar[-which(BecasaDeMar$SEX ==0),] #unique(BecasaDeMar$SEX) BecasaDeMar$fSEXO &lt;- factor(BecasaDeMar$SEX, levels = c(1, 2), labels = c(&quot;Hembra&quot;, &quot;Macho&quot;)) unique(BecasaDeMar$fSEXO) ## [1] Hembra Macho ## Levels: Hembra Macho Code BecasaDeMar$fPERIODO &lt;- factor(BecasaDeMar$PERIOD, levels = c(0, 1, 2), labels = c(&quot;Verano&quot;, &quot;Pre-migración&quot;, &quot;Invierno&quot;)) head(BecasaDeMar) ## RECORD DAY MONTH YEAR LOCATION AGE SEX PERIOD mgconsumed fSEXO ## 125 53 2 4 97 1 1 1 1 0.07 Hembra ## 126 67 16 5 97 0 1 1 2 0.18 Hembra ## 127 69 16 5 97 0 1 1 2 0.39 Hembra ## 128 77 17 6 97 1 1 1 2 0.07 Hembra ## 129 78 17 6 97 1 1 1 2 0.10 Hembra ## 130 79 17 6 97 0 1 1 2 0.08 Hembra ## fPERIODO ## 125 Pre-migración ## 126 Invierno ## 127 Invierno ## 128 Invierno ## 129 Invierno ## 130 Invierno Code BecasaMar &lt;- ggplot(BecasaDeMar, aes(y=mgconsumed, x=fSEXO)) BecasaMar + geom_boxplot(notch=TRUE)+ facet_wrap(~fPERIODO)+ theme(axis.title=element_text(size=12,face=&quot;bold&quot;), axis.text=element_text(size=12, face=&quot;bold&quot;))+ xlab(&quot;Sexo de las aves&quot;)+ ylab(&quot;Razón de consumo&quot;) 10.4 Homogeneidad de varianza en modelos de regresión Para el análisis de tipo regresión es necesario evaluar la homogeneidad de los datos utilizando los residuales del modelo. Esto lo logramos graficándolos contra los valores estimados (fitted values) y haciendo un gráfico de caja condicional con los residuales. Los residuales tienen que ser similares en todos los grupos. Si la variación de los residuales no es igual, será necesario transformar los datos o usar otras técnicas que no requieran del supuesto de la homogeneidad de varianza; por ejemplo, mínimos cuadrados generalizados (generalized least square, en inglés) o un análisis no paramétrico. El gráfico que utilizaremos se llama caja condicional ya que la distribución es condicional al grupo. El residual se calcula como la diferencia entre el valor observado y el valor esperado; en este caso, en la variable de y. A continuación, completamos el análisis utilizando otra vez los datos de la orquídea Dipodium. Primero hay que hacer un análisis de regresión simple usando lm() y darle un nombre al análisis o sea el modelo. Subseguientemente uno puede llamar los valores necesarios para hacer el gráfico con .fitted y .resid. Code dipodium2=dipodium %&gt;% dplyr::select(Number_of_Flowers, Height_Inflo) %&gt;% drop_na() head(dipodium2) ## # A tibble: 6 × 2 ## Number_of_Flowers Height_Inflo ## &lt;int&gt; &lt;int&gt; ## 1 11 35 ## 2 19 47 ## 3 18 63 ## 4 24 47 ## 5 25 61 ## 6 17 35 Code modelflower=lm(Number_of_Flowers~Height_Inflo, data=dipodium2) summary(modelflower) ## ## Call: ## lm(formula = Number_of_Flowers ~ Height_Inflo, data = dipodium2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -12.7346 -2.4391 -0.0868 2.2087 14.3221 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -2.19668 1.24384 -1.766 0.0791 . ## Height_Inflo 0.45074 0.02368 19.038 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.266 on 179 degrees of freedom ## Multiple R-squared: 0.6694, Adjusted R-squared: 0.6676 ## F-statistic: 362.5 on 1 and 179 DF, p-value: &lt; 2.2e-16 Code plot(modelflower) Code ggplot(dipodium2, aes(Height_Inflo, Number_of_Flowers))+ geom_smooth(method=lm)+ geom_point() Code #influence(modelflower) #rstandard(modelflower) #influence.measures(modelflower) #head(fortify(modelflower)) Lo que observaremos es que la distribución de los residuales luce más o menos uniforme alrededor del promedio de los residuales (el cero). Hay aproximadamente igual cantidad de valores mayor a cero (por encima de la línea en verde) y menor a cero (por debajo de la línea en verde) que están distribuidos a través de la variable en el eje de X, o valores estimados. En adición que los residuales (negativos o positivos) no son limitado a sub grupos de de los valores estimados (en la X). Note que se está aplicando el modelo modelflower, y se usan los valores calculados en el modelo .fitted y .resid para producir el gráfico. Se añade una linea horizontal para identificar el modelo nulo con geom_hline. Code res&lt;-ggplot(modelflower, aes(.fitted, .resid))+ geom_point()+ geom_hline(yintercept=0, col=&quot;red&quot;, linetype=&quot;dashed&quot;)+ theme(axis.title=element_text(size=20,face=&quot;bold&quot;), axis.text=element_text(size=20, face=&quot;bold&quot;))+ xlab(&quot;Valores estimados&quot;)+ ylab(&quot;Residuales&quot;)+ ggtitle(&quot;Residuales vs. Valores Estimados&quot;) res 10.5 Los residuales de Student para detectar valores sesgados A continuación se ilustra otro enfoque para evaluar los residuales. En este caso, para detectar valores sesgados (outliers). Se puede visualizar los residuales se usa los residuales estandarizados divido por la desviación estándar. Valores mayores de 3 serian considerados sesgados. Esta alternativa es apropiada si detectar valores sesgados. Note en la figura que se usa otra vez el modelo modelflower y los valores calculados en el modelo .fitted y los residuales de student con .stdresid. Note ahora también que todos los valores en el eje de Y son mayores de cero. Code ResEst=ggplot(modelflower, aes(.fitted, sqrt(abs(.stdresid)))) + geom_point(na.rm=TRUE)+ theme(axis.title=element_text(size=20,face=&quot;bold&quot;), axis.text=element_text(size=20, face=&quot;bold&quot;))+ xlab(&quot;Valores estimados&quot;)+ ylab(&quot;Residuales estandarizados \\n de Student&quot;)+ ggtitle(&quot;Residuales vs. Valores Estimados&quot;) ResEst 10.6 Valores sesgados con la Distancia de Cook, Di Continuando con el tema de evaluar si hay valores que podrían influenciar mucho el análisis, podemos utilizar una de las herramientas para evaluar el peso de cada valor sobre una regresión lineal basada en métodos de los mínimos cuadrados, llamada la Distancia de Cook. Este análisis fue desarrollado por R. Dennis Cook en 1977 y tiene como objetivo evaluar cada valor en la matriz de datos y el peso que tiene sobre el resultado (cuando esté este incluido o no en el análisis). Produce un índice para cada uno de los valores sobre el resultado basándose en los valores residuales que se llama la Distancia de Cook. Por lo tanto, ese análisis evalúa el impacto relativo de cada valor sobre el índice. Infortunadamente no está claro cuál es el valor crítico; o sea, qué valor nos puede indicar que se tiene exceso de peso sobre los resultados. Las dos principales sugerencias son: Distancia de Cook, Di, es mayor a 1 (sugerido por R. Dennis Cook Cook mismo en 1982); y que la Di &gt; 4/n, donde n es el número de observaciones (Bollen et al. 1990). Para hacer una ilustración, continuaremos con el modelo modelflower usando los valores calculados en el modelo anterior. El gráfico se construirá utilizando la opción seq_along, para que los valores en el eje de X se basen en la secuencia de datos en el archivo y los valores en el eje de Y se basen en los valores de la Distancia de Cook. En este caso, vemos que todos los valores están muy por debajo de 1, lo que sugiere que ninguno de los valores individuales influenciaría mucho en los resultados aún si estos fuesen excluidos. Si utilizáramos la segunda alternativa de Di &gt; 4/n, entonces nos deberían preocupar los 8 valores de Di que son mayores a 4/181=0.022, donde 181 es la cantidad de datos en el archivo. Si se considera esta segunda alternativa, sería necesario evaluar 8 valores en la tabla de datos que pudiesen ser sospechosos (los valores encima de la línea roja). Note que no es que están incorrectos; más bien, este resultado es solamente una herramienta para evaluar valores que parecen tener un impacto considerable sobre los resultados. Code ggplot(modelflower, aes(seq_along(.cooksd), .cooksd))+ geom_bar(stat=&quot;identity&quot;, position=&quot;identity&quot;, fill=&quot;steelblue&quot;)+ geom_hline(yintercept =0.022, colour=&quot;red&quot;)+ theme(axis.title=element_text(size=20,face=&quot;bold&quot;), axis.text=element_text(size=20, face=&quot;bold&quot;))+ xlab(&quot;La secuencia de las observaciones&quot;)+ ylab(&quot;Distancia de Cook&quot;)+ ggtitle(&quot;Distancia de Cook&quot;) 10.7 Causas principales de los valores sesgados Los valores que parecen sesgados pueden ser normal de la población estudiada, y por consecuencia en estos casos remoción de estos valores podría resultar en descripción de los resultados incorrectos. Primero hay que evaluar los siguientes posibles causas de valores sesgados. Si algunos de los siguientes son presentes hay que resolver los valores o remover los de la hoja de análisis. los valores recolectado son erróneo. los valores fueron entrado incorrectamente en la hoja de datos los valores recolectado tienen diferente dimensiones, por ejemplo algunos fueron recolectados en cm y otros en mm para la misma variable. 10.8 Supuesto de normalidad Hay muchas pruebas estadísticas que asumen que los datos provienen de una distribución normal. Pero no todas las pruebas tienen que satisfacer ese supuesto. Por ejemplo, un Análisis de Componentes Principales o ACP (en inglés, PCA o Principle Component Analysis) o la prueba de t asumen distribución normal. Por el contrario, las pruebas no paramétricas como Wilcoxon, Mann-Whitney, Kruskall Wallis y otras no asumen ese supuesto. Una alternativa tradicional para comprobar la normalidad de los datos es mirar el gráfico de QQ; o sea, una visualización para comparar las probabilidades de dos variables en las que se gráfica los cuartiles (recordemos que Q viene de cuartil). Si las distribuciones de las dos variables son similares, los puntos aparecerán nítidamente en el gráfico de QQ sobre la línea de X-Y. Eso se demostrará a continuación. 10.9 qplot En el gráfico se representa el consumo por la Becasa de Mar de la base de datos Godwits, el ave de las marismas de Argentina que hemos analizado anteriormente. En el gráfico se nota que los datos a los extremos no están muy cerca de la línea X-Y, lo que sugiere que el consumo por la Becasa de Mar no tiene una distribución normal. La función qplot es la manera más sencilla para generar el gráfico de QQ. Code # Note que anteriormente ya habíamos depositado los datos en el data.frame BecasaDeMar ggplot(BecasaDeMar, aes(sample=mgconsumed))+ geom_qq()+ geom_qq_line()+ theme(axis.title=element_text(size=20,face=&quot;bold&quot;), axis.text = element_text(size=20,face=&quot;bold&quot;))+ xlab(&quot;Valores teóricos&quot;)+ ylab(&quot;Valores observados&quot;) 10.10 geom_qq y geom_qq_line A pesar de lo fácil de este enfoque, apreciar si los datos quedan nítidamente alineados sobre una línea no es tan evidente en algunos casos. Por lo tanto, en la siguiente versión del gráfico de QQ producida con la función geom_qq y geom_qq_line se le añade una línea para mostrar dónde debería estar localizada la gran mayoría de los datos si estos tuvieran una distribución normal. Ahora vemos que claramente muchos de los datos no yacen en la línea. Evidentemente, el trazar la línea teórica ayuda a visualizar la conclusión; en este caso, se podría concluir que el consumo de comida por este pájaro no sigue una distribución normal la linea azul. En el segundo ejemplo se crea un archivo de datos que tiene una distribución normal y esta ejemplo la gran mayoría de los datos solapen la linea, la linea roja Code a= ggplot(Godwits, aes(sample = mgconsumed)) + stat_qq() + stat_qq_line(colour=&quot;blue&quot;)+ xlab(&quot;Valores teóricos&quot;)+ ylab(&quot;Valores observados&quot;) df &lt;- data.frame(y = rnorm(2000)) b &lt;- ggplot(df, aes(sample = y))+ stat_qq() + stat_qq_line(colour=&quot;red&quot;) grid.arrange(a,b,ncol=2) 10.11 La distribución normal Una segunda alternativa para visualizar si los datos siguen una distribución normal es construir un histograma de los datos y gráficar sobre este la curva normal basándonos en el promedio y la desviación estándar de los mismos datos. Para construir el histograma se usa la función geom_histogram y para la distribución teórica normal de estos datos se usa la función stat_function. Esto lo demostramos con gráficos adicionales de la Becasa del Mar, donde se representa la razón de consumo y el período en que esto ocurrió. En la Figura (a) vemos la distribución para todos los períodos, y los otros tres en la Figura (b) muestran una distribución para cada uno de los períodos. Se observa en todos los casos que las distribuciones están sesgadas hacia los valores pequeños (hacia la izquierda). Esta visualización nos ayuda a evaluar la normalidad de esos datos. NOta que no es una prueba estadística igual como el gráfico de qqplot. Nota la formula para calcular la distribución normal. Hay solamente dos parámetros que necesitamos, el promedio \\(\\mu\\) y la desviación estándar \\(\\sigma\\). Todos los otros son constantes, \\(\\pi\\), y e. \\[P(x)=\\frac{1}{{\\sigma\\sqrt{ 2\\pi}}}{e}^{-\\frac{{(x-µ)}^{2}}{{2\\sigma}^{2}}}\\] Note que en geom_histogram se tiene que incluir aes(..density..) y añadir dentro de la función stat_function todo lo siguiente: stat_function(fun = dnorm, args = list(mean = mean(Godwits\\(mgconsumed, na.rm = TRUE), sd = sd(Godwits\\)mgconsumed, na.rm = TRUE)), colour = “red”, size = 1) El parámetro dnorm quiere decir densidad de la distribución normal. También se necesitan dos parámetros para calcular el promedio (mean) y la desviación estándar (sd). Con ambos hay que especificar de dónde provienen los datos; en este caso, Godwits$mgconsumed Además, si hay NA en los datos, hay que añadir na.rm = TRUE para excluir los NA. Veamos. Code a=ggplot(Godwits, aes(mgconsumed)) + theme(legend.position = &quot;none&quot;) + geom_histogram(aes(y=..density..), colour=&quot;black&quot;, fill=&quot;white&quot;)+ theme(axis.title=element_text(size=12,face=&quot;bold&quot;), axis.text = element_text(size=12,face=&quot;bold&quot;))+ labs(x = &quot;Razón de Consumo&quot;, y = &quot;Densidad&quot;) + stat_function(fun = dnorm, args = list(mean = mean(Godwits$mgconsumed, na.rm = TRUE), sd = sd(Godwits$mgconsumed,na.rm = TRUE)), colour = &quot;red&quot;, size = 1)+ ggtitle(&quot;Todos los datos&quot;) b= ggplot(Godwits, aes(mgconsumed)) + theme(legend.position = &quot;none&quot;) + geom_histogram(aes(y=..density..), colour=&quot;black&quot;, fill=&quot;white&quot;)+ theme(axis.title=element_text(size=12,face=&quot;bold&quot;), axis.text = element_text(size=12,face=&quot;bold&quot;))+ labs(x = &quot;Razón de Consumo&quot;, y = &quot;Densidad&quot;) + stat_function(fun = dnorm, args = list(mean = mean(Godwits$mgconsumed, na.rm = TRUE), sd = sd(Godwits$mgconsumed, na.rm = TRUE)), colour = &quot;red&quot;, size = 1)+ facet_wrap(~PERIOD)+ ggtitle(&quot;Por estación anual&quot;) grid.arrange(a,b,ncol=1) 10.12 stat_function Continuaremos con este mismo análisis pero esta vez evaluaremos la distribución del peso de gorriones en un trabajo de captura y recaptura en 6 meses diferentes. Utilizaremos la base de datos SparrowsElphick. En la figura (a) observamos un histograma de la distribución de los pesos de estas aves por cada mes. Vemos claramente que hay meses (mayo, septiembre y octubre) en los que se tuvieron muchas menos observaciones. En el segundo gráfico, Figura (b), observamos el histograma y la curva normal para todos los datos sin importar el mes. Igualmente, esta visualización nos ayuda a evaluar la normalidad de los datos. Code Sparrows=SparrowsElphick Sparrows$fMonth&lt;-factor(Sparrows$Month, levels = c(5, 6, 7, 8, 9, 10), labels = c(&quot;Mayo&quot;, &quot;Junio&quot;, &quot;Julio&quot;, &quot;Agosto&quot;, &quot;Sept.&quot;, &quot;Oct.&quot;)) a=ggplot(Sparrows, aes(wt))+ geom_histogram(binwidth=1, colour=&quot;white&quot;)+ facet_wrap(~fMonth)+ theme(axis.title=element_text(size=12,face=&quot;bold&quot;), axis.text = element_text(size=12,face=&quot;bold&quot;))+ xlab(&quot;Peso&quot;)+ ylab(&quot;Frecuencia&quot;) b=ggplot(Sparrows, aes(wt)) + theme(legend.position = &quot;none&quot;)+ theme(axis.title=element_text(size=12,face=&quot;bold&quot;), axis.text = element_text(size=12,face=&quot;bold&quot;))+ geom_histogram(aes(y=..density..), colour=&quot;black&quot;, fill=&quot;white&quot;) + labs(x = &quot;Peso&quot;, y = &quot;Densidad&quot;) + stat_function(fun = dnorm, args = list(mean = mean(Sparrows$wt, na.rm = TRUE), sd = sd(Sparrows$wt, na.rm = TRUE)), colour = &quot;red&quot;, size = 1) grid.arrange(a,b,ncol=2) 10.13 Visualizando la distribuciones con geom_density A continuación se muestra otra alternativa para observar los datos anteriores. Nada más que estos ahora se representan sustituyendo las funciones geom_histogram y stat_function por geom_density para la construcción de curvas de densidad. Otra vez utilizaremos la base de datos SparrowsElphick. La curva normal que se genera es tipo gausiana (gaussian en inglés). Nóte que para el segundo conjunto de gráficos, (b), no se le especificó la opción en kernel igual a gaussian ya que de forma predeterminada la función geom_density usa el parámetro gaussian; o sea, no es necesario especificarla si eso es lo que se quiere. Una distribución en donde el pico es más alto significa que hay mayor densidad de datos en esa región de la variable en el eje de X. Podemos apreciar que la curva de densidad no sigue claramente una distribución normal con respecto a los valores en X. Code # Note que anteriormente ya habíamos depositado los datos en el data.frame Sparrows: a= ggplot(Sparrows, aes(wt))+ geom_density(aes(group=fMonth, fill=fMonth), kernel=&quot;gaussian&quot;)+ facet_wrap(~fMonth)+ guides(fill=FALSE)+ theme(axis.title=element_text(size=12,face=&quot;bold&quot;), axis.text=element_text(size=12, face=&quot;bold&quot;))+ ylab(&quot;Densidad&quot;)+ xlab(&quot;Peso&quot;) b= ggplot(Sparrows, aes(wt))+ geom_density(aes(group=fMonth, fill=fMonth), alpha=.4)+ scale_color_discrete()+ theme(axis.title=element_text(size=12,face=&quot;bold&quot;), axis.text=element_text(size=12, face=&quot;bold&quot;))+ ylab(&quot;Densidad&quot;)+ xlab(&quot;Peso&quot;)+ labs(colour=&quot;Mes&quot;) grid.arrange(a,b,ncol=1) 10.14 Colinealidad entre covariables con ggpairs Hoy en día la cantidad de datos que se obtienen en diferentes estudios puede ser muy impresionante. Muchas veces el objetivo es detectar si unas variables, entre muchas otras, podrían predecir la variable de respuesta. A consecuencia de eso, el problema mayor es tomar en cuenta la colinealidad entre variables explicativas. La colinealidad es simplemente la correlación entre variables en un modelo de análisis de regresión múltiple, en donde las variables predictivas están altamente correlacionadas. Un ejemplo sencillo de variables con colinealidad podría incluir la relación entre el largo y ancho de las hojas de una herbácea y cómo estas están correlacionadas con la producción de flores. Es probable que la correlación entre el largo y el ancho de la hoja estén correlacionadas con la producción de las flores de formas muy similares; o sea, con una pendiente que explicaría ambas relaciones de formas similares. Entonces, al añadir ambas variables al modelo de regresión múltiple, no estaríamos explicando variaciones distintas, si no más bien la misma variación. Cuando hay mucha colinealidad entre variables explicativas, se debería seleccionar un subgrupo de estas variables que expliquen variaciones distintas para el modelo y no incluir todas las variables. A continuación exploraremos diferentes alternativas para llevar a cabo este tipo de análisis utilizando otra vez los datos de la orquídea Dipodium. En el primer ejemplo, se utiliza la función cor para evaluar solo una relación: la correlación entre la distancia de la planta a un árbol y la altura de la planta, dejando otras variables a un lado. Como deseamos el estimado de la correlación solamente, utilizamos un par de variables a la vez para evaluar la correlación entre la distancia de la orquídea al árbol y la altura de la inflorescencia (mostrado más adelante). Concluimos que a mayor distancia del árbol, menor es la altura de la inflorescencia al este análisis arrojar un valor de pendiente de -0.095 como se muestra en el ejemplo. Code cor(dipodium$Distance, dipodium$Height_Inflo, use=&quot;pairwise.complete.obs&quot;) ## [1] -0.09541256 Otra alternativa es hacer el análisis de correlación de muchas variables en conjunto. En la tabla, Correlaciones de Pearson, se muestra la correlación entre las tres variables siguientes: DBH, cantidad de flores y altura de la inflorescencia. En esa tabla se observa la correlación de Pearson para estos datos. Recordemos que esta correlación asume distribución normal. Code kable(signif(cor(dipodium[,c(3, 8, 9)], use=&quot;pairwise.complete.obs&quot;),2)) DBH Number_of_Flowers Height_Inflo DBH 1.000 -0.035 -0.10 Number_of_Flowers -0.035 1.000 0.82 Height_Inflo -0.100 0.820 1.00 10.14.1 Tabla de correlación de Kendall Usando la función cor se puede también calcular estimados de correlación sin asumir distribución normal usando los métodos Kendall o Spearman mostrados en la Tabla siguiente. Code kable(signif(cor(dipodium[,c(3, 8, 9)], method=&quot;kendall&quot;, use=&quot;pairwise.complete.obs&quot;),2), caption = &quot;\\\\label{fig:CK}Correlaciones de Kendall&quot;) Table 10.1: Correlaciones de Kendall DBH Number_of_Flowers Height_Inflo DBH 1.00000 0.00085 -0.059 Number_of_Flowers 0.00085 1.00000 0.650 Height_Inflo -0.05900 0.65000 1.000 10.14.2 Tabla de correlación de Spearman Code kable(signif(cor(dipodium[,c(3, 8, 9)], method=&quot;spearman&quot;, use=&quot;pairwise.complete.obs&quot;),1)) DBH Number_of_Flowers Height_Inflo DBH 1.000 -0.002 -0.08 Number_of_Flowers -0.002 1.000 0.80 Height_Inflo -0.080 0.800 1.00 En esas tres tablas podemos apreciar un patrón consistente entre todos los métodos; o sea, la altura de la inflorescencia está altamente correlacionada con la cantidad de flores (con coeficientes de correlación de 0.82, 0.65, y 0.81 respectivamente). Note que para facilitar la lectura de los valores, se usó la función signif para así identificar solamente los valores significativos del análisis. Brevemente recapitulamos, si los datos no siguen una distribución normal, se deberían utilizar los métodos Kendall o Spearman. Si se tienen pocos datos, Kendall tiende a ser una mejor alternativa para determinar el indice de correlación. Se le advierte, sin embargo, que consulte libros de estadística sobre este tema antes que realice un análisis de este tipo ya que la decisión de seleccionar una alternativa sobre otra no es tan sencilla. 10.15 Seleción de parámetros para correlaciones cuando hay NA Además, los analísis anteriores utilizados emplearon el parámetro pairwise.complete.obs, ya que obviaría los NA en las columnas que se utilizan para calcular la correlación. Por lo tanto, la cantidad de pares de datos utilizados para calcular las diferentes correlaciones entre variables puede variar si hay NA en el archivo. Tome en consideración que hay otras cuatro alternativas para analizar los datos cuando tenemos NA presentes: everything, all.obs, complete.obs y na.or.complete. No vamos a discutir esas alternativas en el presente libro. Sería bueno que busque información en R para sus usos. Estas alternativas se discutiran en otros modulos. Finalmente, también se utilizó el comando kable ya que es una manera efectiva de organizar los resultados en una tabla. 10.16 Uso de GGally para ver correlaciones Continuando con el mismo tema, una tercera opción para descubrir la colinealidad entre covariables es utilizar el paquete GGally, ya que no solamente nos calcula las correlaciones, si no que también nos permite hacer los gráficos de densidad de la distribución de las variables y un gráfico de dispersión por pares de variables evaluadas. En los gráficos de la siguiente Figura observamos los coeficientes de correlación, la distribución de los datos y la visualización de correlación por cada par. Además, vemos el diagrama de caja de los datos cuando hay variables discretas. Note al extremo derecho que la variable Herbivory tiene una categoría no identificada, que incluye los NA. Con la función de ggpairs podemos calcular las correlaciones entre las variables y a la misma vez producir todos los gráficos entre las variables y gráficos de distribución de densidad de cada variable. En el gráfico podemos observar en la parte izquierda la distribución de los datos en pares. En la diagonal se observa la densidad de cada una de las variables. En la parte superior derecha se observa el valor de correlación y en el extremo derecho se observan los diagramas de caja de las variables discretas con relación a la variable de la izquierda. Este gráfico es sumamente práctico, ya que produce mucha información con pocos pasos. Desafortunadamente, no hay manera de remover los NA al presente. A consecuencia de esto, al extremo derecho uno observa en las cajas abajo una barra con muchos valores (la de la derecha), pero esta representa todos los valores NA en la tabla de datos. En este caso, la presencia de herbivoria en las plantas no fue recolectada y en cambio se dejó con un NA. Note que aquí no se pueden poner ceros u otros valores. Las alternativas podrían ser H para evidenciar la presencia de herbaria y n para las plantas donde no hay evidencia de herbivoría. Code names(dipodium) # para ver los nombres de las variables/columnas ## [1] &quot;Tree Number&quot; &quot;Tree species&quot; ## [3] &quot;DBH&quot; &quot;Plant number&quot; ## [5] &quot;Ramet number&quot; &quot;Distance&quot; ## [7] &quot;Orientation&quot; &quot;Number_of_Flowers&quot; ## [9] &quot;Height_Inflo&quot; &quot;Herbivory&quot; ## [11] &quot;RowPosition_NF&quot; &quot;Number_Flowers_position&quot; ## [13] &quot;Number_of_fruits&quot; &quot;Perc_FR_set&quot; ## [15] &quot;pardalinum_or_roseum&quot; &quot;Fruit_position_effect&quot; ## [17] &quot;Frutos_si_o_no&quot; &quot;P_or_R_Infl_Lenght&quot; ## [19] &quot;Num of fruits&quot; &quot;Species_Name&quot; ## [21] &quot;Cardinal orientation&quot; Code ggpairs(dipodium[,c(8, 9, 13, 14, 10)]) "],["estadística-frecuentista.html", "Chapter 11 Estadística Frecuentista 11.1 Bondad de ajuste y Table de Contingencia 11.2 Qué son supuestos 11.3 Los supuestos de las pruebas de frecuencias. 11.4 Instalar y activar los siguientes packages 11.5 Gregory Mendel y sus guisantes 11.6 Bondad de Ajuste. 11.7 Primer ejemplo 11.8 Segundo ejemplo 11.9 Prueba de Bondad de Ajuste 11.10 Gráfico de Mosaico 11.11 Prueba de Independencia de frecuencia. 11.12 La función CrossTable 11.13 Análisis con datos en formato de tabla 11.14 Prueba de independencia 11.15 El color de pello es independiente del sexo 11.16 Prueba de Exacta de Fisher", " Chapter 11 Estadística Frecuentista 11.1 Bondad de ajuste y Table de Contingencia Este tipo de prueba es frecuentemente conocido erróneamente como la prueba de Chi cuadrado. Los tipos de datos necesarios son distintos a las pruebas anteriores. En las pruebas que en los próximos módulos siempre habrá por lo menos una variable donde la unidad era el número de individuos, el largo o ancho en una unidad (cm, metro, celsius, etc) o sea una variable continua. Ahora para la pruebas de Bondad de ajuste y Tabla de Contingencia se contabiliza el número de eventos por categoría. En otra palabra es la frecuencia que ocurre un evento. En esta sección no estamos interesado en evaluar los valores con datos que son continuos como la altura o el tamaño. Las variables que se usa son variables categóricas, o sea los valores son la frecuencia de un evento (o la ausencia de un evento). Los datos tienen que caer exactamente en una categoría, por ejemplo vivo o muerto. presente o ausente. blanco, rojo, verde, azul. estar embarazada o no. Tiene el fenotipo dominante o recesivo. En una herencia mendeliana, los individuos son homocigóticos recesivo, dominantes o heterocigóticos. 11.2 Qué son supuestos Cuando hablamos de supuestos estamos hablando de las condiciones necesarias para que la prueba sea utilizada. El incumplimiento de los supuestos resulta en que el los resultados de la prueba tenga un nivel de tipo de error I y tipo de error II más grande que los especificado (por ejemplo si selecciona un \\(\\alpha\\) de 0.05, el error seria más grande). Si se usa datos usa datos erróneos puede ser que la prueba sea completamente invalida. 11.3 Los supuestos de las pruebas de frecuencias. Los datos son frecuencias. Las frecuencias son mutuamente exclusivas (no caen en múltiples categorías). Las observaciones son independiente una de la otra. Cada categoría tiene una frecuencia esperada suficiente grande: ninguna de las frecuencia esperada sea menor de 5 cuando hay 4 o menos categorías no más de 20% de las categorías que tengan un valor esperado de &lt; 5 cuando hay más de 5 categorías y ninguna tiene un valor esperado menor de 1. 11.4 Instalar y activar los siguientes packages Code #----Instalar los paquetes si es necesario----- #install.packages(&quot;gmodels&quot;) #install.packages(&quot;MASS&quot;) if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(gmodels, MASS, gt) #------Activar los paquetes----- library(gmodels) ## Analisis de datos de frecuencia library(MASS) ## graficar los datos con la función &quot;mosaicpLot&quot; library(gt) ## &quot;Grammer of Tables&quot;, tablas más bonitas 11.5 Gregory Mendel y sus guisantes Gregory Mendel (1822-1884) el padre de herencia “mendeliana” estaba interesada en determinar como se hereda las características de los organismos. En clases de biología y genética uno de los primeros ejemplos de herencia mendeliana es evaluar si cumple con lo que Mendel sugerió que es la razón de herencia. Si un fenotipo es heredado por un mecanismo sencillo de un gen con solamente dos alelos donde uno de los alelos es dominante y el otro es recesivo entonces hay solamente dos fenotipos posible. Por consecuencia lo más básico es determinar si la frecuencia de los fenotipos en una población sigue una razón mendeliana de 3:1, en otra palabra por cada 3 individuos de un fenotipo “x” hay un individuo del fenotipo “y”. Los datos que estaremos usando provenien directamente de los trabajos de Mendel. Aquí esta la publicación original en aleman y la referencia a la traducción en ingles. Mendel, J.G. (1866). “Versuche über Pflanzenhybriden”, Verhandlungen des naturforschenden Vereines in Brünn, Bd. IV für das Jahr, 1865, Abhandlungen: 3–47, [1]. For the English translation, see: Druery, C.T.; Bateson, William (1901). “Experiments in plant hybridization” (PDF). Journal of the Royal Horticultural Society. 26: 1–32. Tabla de los resultados de experimentos original de Gregor Mendel con semillas redondas y arrugadas. Cada uno represente un experimento y la cantidad de guisantes redondos o arrugadas. Plantas redonda arrugada 1 45 12 2 27 8 3 24 7 4 19 10 5 32 11 6 26 6 7 88 24 8 22 10 9 28 6 10 25 7 Total 336 101 En la pagina número 10 del articulo observamos los resultados de diferentes experimentos. En el experimento 1, la Planta #1, produjo un total de 57 semillas donde 45 eran redonda y 12 eran arrugadas. Si lo que esperamos es una razón de 3:1, los que se se espera es que 0.75:0.25 que seria las proporciones esperada. Creamos un vector de datos de los valores observados (obs) y un vector de datos para la proporción esperada (esp). 11.6 Bondad de Ajuste. La prueba de bondad de ajuste y de tabla de contingencia son pruebas que evalúa la cantidad/frecuencia en las categorías y lo compara con un modelo nulo. En este caso lo que se compará es la cantidad de la frecuencia observada \\(o\\), con la frecuencia esperada \\(e\\). La formula es la siguiente \\[\\chi^2=\\sum_{n=i}^n\\frac{\\left(o-e\\right)^2}{e}\\] Usamos un ejemplo sencillo de los datos de Mendel haciendo los cálculos a mano de una proporción 3:1 de herencia de los fenotipos redonda:arrugada. Los datos son de la primer linea de uno de los experimentos que hizo Mendel. Code 57*.75 ## [1] 42.75 Code 57*.25 ## [1] 14.25 Code library(knitr) library(kableExtra) df &lt;- data.frame(Calculos = c(&quot;Observado&quot;,&quot;Esperado&quot;, &quot;(o-e)&quot;, &quot;(o-e)^2&quot;, &quot;$$\\\\frac{(o-e)^2}{e}$$&quot;, &quot;$$\\\\chi_{total}^2$$&quot;), Redonda = c(45, 42.75, 2.25,5.0625, 0.1184, &quot;&quot;), Arrugada = c(12,14.25, -2.25,5.0625 ,0.3553, &quot;&quot;), Total = c(&quot;&quot;,&quot;&quot;,&quot;&quot;,&quot;&quot;,&quot;&quot;,0.4737)) kable(df, escape=FALSE) Calculos Redonda Arrugada Total Observado 45 12 Esperado 42.75 14.25 (o-e) 2.25 -2.25 (o-e)^2 5.0625 5.0625 \\[\\frac{(o-e)^2}{e}\\] 0.1184 0.3553 \\[\\chi_{total}^2\\] 0.4737 Los pasos para calcular el Chi Cuadrado: Los valores esperados, en este caso fue una proporción de 3:1 Las diferencias Cuadrar las diferencias División por el valor esperado (da los Chi Square parcial) Sumar los valores en #4. buscar en una tabla de Chi Square el valor critico de Chi Square para la cantidad de grupos menos 1 y el \\(\\alpha\\) correspondiente. En este caso se busca un \\(\\alpha\\) de 0.05 y el grado de libertad (n-1) = 2-1, n es el número de grupos. Para determinar si es significado el valor de Chi Square observado se compara con el valor critico (de la tabla). Aquí usamos R para conseguir este valor. Note aquí se usa (1-0.05= 0.95) y el grado de libertad que es 1. Ahora se compara ese valor con 0.4737, Si el valor observado es menor que el valor 3.841459 se acepta la hipótesis nula. En este caso no hay evidencia que los fenotipos se hereden diferente a 3:1. Code qchisq(0.95, 1) ## [1] 3.841459 No hay ninguna razón de hacer los cálculos a mano si tenemos a R para hacerlo. Nota aquí se hace la misma prueba con los mismos datos y tenemos el mismo resultado. 11.7 Primer ejemplo Lo que uno observa es el valor de la prueba de Bondad de ajuste tiene un Chi Cuadrado de 0.48, p =.49. Como el valor de p es mayor a 0.05, no se rechaza la hipótesis nula y que la frecuencia no es diferente de una proporción de 3:1. Code obs&lt;-c(45,12) esp&lt;-c(0.75,0.25) # este el modelo nulo chisq.test(x=obs, p=esp) ## ## Chi-squared test for given probabilities ## ## data: obs ## X-squared = 0.47368, df = 1, p-value = 0.4913 11.8 Segundo ejemplo Ahora evaluamos si la frecuencia de semillas redondas:arrugadas de todo el experimento sigue un patrón de 3:1. Se observa un Chi cuadrado de 0.83 y un valor de p=0.36, otra vez el valor es por encima de 0.05, y se concluye que la frecuencia de semillas redondas:redondas no es distintas a 3:1. Se acepta la hipotesis nula. Vemos que a re-evaluar los experimentos de G. Mendel tenemos un resultado que apoya su predicciones. Nota que G. Mendel NO tenia pruebas estadísticas para determinar si las frecuencias eran diferente o no de 3:1. El hizo observaciones y llego a unas conclusiones. Se acuerda cuando fue desarrollado este método y por quien? Code obs&lt;-c(336,101) esp&lt;-c(0.75,0.25) chisq.test(x=obs, p=esp) ## ## Chi-squared test for given probabilities ## ## data: obs ## X-squared = 0.83066, df = 1, p-value = 0.3621 Ejercicio: Cien pajaritos recibieron semillas de girasol con rayas negras o semillas negras. Setenta y cinco eligieron semillas negras. ¿Podemos concluir que la población de la que se tomó esta muestra tiene preferencia por las semillas de girasol negras sobre las semillas de girasol rayadas? (traducido del extracto 7.1 de Havel et al.). ¿Cual es la hipótesis nula? ¿cual es la hipótesis alterna? calcula los valores esperados calcula el chi cuadrado ¿Se rechaza o acepta la Ho? Code #install.packages(&quot;MASS&quot;, dependencies = TRUE) 11.9 Prueba de Bondad de Ajuste Esta prueba se usa para Los siguientes datos son de Field, Miles and Field 2012. Este conjunto de datos represente un experimento ficticio de tratar de entrenar 200 gatos para que bailan basado en si se la da una recompensa o no. Este esta basado en el concepto del psicólogo Ruso Ivan Pavlov (1849-1936) de que se puede enseñar o sea motivar a una acción dando una recompensa. Lo que se llama “condicionar” un proceso de aprendizaje que ocurre entre la asociación de un estimulo ambiental y un comportamiento. Primero entramos los datos directamente en una tabla Los datos son los siguientes: A 38 gatos se la ha dado una recompensa, y de estos 28 bailaron y 10 no bailaron. A 162 no se la dado recompensa, y de estos 48 bailaron y 114 no bailaron. Se crea dos listas con los resultados y se une estas dos filas con cbind() y después se la añade un nombre a las filas con rownames(). Vemos ahora la tabla de frecuencias de cuantos gatos bailaron o no y si fueron entrenado por comido o cariño. Nota que no se puede añadir la tilde ~ a la n de cariño. Code #Crear la tabla de contingencia comida &lt;- c(10, 28) carino &lt;- c(114,48) catsTable &lt;- cbind(comida, carino) rownames(catsTable)&lt;-c(&quot;No_bailan&quot;, &quot;bailan&quot;) # Añade el nombre a las filas catsTable ## comida carino ## No_bailan 10 114 ## bailan 28 48 11.10 Gráfico de Mosaico Podemos visualizar la frecuencia de los datos con un gráfico de mosaico. Si la hipótesis nula la organización de las cajas deberían ser más o menos de la mismq proporción (relativo a su frecuencia). En este caso lo que uno observa es que los que reciben comida y no bailan, la caja es mucha más pequeña que los que bailan y reciben comida. Nota que esto no es una prueba es una visualización de los datos y puede ayudar a entender el patrón. Code mosaicplot(catsTable) Haz un tabla con diferentes cantidad de frecuencia y gráficolos con mosaicplot para evaluar como cambia el gráfico. 11.11 Prueba de Independencia de frecuencia. En ingles se le conoce como “Contingency Tables” Los valores esperados en esta caso son calculados directamente de la tabla. Para cada celda \\(E_{ij}\\) donde la {i} representa la fila y la {j} las columnas. El valor esperado se calcula multiplicando la suma de la fila por la suma \\({R_i}\\) de la suma de la columna \\({C_j}\\). La formula de los valores esperados es la siguiente, donde la N es la suma total de datos. El primer paso es sumar la filas y la columnas de la tabla. Code catsTable ## comida carino ## No_bailan 10 114 ## bailan 28 48 \\[E_{ij}=\\frac{\\left(R_i\\cdot C_j\\right)}{N}\\] Cálculos dos de los valores esperados Los gatos que reciban comida y bailan \\[E_{12}=\\frac{\\left(R_2\\cdot C_1\\right)}{N}= \\frac{(38*76)}{200}=14.44\\] Los gatos que reciban cariño y no bailan \\[E_{21}=\\frac{\\left(R_1\\cdot C_2\\right)}{N}= \\frac{(124*162)}{200}=100.44\\] La prueba es exactamente igual como la anterior donde comparamos el valor observado con el valor esperado. Por ser más de una fila la formula cambia. \\[\\chi^2=\\sum_{n=i}^n\\sum_{n=j}^n\\frac{\\left(o-e\\right)^2}{e}\\] El Chi Cuadrado final es \\[\\chi^2=\\frac{(10-23.56)^2}{23.56}+\\frac{(28-14.44)^2}{14.44}+\\frac{(114-100.44)^2}{100.44}+\\frac{(48-61.56)^2}{61.56}=25.36\\] \\[\\chi^2=25.36\\] 11.12 La función CrossTable Con esta función se calcula el chi cuadrado con los valores esperados. Nota la leyenda al principio para poder entender la organización de los datos. El grado de liberta se calcula con la siguiente formula, el numero de filas -1 multiplicado por la cantidad de columnas -1, df= (R-1)(C-1). df = es para grado de libertad. Si tiene solamente 1 grado de libertad hay que usar el resultado de la prueba de Yates de continuidad, que hace una corrección para la poca cantidad de grados de libertad. \\[\\chi^2=\\sum_{n=i}^n\\sum_{n=j}^n\\frac{\\left(\\left|o-e\\right|-0.5\\right)^2}{e}\\] Code CrossTable(catsTable, fisher = TRUE, chisq = TRUE, expected = TRUE, sresid = TRUE, format = &quot;SAS&quot;) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Expected N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 200 ## ## ## | ## | comida | carino | Row Total | ## -------------|-----------|-----------|-----------| ## No_bailan | 10 | 114 | 124 | ## | 23.560 | 100.440 | | ## | 7.804 | 1.831 | | ## | 0.081 | 0.919 | 0.620 | ## | 0.263 | 0.704 | | ## | 0.050 | 0.570 | | ## -------------|-----------|-----------|-----------| ## bailan | 28 | 48 | 76 | ## | 14.440 | 61.560 | | ## | 12.734 | 2.987 | | ## | 0.368 | 0.632 | 0.380 | ## | 0.737 | 0.296 | | ## | 0.140 | 0.240 | | ## -------------|-----------|-----------|-----------| ## Column Total | 38 | 162 | 200 | ## | 0.190 | 0.810 | | ## -------------|-----------|-----------|-----------| ## ## ## Statistics for All Table Factors ## ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 25.35569 d.f. = 1 p = 4.767434e-07 ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ------------------------------------------------------------ ## Chi^2 = 23.52028 d.f. = 1 p = 1.236041e-06 ## ## ## Fisher&#39;s Exact Test for Count Data ## ------------------------------------------------------------ ## Sample estimate odds ratio: 0.1519927 ## ## Alternative hypothesis: true odds ratio is not equal to 1 ## p = 1.311709e-06 ## 95% confidence interval: 0.06086544 0.352389 ## ## Alternative hypothesis: true odds ratio is less than 1 ## p = 7.7122e-07 ## 95% confidence interval: 0 0.3131634 ## ## Alternative hypothesis: true odds ratio is greater than 1 ## p = 0.9999999 ## 95% confidence interval: 0.07015399 Inf ## ## ## Enlace a un Video de la serpiente Ejercicio: Un herpetólogo sospecha que las serpientes de agua hembras que se alimentan en el lago Michigan migran a los estanques del interior en el otoño para dar a luz a sus crías. Si esta hipótesis es correcta, cabría esperar que las hembras fueran mucho más propensas a migrar en ese momento que los machos. Se recopilaron los siguientes datos. (De Havel et al.) Migrantes No Migrantes Hembra 25 2 Machos 4 30 - ¿Cual es la hipótesis nula? - ¿cual es la hipótesis alterna? - calcula los valores esperados - calcula el chi cuadrado - ¿Se rechaza o acepta la Ho? 11.13 Análisis con datos en formato de tabla Estos son los mismos datos pero no sumado, en otra palabra es información específica sobre cada gato y su tratamiento y si bailo o no. La ventaja de este método es que uno no tiene que hacer el calculo y sumar la frecuancias, se deja la función CrossTable hacer la suma. Miran bien la tabla. Code ## La data sin sumar Training&lt;-c(rep(0, 38), rep(1, 162)) Dance&lt;-c(rep(1, 10), rep(0, 28), rep(1, 114), rep(0, 48)) Training&lt;-factor(Training, labels = c(&quot;Food as Reward&quot;, &quot;Affection as Reward&quot;)) Dance&lt;-factor(Dance, labels = c(&quot;No&quot;, &quot;Yes&quot;)) catsData&lt;-data.frame(Training, Dance) ## catsData Los datos completos gt(head(catsData, n=6)) #eurajpnjqv table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #eurajpnjqv thead, #eurajpnjqv tbody, #eurajpnjqv tfoot, #eurajpnjqv tr, #eurajpnjqv td, #eurajpnjqv th { border-style: none; } #eurajpnjqv p { margin: 0; padding: 0; } #eurajpnjqv .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #eurajpnjqv .gt_caption { padding-top: 4px; padding-bottom: 4px; } #eurajpnjqv .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #eurajpnjqv .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #eurajpnjqv .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #eurajpnjqv .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #eurajpnjqv .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #eurajpnjqv .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #eurajpnjqv .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #eurajpnjqv .gt_column_spanner_outer:first-child { padding-left: 0; } #eurajpnjqv .gt_column_spanner_outer:last-child { padding-right: 0; } #eurajpnjqv .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #eurajpnjqv .gt_spanner_row { border-bottom-style: hidden; } #eurajpnjqv .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #eurajpnjqv .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #eurajpnjqv .gt_from_md > :first-child { margin-top: 0; } #eurajpnjqv .gt_from_md > :last-child { margin-bottom: 0; } #eurajpnjqv .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #eurajpnjqv .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #eurajpnjqv .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #eurajpnjqv .gt_row_group_first td { border-top-width: 2px; } #eurajpnjqv .gt_row_group_first th { border-top-width: 2px; } #eurajpnjqv .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #eurajpnjqv .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #eurajpnjqv .gt_first_summary_row.thick { border-top-width: 2px; } #eurajpnjqv .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #eurajpnjqv .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #eurajpnjqv .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #eurajpnjqv .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #eurajpnjqv .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #eurajpnjqv .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #eurajpnjqv .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #eurajpnjqv .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #eurajpnjqv .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #eurajpnjqv .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #eurajpnjqv .gt_left { text-align: left; } #eurajpnjqv .gt_center { text-align: center; } #eurajpnjqv .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #eurajpnjqv .gt_font_normal { font-weight: normal; } #eurajpnjqv .gt_font_bold { font-weight: bold; } #eurajpnjqv .gt_font_italic { font-style: italic; } #eurajpnjqv .gt_super { font-size: 65%; } #eurajpnjqv .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #eurajpnjqv .gt_asterisk { font-size: 100%; vertical-align: 0; } #eurajpnjqv .gt_indent_1 { text-indent: 5px; } #eurajpnjqv .gt_indent_2 { text-indent: 10px; } #eurajpnjqv .gt_indent_3 { text-indent: 15px; } #eurajpnjqv .gt_indent_4 { text-indent: 20px; } #eurajpnjqv .gt_indent_5 { text-indent: 25px; } Training Dance Food as Reward Yes Food as Reward Yes Food as Reward Yes Food as Reward Yes Food as Reward Yes Food as Reward Yes Code gt(tail(catsData, n=5)) #mwlhnpmhwb table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #mwlhnpmhwb thead, #mwlhnpmhwb tbody, #mwlhnpmhwb tfoot, #mwlhnpmhwb tr, #mwlhnpmhwb td, #mwlhnpmhwb th { border-style: none; } #mwlhnpmhwb p { margin: 0; padding: 0; } #mwlhnpmhwb .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mwlhnpmhwb .gt_caption { padding-top: 4px; padding-bottom: 4px; } #mwlhnpmhwb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mwlhnpmhwb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mwlhnpmhwb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mwlhnpmhwb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mwlhnpmhwb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mwlhnpmhwb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mwlhnpmhwb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mwlhnpmhwb .gt_column_spanner_outer:first-child { padding-left: 0; } #mwlhnpmhwb .gt_column_spanner_outer:last-child { padding-right: 0; } #mwlhnpmhwb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mwlhnpmhwb .gt_spanner_row { border-bottom-style: hidden; } #mwlhnpmhwb .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #mwlhnpmhwb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mwlhnpmhwb .gt_from_md > :first-child { margin-top: 0; } #mwlhnpmhwb .gt_from_md > :last-child { margin-bottom: 0; } #mwlhnpmhwb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mwlhnpmhwb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mwlhnpmhwb .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mwlhnpmhwb .gt_row_group_first td { border-top-width: 2px; } #mwlhnpmhwb .gt_row_group_first th { border-top-width: 2px; } #mwlhnpmhwb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mwlhnpmhwb .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mwlhnpmhwb .gt_first_summary_row.thick { border-top-width: 2px; } #mwlhnpmhwb .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mwlhnpmhwb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mwlhnpmhwb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mwlhnpmhwb .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #mwlhnpmhwb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mwlhnpmhwb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mwlhnpmhwb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mwlhnpmhwb .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mwlhnpmhwb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mwlhnpmhwb .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mwlhnpmhwb .gt_left { text-align: left; } #mwlhnpmhwb .gt_center { text-align: center; } #mwlhnpmhwb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mwlhnpmhwb .gt_font_normal { font-weight: normal; } #mwlhnpmhwb .gt_font_bold { font-weight: bold; } #mwlhnpmhwb .gt_font_italic { font-style: italic; } #mwlhnpmhwb .gt_super { font-size: 65%; } #mwlhnpmhwb .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #mwlhnpmhwb .gt_asterisk { font-size: 100%; vertical-align: 0; } #mwlhnpmhwb .gt_indent_1 { text-indent: 5px; } #mwlhnpmhwb .gt_indent_2 { text-indent: 10px; } #mwlhnpmhwb .gt_indent_3 { text-indent: 15px; } #mwlhnpmhwb .gt_indent_4 { text-indent: 20px; } #mwlhnpmhwb .gt_indent_5 { text-indent: 25px; } Training Dance Affection as Reward No Affection as Reward No Affection as Reward No Affection as Reward No Affection as Reward No Nota que aquí se llama cada columna aparte en la función (catsData\\(Training, catsData\\)Dance). 11.14 Prueba de independencia Code # usando los datos en formato de data frame **catsData** CrossTable(catsData$Training, catsData$Dance, fisher = TRUE, chisq = TRUE, expected = TRUE, sresid = TRUE, format = &quot;SPSS&quot;) ## ## Cell Contents ## |-------------------------| ## | Count | ## | Expected Values | ## | Chi-square contribution | ## | Row Percent | ## | Column Percent | ## | Total Percent | ## | Std Residual | ## |-------------------------| ## ## Total Observations in Table: 200 ## ## | catsData$Dance ## catsData$Training | No | Yes | Row Total | ## --------------------|-----------|-----------|-----------| ## Food as Reward | 28 | 10 | 38 | ## | 14.440 | 23.560 | | ## | 12.734 | 7.804 | | ## | 73.684% | 26.316% | 19.000% | ## | 36.842% | 8.065% | | ## | 14.000% | 5.000% | | ## | 3.568 | -2.794 | | ## --------------------|-----------|-----------|-----------| ## Affection as Reward | 48 | 114 | 162 | ## | 61.560 | 100.440 | | ## | 2.987 | 1.831 | | ## | 29.630% | 70.370% | 81.000% | ## | 63.158% | 91.935% | | ## | 24.000% | 57.000% | | ## | -1.728 | 1.353 | | ## --------------------|-----------|-----------|-----------| ## Column Total | 76 | 124 | 200 | ## | 38.000% | 62.000% | | ## --------------------|-----------|-----------|-----------| ## ## ## Statistics for All Table Factors ## ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 25.35569 d.f. = 1 p = 4.767434e-07 ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ------------------------------------------------------------ ## Chi^2 = 23.52028 d.f. = 1 p = 1.236041e-06 ## ## ## Fisher&#39;s Exact Test for Count Data ## ------------------------------------------------------------ ## Sample estimate odds ratio: 6.579265 ## ## Alternative hypothesis: true odds ratio is not equal to 1 ## p = 1.311709e-06 ## 95% confidence interval: 2.837773 16.42969 ## ## Alternative hypothesis: true odds ratio is less than 1 ## p = 0.9999999 ## 95% confidence interval: 0 14.25436 ## ## Alternative hypothesis: true odds ratio is greater than 1 ## p = 7.7122e-07 ## 95% confidence interval: 3.193221 Inf ## ## ## ## Minimum expected frequency: 14.44 Code # Se puede hacer un grafico de los resultados Ta2= xtabs(~Training+Dance, data=catsData) Ta2 ## Dance ## Training No Yes ## Food as Reward 28 10 ## Affection as Reward 48 114 Code mosaicplot(Ta2, shade=TRUE) 11.15 El color de pello es independiente del sexo En la siguiente tabla se encuentra el color de pello de estudiantes de la UPR. La hipótesis es que el color de pelo no esta asociado al sexo de los estudiantes. Color de Pello Mujer Hombre Negro 32 55 Marrón 43 65 Rubio 16 64 Rojo 9 16 Creamos Code Negro=c(32,55) Marron=c(43, 65) Rubio=c(16,64) Rojo=c(9,16) HairColour=cbind(Negro,Marron, Rubio,Rojo) rownames(HairColour)&lt;-c(&quot;Mujer&quot;, &quot;Hombre&quot;) # Añade el nombre a las filas HairColour ## Negro Marron Rubio Rojo ## Mujer 32 43 16 9 ## Hombre 55 65 64 16 ¿Cual es la hipótesis nula? ¿Cual es la hipótesis alterna? El resultado de la prueba. ¿Se acepta o rechaza la hipótesis nula? Code CrossTable(HairColour, fisher = TRUE, chisq = TRUE, expected = TRUE, sresid = TRUE, format = &quot;SPSS&quot;) ## ## Cell Contents ## |-------------------------| ## | Count | ## | Expected Values | ## | Chi-square contribution | ## | Row Percent | ## | Column Percent | ## | Total Percent | ## | Std Residual | ## |-------------------------| ## ## Total Observations in Table: 300 ## ## | ## | Negro | Marron | Rubio | Rojo | Row Total | ## -------------|-----------|-----------|-----------|-----------|-----------| ## Mujer | 32 | 43 | 16 | 9 | 100 | ## | 29.000 | 36.000 | 26.667 | 8.333 | | ## | 0.310 | 1.361 | 4.267 | 0.053 | | ## | 32.000% | 43.000% | 16.000% | 9.000% | 33.333% | ## | 36.782% | 39.815% | 20.000% | 36.000% | | ## | 10.667% | 14.333% | 5.333% | 3.000% | | ## | 0.557 | 1.167 | -2.066 | 0.231 | | ## -------------|-----------|-----------|-----------|-----------|-----------| ## Hombre | 55 | 65 | 64 | 16 | 200 | ## | 58.000 | 72.000 | 53.333 | 16.667 | | ## | 0.155 | 0.681 | 2.133 | 0.027 | | ## | 27.500% | 32.500% | 32.000% | 8.000% | 66.667% | ## | 63.218% | 60.185% | 80.000% | 64.000% | | ## | 18.333% | 21.667% | 21.333% | 5.333% | | ## | -0.394 | -0.825 | 1.461 | -0.163 | | ## -------------|-----------|-----------|-----------|-----------|-----------| ## Column Total | 87 | 108 | 80 | 25 | 300 | ## | 29.000% | 36.000% | 26.667% | 8.333% | | ## -------------|-----------|-----------|-----------|-----------|-----------| ## ## ## Statistics for All Table Factors ## ## ## Pearson&#39;s Chi-squared test ## ------------------------------------------------------------ ## Chi^2 = 8.987184 d.f. = 3 p = 0.02946177 ## ## ## ## Fisher&#39;s Exact Test for Count Data ## ------------------------------------------------------------ ## Alternative hypothesis: two.sided ## p = 0.02410446 ## ## ## Minimum expected frequency: 8.333333 11.16 Prueba de Exacta de Fisher La prueba Exacta de Fisher es similar a la prueba de Bondad de Ajuste para evaluar si hay asociación entre dos variables categorías. La diferencia importante es que no es necesario que el valor esperado sea mayor de 5. Por consecuencia se puede usar con muestras más pequeñas. 11.16.1 Los supuestos de las prueba Exacta de Fisher. Los datos son frecuencias. Las frecuencias son mutuamente exclusivas (no caen en múltiples categorías). Las observaciones son independiente una de la otra. La tabla tiene 2 filas y 2 columnas. Usando los datos de serpientes del ejemplo 7.4 del libro de Havel et al.  Code responde &lt;- c(6,3) no_responde &lt;- c(1,6) serpiente &lt;- cbind(responde, no_responde) rownames(serpiente)&lt;-c(&quot;Estimulo_ariba&quot;, &quot;Estimulo_lateral&quot;) # Añade el nombre a las filas serpiente ## responde no_responde ## Estimulo_ariba 6 1 ## Estimulo_lateral 3 6 Se puede visualizar los datos con el Mosaico Code mosaicplot(serpiente) Nota que se usa la misma función que anterior pero en los resultados hay que fijarse en la sección que dice Fisher’s Exact test. Lo que uno observa es que el valor de p es menor de 0.05 por consecuencia se rechaza la hipótesis nula. Lo que significa es que para la serpiente el angulo donde proviene el estimulo resulta en una repuesta diferente. Code fisher.test(serpiente) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: serpiente ## p-value = 0.06014 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.7110878 638.2231455 ## sample estimates: ## odds ratio ## 10.02595 "],["distribución-normal.html", "Chapter 12 Distribución Normal 12.1 Instalar y activar los siguientes paquete 12.2 La distribución normal 12.3 Evaluando visualmente la distribución 12.4 Añadiendo la distribución teórica al histograma 12.5 Evaluando datos no normal 12.6 Datos teóricos con histograma y la función de normalidad 12.7 qqplot 12.8 Pruebas de normalidad. 12.9 La prueba de Shapiro-Wilks 12.10 La prueba de normalidad de Anderson-Darling", " Chapter 12 Distribución Normal 12.1 Instalar y activar los siguientes paquete Code if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load( car, GGally, ggversa, pastecs, psych, pander, ggplot2, nortest, Hmisc, boot, knitr,tidyverse, gt, gridExtra) Activar los Paquetes Code library(nortest) # paquete para probar la normalidad library(car) # paquete para análisis de correlación library(ggplot2) # paquete para visualizar los datos library(ggversa) # paquete para diferentes conjuntos de datos library(GGally) # Un paquete basado un ggplot2 para visualizar correlaciones library(pastecs) # paquete para análisis tiempo-espacial usado en ecología library(psych) # paquete para análisis psicométrica, psicológica y de personalidad library(Hmisc) # Un grupo de función prácticos para gráficos y tablas library(boot) # paquete para calcular los intervalos usando &quot;bootstrap&quot; library(knitr) # un grupo de función para incluyendo tablas bonitas con kable. library(tidyverse) library(gt) library(gridExtra) 12.2 La distribución normal Es modulo está enfocado en entender diferentes aspectos de la distribución normal. Muchas pruebas como la prueba de t, correlaciones, regresiones y ANOVA depende que algunos de los conjuntos de datos cumple con una distribución normal. Este tipo de pruebas se pueden referir a pruebas paramétricas. La distribución normal tiene una ecuación que describe su distribución. Lo que que se observa es que la ecuación depende de solamente dos valores desconocidos, el promedio universal, µ y la desviación universal \\(\\sigma\\). Nota que aquí estamos considerando todos los datos sobre un variable. Por ejemplo si esta hablando de del tamaño de un especie de pájaro ( El quetzal), es que tendríamos que tener TODOS los datos de cada uno de ellos. Primero vemos como se ve esta distribución y después explicamos porque aunque no tenemos todos los datos una aproximación es suficiente. \\[P(x)=\\frac{1}{{\\sigma\\sqrt{ 2\\pi}}}{e}^{-\\frac{{(x-µ)}^{2}}{{2\\sigma}^{2}}}\\] El promedio de la población \\(\\mu=\\frac{\\sum{{x}_{i}}}{{n}_{i}}\\), se usa la letra “mu”, y se refiere al promedio universal. Esto quiere decir que no falta ningún dato. Nota que la distribución es en forma de campana, donde 50% de los datos están por encima del promedio y 50% están por debajo el promedio. Debido que la distribución tiene unos parámetros específico se puede predecir información cuando los datos cumple con tal distribución. Code set.seed(12345) dfnorm=rnorm(1000000, 0,1) dfnorm=data.frame(dfnorm) ggplot(dfnorm,(aes(x=dfnorm)))+ geom_density()+ geom_vline(xintercept = 0, colour=&quot;red&quot;)+ annotate(&quot;text&quot;, x=.8, y = .1, label=&quot;50% de los \\n valores&quot;)+ annotate(&quot;text&quot;, x=-.8, y = .1, label=&quot;50% de los \\n valores&quot;)+ xlab(&quot;algun valor&quot;)+ ylab(&quot;densidad&quot;) 12.3 Evaluando visualmente la distribución El primer paso de cada investigación es evaluar si los supuestos se cumplen. Si las pruebas necesitan tener una distribución normal uno de los métodos más sencillo construir un histograma de los datos. Usaremos datos que hemos visto en el modulo T5. Se necesita el archivo DownloadFestival que se encuentra debajo la pestaña de Los Datos. El ejemplo proviene de Field et al. (2014). Una bióloga estaba preocupado por los posibles efectos sobre la salud de los que particpan a un festivales de música. Entonces, un año fue al Download Festival en el Reino Unido (Download Festival UK). Ella midió la higiene del los que participaron al concierto n= 810 durante el festival de 3 días. Cada día intentaba encontrar a todas las personas que censó el primer día. Los valores asignado fueron de 0 a 4 sobre el nivel de limpieza por como olia los participantes 0 = hueles como un cadáver. 4 = hueles a rosas dulces en un fresco día de primavera Code library(readr) DownloadFestival_No_Outlier_ &lt;- read_csv(&quot;Data_files_csv/DownloadFestival_No_Outlier.csv&quot;) dlf=DownloadFestival_No_Outlier_ #usamos un nombre más corta para facilitar head(dlf) # ver las 3 primeras filas ## # A tibble: 6 × 5 ## ticknumb gender day1 day2 day3 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2111 Male 2.64 1.35 1.61 ## 2 2229 Female 0.97 1.41 0.29 ## 3 2338 Male 0.84 NA NA ## 4 2384 Female 3.03 NA NA ## 5 2401 Female 0.88 0.08 NA ## 6 2405 Male 0.85 NA NA Se nota en el histograma que la mayoría de los datos de la higiene de los participantes en el primer día se parece bastante a una distribución normal. Nota que los valores en el eje de y es la frecuencia de los valores en el conjunto de datos. Code ggplot(dlf, aes(day1))+ geom_histogram(color=&quot;white&quot;, fill=&quot;red&quot;) *** 12.4 Añadiendo la distribución teórica al histograma Ahora vamos a añadir la siguiente formula al gráfico \\(P(x)=\\frac{1}{{\\sigma\\sqrt{ 2\\pi}}}{e}^{-\\frac{{(x-µ)}^{2}}{{2\\sigma}^{2}}}\\). De esta forma podemos comparar los datos reales (las barras roja) con la distribución teorica si el promedio y la desviación estandar es igual a los datos. Se añade el promedio y la desviación estándar con la siguientes funciones. La función *stat_function()** es para calcular parámetros. stat_function(fun = dnorm, # dnorm = la densidad de la distribución normal args = list( mean = mean(dlf$day2, na.rm = TRUE), # mean = el promedio de los datos sd = sd(dlf$day2, na.rm = TRUE))) # sd = la desviación estandar de los datos Ahora nota que el eje de y no son frecuencias pero son densidades. La suma de todas las densidades es igual a 1.0. Vea que la linea teórica se acerca bastante a las barras del histograma. Este proceso NO es una prueba para determinar si los datos cumple con una distribución normal. Aunque con experiencia visualizando los datos uno puede tener un buen apreciación si los datos cumple suficientemente con la distribución normal para usar las pruebas paramétricas. Code hist.dlfc1 &lt;- ggplot(dlf, aes(day1)) + geom_histogram(aes(y=..density..), colour=&quot;white&quot;, fill=&quot;red&quot;) + labs(x=&quot;Higiene día 1&quot;, y = &quot;Densidad&quot;)+ stat_function(fun = dnorm, args = list(mean = mean(dlf$day1, na.rm = TRUE), sd = sd(dlf$day1, na.rm = TRUE)), colour = &quot;green&quot;, size = 1) hist.dlfc1 12.5 Evaluando datos no normal Usamos los datos del segundo día y comparamos con el primer día. En este caso vemos que los datos no siguen una distribución normal están sesgados a la izquierda y vemos que “falta” valores pequeños, en otra palabra en este caso los valores negativos. Evalúa y compara con el día tres Code hist.dlfc2 &lt;- ggplot(dlf, aes(day2)) + geom_histogram(aes(y=..density..), colour=&quot;white&quot;, fill=&quot;blue&quot;) + labs(x=&quot;Higiene día 2&quot;, y = &quot;Densidad&quot;)+ stat_function(fun = dnorm, args = list(mean = mean(dlf$day2, na.rm = TRUE), sd = sd(dlf$day2, na.rm = TRUE)), colour = &quot;yellow&quot;, size = 2) hist.dlfc2 12.6 Datos teóricos con histograma y la función de normalidad Aquí creo una conjunto de datos al azar con la función rnorm y se presenta un histograma y se añade la linea teórica de la distribución normal. La función rnorm creea una lista de datos una promedio y una dispersión específica. rnorm(n, mean, sd) rnorm = (la cantidad de datos generados, promedio, la desviación estandard) Es necesario convertir la lista en un data.frame en un tibble para usar los datos en ggplot2. Como los datos provienen de una distribución normal la linea teórica (casi) sigue perfectamente las barras de frecuencia. Más datos que uno tiene más similar las distribución observada (las barras) a la distribución teórica (la linea). Haz unos ejercicio de reducir y aumentar el tamaño de muestra, n y compara las distribuciones. Evalúa cuando cuando son muy pequeño (n de 30 o menos). Code #rnorm(10, 100, 10) x=rnorm(10000, 10, 2) dfx=as.tibble(x) gt(head(dfx, n=3)) # Los primeros 3 datos del tibble #djmqwlxojf table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #djmqwlxojf thead, #djmqwlxojf tbody, #djmqwlxojf tfoot, #djmqwlxojf tr, #djmqwlxojf td, #djmqwlxojf th { border-style: none; } #djmqwlxojf p { margin: 0; padding: 0; } #djmqwlxojf .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #djmqwlxojf .gt_caption { padding-top: 4px; padding-bottom: 4px; } #djmqwlxojf .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #djmqwlxojf .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #djmqwlxojf .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #djmqwlxojf .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #djmqwlxojf .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #djmqwlxojf .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #djmqwlxojf .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #djmqwlxojf .gt_column_spanner_outer:first-child { padding-left: 0; } #djmqwlxojf .gt_column_spanner_outer:last-child { padding-right: 0; } #djmqwlxojf .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #djmqwlxojf .gt_spanner_row { border-bottom-style: hidden; } #djmqwlxojf .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #djmqwlxojf .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #djmqwlxojf .gt_from_md > :first-child { margin-top: 0; } #djmqwlxojf .gt_from_md > :last-child { margin-bottom: 0; } #djmqwlxojf .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #djmqwlxojf .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #djmqwlxojf .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #djmqwlxojf .gt_row_group_first td { border-top-width: 2px; } #djmqwlxojf .gt_row_group_first th { border-top-width: 2px; } #djmqwlxojf .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #djmqwlxojf .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #djmqwlxojf .gt_first_summary_row.thick { border-top-width: 2px; } #djmqwlxojf .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #djmqwlxojf .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #djmqwlxojf .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #djmqwlxojf .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #djmqwlxojf .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #djmqwlxojf .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #djmqwlxojf .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #djmqwlxojf .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #djmqwlxojf .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #djmqwlxojf .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #djmqwlxojf .gt_left { text-align: left; } #djmqwlxojf .gt_center { text-align: center; } #djmqwlxojf .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #djmqwlxojf .gt_font_normal { font-weight: normal; } #djmqwlxojf .gt_font_bold { font-weight: bold; } #djmqwlxojf .gt_font_italic { font-style: italic; } #djmqwlxojf .gt_super { font-size: 65%; } #djmqwlxojf .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #djmqwlxojf .gt_asterisk { font-size: 100%; vertical-align: 0; } #djmqwlxojf .gt_indent_1 { text-indent: 5px; } #djmqwlxojf .gt_indent_2 { text-indent: 10px; } #djmqwlxojf .gt_indent_3 { text-indent: 15px; } #djmqwlxojf .gt_indent_4 { text-indent: 20px; } #djmqwlxojf .gt_indent_5 { text-indent: 25px; } value 8.776594 6.691068 9.287899 Code library(ggplot2) hist.x &lt;- ggplot(dfx, aes(value)) + theme(legend.position = &quot;none&quot;) + geom_histogram(aes(y=..density..), bins=40,colour=&quot;black&quot;, fill=&quot;white&quot;) + labs(x=&quot;Variable&quot;, y = &quot;Densidad&quot;)+ stat_function(fun = dnorm, args = list(mean = mean(dfx$value, na.rm = TRUE), sd = sd(dfx$value, na.rm = TRUE)), colour = &quot;red&quot;, size = 1) hist.x 12.7 qqplot El gráfico Q-Q, o gráfico cuantil-cuantil, es una herramienta gráfica que nos ayuda a evaluar si un conjunto de datos proviene de alguna distribución teórica. Por ejemplo, si ejecutamos un análisis estadístico que asume que nuestra variable dependiente está normalmente distribuida, podemos usar un gráfico Q-Q normal para verificar esa suposición, se puede también evaluar otras distribuciones. Nota que es solo una verificación visual, no una prueba estadística. Esto nos permite visualizar si los datos cumple si o no con la distribución teórica. Un diagrama Q-Q es un diagrama de dispersión y compara dos conjuntos de cuantiles uno observado y el otro teórico. Si ambos conjuntos de cuantiles provienen de una distribución normal, deberíamos ver los puntos formando una línea que es más o menos recta. Usamos los datos del primer y el segundo día de la higiene de los participantes al concierto de rock. Vean que los puntos están en el primer gráfico siguen una linea recta y la linea teórica (color azul) sigue estos puntos. Esto sugiere que los datos siguen una distribución normal. En el segundo gráfico vemos que los datos observados no siguen los datos teóricos (color rojo). Code d=ggplot(dlf, aes(sample=day1))+ geom_qq()+ geom_qq_line(colour=&quot;blue&quot;) e=ggplot(dlf, aes(sample=day2))+ geom_qq()+ geom_qq_line(colour=&quot;red&quot;) grid.arrange(d,e, ncol=2) 12.8 Pruebas de normalidad. Los ejemplos arriba no son pruebas, son visualización de los datos y con experiencia uno puede reconocer los con juntos de datos que cumple o no con una distribución normal. Al principio, cuando uno comienza a estudiar la estadística esto puede ser un poco confuso. Hay pruebas donde uno puede utiliza para evaluar y rechazar o aceptar si los datos cumple con distribución normal. Estos se introduce ahora por qué muchas de estas pruebas tienden a tener un tipo de error Tipo II alto. En otra palabra se rechaza la hipótesis nula (los datos provienen de una distribución normal) cuando son suficiente normal para las pruebas que se van a usar. Vamos a ver dos de estas pruebas aunque hay muchos en la literatura. Por ejemplo Wikipedia menciona por lo menos 8 diferentes pruebas de normalidad https://en.wikipedia.org/wiki/Normality_test. 12.9 La prueba de Shapiro-Wilks La prueba de Shapiro-Wilk es un prueba para determinar si un muestreo proviene de una distribución normal. Los datos se ponen en orden de los valores y se calcula el estadística de W. Aquí no vamos enseñar como hacer los cálculos los que le interesa pueden ir al a la siguiente pagina de https://en.wikipedia.org/wiki/Shapiro–Wilk_test. Lo importante es que Ho: los datos no son diferentes de una distribución normal Ha: los datos no concuerda con una distribución normal. Por consecuencia si se rechaza la hipótesis nula uno dice que los datos no cumplen con una distribución normal. Problemas con la prueba. La prueba es sensitiva al tamaño de muestra. Esto quiere decir que cando el tamaño de muestra es demasiado pequeño o grande tiende a dar errores de Tipo II y Tipo I respectivamente. Reglas básica. 1. no utilizar la prueba si el tamaño de muestra es menor de 50 2. no utilizar la prueba si el tamaño de muestra de muy grande (mayor de 200) a. Nota que algunos programa han podido hacer modificación a la formula y ahora se puede utilizar tamaño de muestra hasta 2000 (Stata, SPSS, SAS). La función shapiro.test() es para evaluar una variable a la vez. Nota que aquí los datos de higiene del primer día sugiere que no cumple con una distribución normal. Cuando las dos alternativas anteriores los daots se ven bastante norma (histograma y qqplot) Code shapiro.test(dlf$day1) ## ## Shapiro-Wilk normality test ## ## data: dlf$day1 ## W = 0.99592, p-value = 0.03198 Code length(dlf$day1) ## [1] 810 12.10 La prueba de normalidad de Anderson-Darling La prueba de Anderson-Darling es una prueba omnibus (una prueba general) EDF para la hipótesis que los datos provienen de una distribución normal. Las pruebas ómnibus son una especie de prueba estadística. Prueban si la varianza explicada en un conjunto de datos es significativamente mayor que la varianza inexplicada, en general. Para más detalle sobre esta prueba vea https://en.wikipedia.org/wiki/Anderson–Darling_test. Se necesita la librería nortest y la función ad.test Miran ahora que la distribución de los datos cumplen con normalidad cuando la de Shapiro-Wilk rechaza la hipótesis nula. El mensaje es que es posible que diferentes pruebas le den información distinta y hay que estar claro sobre los supuestos y la sensitividad de estas pruebas. La prueba de Anderson Darling es una de las más poderosas para evaluar si los datos provienen de una distribución normal. D’Agostino (1986) sugiere que la prueba puede ser utilizada con tamaño de muestra tan bajo como n=8. *Ralph B. D&#39;Agostino (1986). &quot;Tests for the Normal Distribution&quot;. In D&#39;Agostino, R.B.; Stephens, M.A. (eds.). Goodness-of-Fit Techniques. New York: Marcel Dekker. ISBN 0-8247-7487-6.* Code library(nortest) ad.test(dlf$day1) ## ## Anderson-Darling normality test ## ## data: dlf$day1 ## A = 0.53944, p-value = 0.1661 "],["prueba-de-una-muestra.html", "Chapter 13 Prueba de una muestra 13.1 El promedio, un estimado 13.2 Ejemplo 9.1 y 9.2. 13.3 La distribución de t 13.4 Cuando es que uno rechaza la hipótesis nula 13.5 El intervalo de confianza de \\(\\mu\\) 13.6 Ejemplo 9.3 13.7 Los limites del intervalo 13.8 El limite superior 13.9 El limite inferior 13.10 Menos o más grados de libertad 13.11 Muchos muestreos y el universo 13.12 Pruebas de t un muesteo 13.13 Propinas 13.14 ¿Cómo graficar el resultado de una prueba t? 13.15 Ejercicio de práctica 1: Amigos de Facebook 13.16 Ejercicio de práctica 2: Dias de enfermedades", " Chapter 13 Prueba de una muestra Code library(gridExtra) library(tidyverse) Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; 13.1 El promedio, un estimado En este modulo se evalúa el promedio y la propriedades de una distribución normal y el muestreo de para estimar el promedio. En el módulo se evalúa la hipótesis de un muestreo y se estima el intervalo de confianza para estimar el posible rango del promedio. Es importante reconocer que el muestreo para estimar el promedio \\(\\overline{x}\\) es solamente un estimado. En otra palabra no es necesariamente la VERDAD, o dicho de forma estadística, el promedio del universo, \\(\\mu\\) de esta variable. Con frecuencia se quiere saber conocer información sobre el verdadero promedio, \\(\\mu\\) basado en un muestreo. Por ejemplo cual es promedio de la edad de las Palmas de Sierra en Puerto Rico, cual es el promedio de la presión arterial de los humanos, cual es la producción promedio de mangos en los arboles de mangos. En cada caso no sabemos cual es el promedio universal, \\(\\mu\\) y tampoco no sabemos el valor exacto de la desviación estándar \\(\\sigma\\). Para evaluar la hipótesis sobre el promedio de la población \\(\\mu\\), uno puede utilizar datos recogido al azar, un muestreo y usar estos para inferir cual es el promedio y desviación estándar del universo. 13.2 Ejemplo 9.1 y 9.2. Leen estos dos ejercicios, y considera cual es son los valores del universo,\\(\\mu\\) y \\(\\sigma\\) y el promedio del muestreo \\(\\overline{x}\\). 13.3 La distribución de t Cuando queremos inferir información del promedio o la desviación del universo de un muestreo hay que utilizar la distribución de t. La razón es que la forma de la distribución normal cambia con el tamaño de muestra cuando no sabemos cual es la desviación estándar del universo. A medida que uno reduce el tamaño de muestra la distribución se desvía de una distribución normal. Para tomar esto en cuenta no usamos la distribución normal la de distribución de t, también se dice la distribución de t de estudiante. Code ggplot(out,aes(df1x, val, colour=df) )+ geom_line()+ rlt_theme+ scale_colour_manual(name = &quot;Grado de \\nlibertad&quot;, values = c(&quot;blue&quot;, &quot;red&quot;, &quot;springgreen4&quot;, &quot;black&quot;), labels = expression(nu[1], nu[2],nu[5], nu[infinity]))+ theme(legend.position = c(0.8, 0.8))+ xlab(&quot;Valores&quot;)+ ylab(&quot;Densidad&quot;) Observa que la distribución de t, cuando cambio el tamaño de muestra, (grado de libertad es \\(\\nu=n-1\\)). Tiene que observar dos componentes 1. hay menos datos en centrado en el promedio y 2. hay más datos en la colas. Se usa la distribución de t para calcular el intervalo de confianza y la hipótesis del promedio de una muestra, debido que la forma de la distribución de t cambia con el tamaño de muestra \\(\\nu=n-1\\) y también con la razón de error Tipo I, \\(\\alpha\\). 13.4 Cuando es que uno rechaza la hipótesis nula Regresamos a la idea de Tipo de error I. Cuando se selecciona un \\(\\alpha=0.05\\), lo que estamos diciendo es que hay 5% de probabilidad de cometer un error Tipo 1, que es de rechazar la hipótesis nula cuando uno debería aceptarla. Ahora este 5% puede estar divido en dos componentes, uno cuando el valor es más pequeño o más grande que el valor observado. Por consecuencia el área de rechazar la hipótesis nula es 0.025 en la parte negativa y positiva. Seleccionamos la curva con un grado de libertad de 5 y evaluamos el área de la curva que esta dentro del 95% del intervalo de confianza y lo fuera de este rango. Si el promedio estimado de una prueba de t es dentro del área en gris se aceptará la hipótesis nula, si esta en el área rojo se rechazara la hipótesis nula. NOta que para esta hipótesis hay son maneras de rechazar la hipótesis nula. La alternativa es que nuestra hipótesis sea nada más de un lado donde el total del 5% es en la parte inferior o superior. En esta caso se rechaza solamente si se encuentra en esta proporción de los valores de t. Nota ahora que el área en esta sección es más grande (incluye más valores, no solamente el 2.5% pero el 5% de los valores). 13.5 El intervalo de confianza de \\(\\mu\\) Ahora se demuestra como calcular el intervalo de confianza de \\(\\mu\\). Seleccionando un conjunto de datos al azar n se puede calcular el promedio \\(\\overline{x}\\) y el estimado de la desviación estándar s, con estos valores podemos calcular el rango donde pudiese estar el promedio del universo \\(\\mu\\) con cieto nivel de confianza (Tipo de Error I, \\(\\alpha\\)). 13.6 Ejemplo 9.3 Se selecciona 20 peces machos de una misma especie en un riachuelo de Puerto Rico y se mide el largo en millimetros. El promedio es \\(\\overline{x}=21.0mm\\) y una desviación estándar \\(s=1.76mm\\). Queremos construir in intervalo de confianza de 95%. El tamaño de los peces es aproximadamente normal. Queremos calcular intervalo que incluye 95%, por consecuencia es el rango que hay en el área gris de la primera figura. 13.7 Los limites del intervalo Para calcular el intervalo se necesita solamente el valor de t con la tipo de error I de 95% y que corresponde a un tamaño de muestra de 20, \\(t_{0.05,\\ n-1}\\). Para conocer este valor hay que ir a una tabla de la distribución de t (vea p. 217 en el libro) o usar R para calcular el valor. En la tabla busca el error I deseado (0.05) y se busca el grado de libertad n-1, \\(t_{0.05,\\ 19}\\). El valor del libro es \\(t = 2.093\\). Si se quisiera un Tipo de error I con solamente 1% error el valor seria \\(t=2.8609\\), (busca la información en la tabla, o usando la función qt()). Code abs(qt(0.025, 19)) # nota que se usa la mitad de 0.05, por que es una prueba de dos lados. ## [1] 2.093024 Code 21+abs(qt(0.025, 19)*(1.76/sqrt(20))) ## [1] 21.82371 13.8 El limite superior Ahora falta sustituir los valores en la formula \\[UL_{0.95}=\\overline{x}+\\left(t_{0.05,\\ n-1}\\cdot\\frac{s}{\\sqrt{n}}\\right)\\] \\[UL_{0.95}=21+2.093*\\left(\\frac{1.76}{\\sqrt{20}}\\right)=21.823\\] 13.9 El limite inferior \\[LL_{0.95}=\\overline{x}-\\left(t_{0.05,\\ n-1}\\cdot\\frac{s}{\\sqrt{n}}\\right)\\] \\[LL_{0.95}=21-2.093*\\left(\\frac{1.76}{\\sqrt{20}}\\right)=20.176\\] El intervalo de confianza del \\(\\mu\\) es entre 20.175-21.825 con un 95% de probabilidad. Code UL=20+abs(qt(0.025, 19)*1.76/sqrt(20)) LL=20-abs(qt(0.025, 19)*1.76/sqrt(20)) UL ## [1] 20.82371 Code LL ## [1] 19.17629 13.10 Menos o más grados de libertad Nota lo que pasa si uno tiene menos datos o más datos con el intervalo de confianza. Con un tamaño de muestra solamente de 5 datos el IC de 95% es entre 17.824-22.185. Por tener menos datos tenemos menos confianza donde se entra el promedio del universo. Code UL=21+qt(0.025, 4)*1.76/sqrt(5) LL=21-qt(0.025, 4)*1.76/sqrt(5) UL ## [1] 18.81467 Code LL ## [1] 23.18533 Ahora con en tamaño de muestra de 100. Ahora el intervalo de confianza esta más estrecho 19.651-20.349 Code UL=21+qt(0.025, 99)*1.76/sqrt(100) LL=21-qt(0.025, 99)*1.76/sqrt(100) UL ## [1] 20.65078 Code LL ## [1] 21.34922 13.11 Muchos muestreos y el universo Para demostrar lo que quiere decir el intervalo de confianza evaluamos el siguiente gráfico. Cada linea horizontal representa un muestreo independiente, la pequeña linea vertical representa el promedio de este muestreo \\(\\overline{x}\\), y la linea vertical que cruza todos los muestreos representa el promedio universal \\(\\mu\\). Nota que este caso el intervalo de confianza casi siempre cruza el \\(\\mu\\), aparte de uno. El muestreo aunque proviene de la misma población no incluyo el promedio del universo. Figure 13.1: Su promedio incluye el promedio del universo? 13.11.1 QUIZ: estas preguntas la tienen que contestar en una asignación. Title: Ultrasound evaluation of the morphometric patterns of lymph nodes of the head and neck in young and middle-aged individuals. Ogassavara et al. 2016, 49:225-228, Radiologia Brasileira. doi: 10.1590/0100-3984.2015.0002. En este trabajo evaluaron los ganglios linfáticos de 20 individuos sanos. Encontraron que la media de los ganglios linfáticos mastoideos de los hombres era de 0,9 cm con una desviación estándar de 0,4 cm. ¿Cuál es el intervalo de confianza al 95% de los ganglios linfáticos mastoideos en hombres? . Usando los mismo datos de la pregunta #1. Title: Ultrasound evaluation of the morphometric patterns of lymph nodes of the head and neck in young and middle-aged individuals. Ogassavara et al. 2016, 49:225-228, Radiologia Brasileira. doi: 10.1590/0100-3984.2015.0002. En este trabajo evaluaron los ganglios linfáticos de 20 individuos sanos. Encontraron que la media de los ganglios linfáticos mastoideos de los hombres era de 0,9 cm con una desviación estándar de 0,4 cm. Ya se pudo medir el tamaño de los ganglios linfáticos mastoideos de TODOS los hombres del planeta, y se determino que que el promedio es de 0.7 cm con una desviación estándar de 0,2 cm. Usando los siguientes datos haga la prueba correspondiente en R para determinar el valor de t, observado y el valor critico. 13.12 Pruebas de t un muesteo Esta prueba esencialmente calcula la media de los datos y crea un intervalo de confianza. Si el valor que estamos probando cae dentro de ese intervalo de confianza, concluimos que es el valor verdadero para la media de los datos; de lo contrario, concluimos que no es la verdadera media. Nota que la \\(\\mu\\) representa el modelo nulo, o sea la hipótesis nula. Si \\(\\mu=0\\) decimos que el universo es igual cero. En otro ejemplo si por ejemplo decimos que el promedio del nivel de colesterol en mujer es \\(\\mu=209.4\\) y observamos en muestreo de mujeres un promedio de \\(\\overline{x}= 196.7\\) con una desviación estándar de \\(s=39.1\\). Eso suficiente la diferencia para decir que lo que UD observo es significativamente diferente del muestreo del universo a un 95% de error \\(\\alpha\\)? Vamos asumir que se hizo una investigación un gran número de mujeres de Puerto Rico y se tiene un muestreo de 10,000 de mujeres. Lo que necesitamos hacer ahora es sustituir los valores en la formula. Observamos un valor de t observado de t=32.48 (el valor es absoluto), y este los comparamos con el valor de t critico = 1.96 (valor absoluto). El resultado: el valor de t observado es mayor del valor critico y por consecuencia rechazamos lo hipótesis nula, y concluimos que el nivel de colesterol en la muestra \\(\\overline{x}= 196.7\\) es significativamente diferente del nivel universal \\(\\mu=209.4\\). Ho: \\(\\overline{x}=\\mu\\) Ha: \\(\\overline{x}≠\\mu\\) \\[|t|=\\frac{\\left(\\overline{x}-\\mu_0\\right)}{\\frac{s}{\\sqrt{n}}}\\] Sustitución de los valores en la prueba de t. Code t=abs((196.7-209.4)/((39.1)/sqrt(30)) ) t # Valor t de observado ## [1] 1.779048 Code abs(qt(0.025, 29)) # valor de t-critico, de la tabla ## [1] 2.04523 13.13 Propinas Un ejemplo con datos en una tabla Usamos un conjunto de datos en el paquete reshape, que llama tips. Se refiere a las propinas que recibe los meseros. Nuestra hipótesis es que en promedio, las personas dan una propina de $2.50, Esta es nuestra hipótesis nula Nuestra hipótesis alternativa es que las personas dan significativamente más o menos de $2.50. Ho: \\(\\overline{x}=\\mu\\) Ha: \\(\\overline{x}≠\\mu\\) Code data(tips, package=&quot;reshape2&quot;) head(tips) ## total_bill tip sex smoker day time size ## 1 16.99 1.01 Female No Sun Dinner 2 ## 2 10.34 1.66 Male No Sun Dinner 3 ## 3 21.01 3.50 Male No Sun Dinner 3 ## 4 23.68 3.31 Male No Sun Dinner 2 ## 5 24.59 3.61 Female No Sun Dinner 4 ## 6 25.29 4.71 Male No Sun Dinner 4 Con la función t.test() es muy sencillo hacer la prueba, no hay que calcular hay solamente que añadir la información. Las opciones para esta prueba son las siguientes en roja t.test(x, y = NULL, alternative = c(two.sided, less, greater), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95, …). Code t.test(tips$tip, alternative=&quot;two.sided&quot;, mu=2.5, conf.level = .95) ## ## One Sample t-test ## ## data: tips$tip ## t = 5.6253, df = 243, p-value = 5.08e-08 ## alternative hypothesis: true mean is not equal to 2.5 ## 95 percent confidence interval: ## 2.823799 3.172758 ## sample estimates: ## mean of x ## 2.998279 El resultado: El valor de t-observado es de 5.625, con un grado de libertad de 243 (n=244), y valor de p &lt;0.0001. Por consecuencia se rechaza la hipótesis nula y se acepta la alterna. El intervalo de confianza del promedio es $2.82 - $3.17, con un promedio de $3.00 *** 13.14 ¿Cómo graficar el resultado de una prueba t? Pasos Crear una distribución normal de la hipótesis NULA con un promedio de Calcule las estadísticas t.test Dibuje la media de la estadística t en la figura la linea entrecortada representa el intervalo de confianza de 95% la linea roja representa la estadística de los datos. En este ejemplo observamos que el promedio estimado es por encima del intervalo de confianza (la lineas entrecortadas). Code # construir una distribución normal de los datos randT&lt;-rt(30000, df=NROW(tips)-1)+2.5 # Hacer la prueba de t tipTTest&lt;-t.test(tips$tip, alternative = &quot;two.sided&quot;, mu=2.50) tipTTest ## ## One Sample t-test ## ## data: tips$tip ## t = 5.6253, df = 243, p-value = 5.08e-08 ## alternative hypothesis: true mean is not equal to 2.5 ## 95 percent confidence interval: ## 2.823799 3.172758 ## sample estimates: ## mean of x ## 2.998279 Code # Graficar los resultados ggplot(data.frame(x=randT))+ geom_density(aes(x=x), fill=&quot;grey&quot;, color=&quot;grey&quot;)+ # La densidad de los datos geom_vline(xintercept = tipTTest$statistic, colour=&quot;red&quot;)+ # El resultado de la prueba estadística geom_vline(xintercept = mean(randT)+c(-2,2)*sd(randT), linetype=2)+ # El intervalo de confianza xlab(&quot;Promedio de propina&quot;) 13.15 Ejercicio de práctica 1: Amigos de Facebook Mucha gente creen que la cantidad promedio de amigos en Facebook es 338 con una desviación estandard de 43.2. En un muestro al azar de 50 estudiantes universitarios en un pais se calculo que el promedio de estos estudiantes es de 350 amigos. Al nivel de 5% de error determina si hay evidencia que los estudiante tenga mayor numero de amigos que el promedio anunciado por Facebook Cual es valor de t Cual es el valor de t critico ¿Se rechaza o acepta la hipótesis nula? 13.16 Ejercicio de práctica 2: Dias de enfermedades Un dueño de una impresa dice que su insiste que la cantidad de días promedio de enfermedades de sus empleados es menor que el promedio nacional de 10. Los datos de 40 empleados sigue. Determina si hay evidencia para creer el comentario del dueño de esta impresa. Code dias_E=tribble( ~dias_e, 0,6,12,3,3,5,4,1, 3,9,6,0,7,6,3,4, 7,4,7,1,0,8,12,3, 2,5,10,5,15,3,2,5, 3,11,8,2,2,4,1,9 ) dias_E ## # A tibble: 40 × 1 ## dias_e ## &lt;dbl&gt; ## 1 0 ## 2 6 ## 3 12 ## 4 3 ## 5 3 ## 6 5 ## 7 4 ## 8 1 ## 9 3 ## 10 9 ## # ℹ 30 more rows "],["prueba-de-t-pareados.html", "Chapter 14 Prueba de t pareados 14.1 Datos dependientes 14.2 Visualizar la correlación 14.3 La prueba de t-pareado 14.4 Visualizar la diferencias 14.5 Paired t-test, Números de niños abuela y madre 14.6 Ejercicio de clase 14.7 Cultivador de Toronjas con parcelas pareadas 14.8 El número de Hojas por planta en diferentes momentos (tiempo). 14.9 Anxiedad y Alacranes 14.10 Supuestos de la prueba de t con datos pareados.", " Chapter 14 Prueba de t pareados Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; 14.1 Datos dependientes Si tienes datos que no son independiente, es necesario usar la prueba con datos pareados (paired t-test). Cuando se refiere a datos no independiente es que hay evidencia que los datos pueden estar relacionado de una forma. En el siguiente ejemplo tenemos la altura de los padres y el altura de el hijo. Hay evidencia que la genética influencia la altura de los humanos, también hay el ambiente. Si el ambiente (nutrición, etc) es la única variable que tiene influencia sobre la altura pudiese que no se debería encontrar una relación entre la altura del padre y el hijo. Si la genética es la única variable que impacta la altura de los humanos, en este caso deberíamos encontrar una muy fuerte correlación entre la alturas de los padres y los hijos. Los datos provienen del paquete UsingR y el archivo se llama father.son Primero mire los datos y los nombres de las variables. Paired Two-Sample T-test Code require(Hmisc) require(UsingR) # father.son data set head(father.son) ## fheight sheight ## 1 65.04851 59.77827 ## 2 63.25094 63.21404 ## 3 64.95532 63.34242 ## 4 65.75250 62.79238 ## 5 61.13723 64.28113 ## 6 63.02254 64.24221 Code #install.packages(&quot;UsingR&quot;, dependencies = TRUE) 14.2 Visualizar la correlación Antes de hacer la prueba es recomendado hacer un gráfico de puntos para visualizar los datos y observar si hay un patrón. Vemos a medida que aumenta la altura de los padres los hijos tienden a estar más altos. parece que hay una correlación en la altura de los hijos basado en la altura del padre. Por consecuencia la altura de los hijos no son independiente de la altura de los padres. Aunque hay evidencia que el ambiente, tal como el acceso a recursos (comida, leche, etc) tiene impacto sobre la altura de los humanos, la genética también tiene impacto to sobre la altura de los humanos. Code ggplot(father.son, aes(fheight, sheight))+ geom_point()+ rlt_theme+ xlab(&quot;Alturas de los padres&quot;)+ ylab(&quot;Alturas de los hijos&quot;) 14.3 La prueba de t-pareado La prueba de t-con datos pareados es la misma que la prueba de t con un grupo, t.test(). La hipótesis nula es que la diferencia entre los datos dependientes es igual a cero. La d se refiere a la diferencia entre los pares de datos. Nota entonces que el análisis se hace evaluando si el promedio de las diferencias es igual a cero. Nota que el valor de t es absoluto \\(\\left|t\\right|\\), un valor negativo es igual que un valor positivo. Ho: \\(\\overline{x_d}=0\\) Ha: \\(\\overline{x_d}≠0\\) La prueba de t con datos pareados. \\[\\left|t\\right|=\\bar{\\frac{d}{\\frac{s_d}{\\sqrt{n}}}}\\] Si el valor absoluto de las estadísticas de la prueba \\(\\begin{array}{l}t=\\left|t\\right|\\\\\\end{array}\\) es mayor que el valor crítico, entonces la diferencia es significativa. El nivel critico del valor p corresponde al indicado en la tabla de la prueba tomando en cuanta el grado de libertad, la cantidad de error I y si es de un lado o ambos lados. Las opciones para esta prueba son las siguientes en roja t.test(x, y, alternative = c(two.sided, less, greater), mu =, paired = FALSE, var.equal = FALSE, conf.level = 0.95, …). El resultado: El valor de \\(\\left|t\\right|\\) observado es de 11.789, con un grado de libertad de 1077 (n=1078), y un valor de p &lt;0.0001. Por consecuencia se rechaza la hipótesis nula y se acepta la alterna. El intervalo de confianza del promedio es -1.163 a -0.831, con un promedio de -0.99. Esto significa que los padres tiende a estar una pulgada (-0.99) más bajo que los hijos. Code t.test(father.son$fheight, father.son$sheight, paired=TRUE) ## ## Paired t-test ## ## data: father.son$fheight and father.son$sheight ## t = -11.789, df = 1077, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -1.1629160 -0.8310296 ## sample estimates: ## mean difference ## -0.9969728 14.4 Visualizar la diferencias Podemos visualizar la diferencia entre los hijos y los padres. Vemos el promedio si no tuviese diferencia (la linea azul), esto es nuestra hipótesis nula, y el estimado (el promedio de la diferencias es rojo, con el intervalo de confianza en las lineas entrecortada). Si nuestro estimado (el intervalo de confianza de 95%) hubiese incluido la linea azul la prueba no seria significativa, y se aceptaría la hipótesis nula. Code father.son$heightDiff&lt;-father.son$fheight-father.son$sheight # para calcular la diferencia entre el padre y el hijo. ggplot(father.son, aes(x=fheight-sheight))+ geom_density()+ geom_vline(xintercept = mean(father.son$heightDiff), colour=&quot;red&quot;)+ geom_vline(xintercept = mean(father.son$father.son$heightDiff)+ 2*c(-1,1)*sd(father.son$heightDiff)/sqrt(nrow(father.son)), linetype=2)+ geom_vline(xintercept = 0, colour=&quot;blue&quot;)+ rlt_theme+ xlab(&quot;Diferencia en altura entre padres y hijos&quot;)+ scale_x_continuous(breaks = round(seq(min(father.son$heightDiff), max(father.son$heightDiff), by = .5),0))+ theme(axis.text.x = element_text(angle = 90)) 14.4.1 Supuesto de normalidad Cual metodo para determinar si las diferencias cumple normalidad? 14.5 Paired t-test, Números de niños abuela y madre 14.6 Ejercicio de clase Vamos a evaluar si la cantidad de hijos cambia entre su abuela y su madre. Code abuela=c(3,3,2, 3, 5, 3,2,3, 4,3,4) madre=c(2,2,2, 3,3, 3,2, 3, 1,2,2) df=data.frame(abuela,madre) df ## abuela madre ## 1 3 2 ## 2 3 2 ## 3 2 2 ## 4 3 3 ## 5 5 3 ## 6 3 3 ## 7 2 2 ## 8 3 3 ## 9 4 1 ## 10 3 2 ## 11 4 2 Code df$diff=df$abuela-df$madre df ## abuela madre diff ## 1 3 2 1 ## 2 3 2 1 ## 3 2 2 0 ## 4 3 3 0 ## 5 5 3 2 ## 6 3 3 0 ## 7 2 2 0 ## 8 3 3 0 ## 9 4 1 3 ## 10 3 2 1 ## 11 4 2 2 Code mean(df$diff) ## [1] 0.9090909 Code t.test(df$abuela,df$madre, paired=TRUE) ## ## Paired t-test ## ## data: df$abuela and df$madre ## t = 2.8868, df = 10, p-value = 0.0162 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 0.2074091 1.6107727 ## sample estimates: ## mean difference ## 0.9090909 14.7 Cultivador de Toronjas con parcelas pareadas Un cultivador heredo 18 parcelas donde hay árboles de toronjas cada una en diferentes municipios. El quiere saber si al añadir abono, la cosecha de toronjas aumenta. El podría decidir que de seleccionar 9 de estas parcelas y añadir abono y las otras 9 sin abono. El problema con este diseño experimental es que es bien conocido que el suelo varia de un sitio a otro y que el clima varia también. Es más apropiado que el divide cada parcela en 2, y que la mitad recibe el abono y la otra mitad sirva de control (sin abono). Cual sera el efecto del abono sobre la producción de toronjas en parcelas pareadas en Puerto Rico. La cantidad de Toronjas producidas por árbol en fincas pareadas, cada finca tiene una parcela con abono y la otra la otra parcela sin abono. Tenemos 18 diferentes sitios en PR donde se probo el efecto del abono sobre la producción de toronjas, se enseña solamente los primeros 8 pares de valores en la tabla. Cada parcela es del mismo tamaño con la misma cantidad de arboles. Los datos completos están en el próximo chunk. Code library(tibble) library(huxtable) Toronja=tribble( ~Fertilizante, ~Sin_Fertilizante, ~Municipio, 2250, 1920 , &quot;Utuado&quot;, 2410, 2020, &quot;Cabo Rojo&quot;, 2260, 2060, &quot;Manati&quot;, 2200, 1960, &quot;Yabucoa&quot;, 2360, 1960, &quot;Humacao&quot;, 2320, 2140,&quot;Caguas&quot;, 2240, 1980, &quot;San Juan&quot;, 2300, 1940, &quot;Jayuya&quot;, 2090, 1790,&quot;Ponce&quot; ) Toronja Toronja$dif_F_NF=Toronja$Fertilizante-Toronja$Sin_Fertilizante Toronja library(ggplot2) ggplot(Toronja, aes(dif_F_NF))+ geom_histogram() ggsave(&quot;Mi_super_grafico.png&quot;) huxtable(Toronja)%&gt;% theme_article(header_col = TRUE)%&gt;% set_bottom_border(row = 1, col = everywhere, value = 1)%&gt;% set_caption(&quot;La cantidad de toronjas producidas en parceles en diferentes municipios&quot;) Primero añadimos los datos en listas y la unimos en un df. Se calcula la diferencias de producción de toronjas por parcela. Cual es el promedio de las diferencias. Hacer la prueba de t con datos pareado. El resultado: El valor de t-observado es de 8.80, con un grado de libertad de 17 (n=18), y valor de p &lt;0.0001. Por consecuencia se rechaza la hipótesis nula y se acepta la alterna. El intervalo de confianza del promedio es 198.5 - 323.7, con un promedio de 261. Esto significa que a añadir fertilizante la producción de toronjas aumento de en promedio de 261 toronjas. Code Fert=c(2250,2410, 2260,2200, 2360, 2320,2240,2300,2090, 2250,2410, 2260,2200, 2360, 2320,2240,2300,2090) #Fert SFert=c(1920,2020,2060,1960, 1960,2140,1980,1940,2100, 1920,2020,2060,1960, 1960,2140,1980,1940,2100) #SFert df=data.frame(Fert,SFert) df$diff_produccion=df$Fert-df$SFert mean(df$diff_produccion) # el promedio de las diferencias t.test(df$Fert,df$SFert, paired=TRUE) 14.8 El número de Hojas por planta en diferentes momentos (tiempo). Los datos representa cuantas hojas tenían las mismas plantas en diferentes momentos de su muestreo. Por consecuencia los datos nos son independiente. Los datos provienen de datos recolectados en el Yunque en una pequeña orquídea epifita, Lepanthes eltoroensis Stimson. Aquí una foto de la planta. El archivo de datos tiene información sobre la cantidad de hojas que tiene cada una de las plantas marcadas después del huracán Georges (1998). La plantas fueron muestreado a cada 6 meses comenzando 6 meses después del huracán por 6 años (13 muestreos). Fueron seguidos 1084 plantas distintas, aunque no todos están muestreados a cada tiempo. Cada fila representa un individuo, si no hay información en un tiempo puede ser que la planta a) no fue encontrada en este muestreo, b) que la planta este muerta o que c) fue antes que la planta creciera (todavía no había germinado). Code library(readr) Lepanthes_eltoroensis_Georges_STUDENT &lt;- read_csv(&quot;Data_files_csv/Lepanthes_eltoroensis_Georges_STUDENT.csv&quot;) Lep=Lepanthes_eltoroensis_Georges_STUDENT head(Lep) library(tidyverse) length(Lep$T1) Compara si la cantidad de hojas por plante es igual entre el primer muestreo (1) y el segundo muestreo (2). y contesta la siguientes preguntas. Se someterá un documento html en Edmodo contestando las siguientes preguntas. Cual son sus conclusiones. ¿Cuantas plantas fueron muestreadas en ambos periodos? ¿Cual es la hipotesis nula? ¿Haz la prueba corecta para evaluar la hipotesis? ¿Cual es el valor de t observado? ¿Cual es el promedio de diferencias entre un muestreo y el otro? ¿Cual es el intervalo de confianza del promedio? ¿Cumple con el supuesto de esta prueba? enseña la evidencia. ¿Se acepta o rechaza la hipótesis nula? la plantas en el tiempo 2 tienen mayor hojas? la plantas en el tiempo 2 tienen menor hojas? la plantas tienen la misma cantidad de hojas? 14.9 Anxiedad y Alacranes Con un indice de Ansiedad. Más alto el número más ansioso. Code picture=c(1,2,5,2,8,4,5,0,7) dead=c(15,15,17,10,10,10,18,16,11) mean(picture) mean(dead) alacran=data.frame(picture,dead) head(alacran) t.test(alacran$dead, alacran$picture,paired=FALSE) 14.10 Supuestos de la prueba de t con datos pareados. Los supuestos de la prueba t-pareados. Las variables dependientes sean valores continuos (intervalos o razón). Qué los individuos sean observaciones independientes. Qué las diferencias sean normales. Qué no hay valores atípicos. "],["prueba-de-t-independiente.html", "Chapter 15 Prueba de t independiente 15.1 Datos dependientes 15.2 Visualizar la correlación 15.3 La prueba de t-pareado 15.4 Visualizar la diferencias 15.5 Paired t-test, Números de niños abuela y madre 15.6 Ejercicio de clase 15.7 Cultivador de Toronjas con parcelas pareadas 15.8 El número de Hojas por planta en diferentes momentos (tiempo). 15.9 Anxiedad y Alacranes", " Chapter 15 Prueba de t independiente 15.1 Datos dependientes Si tienes datos que no son independiente, es necesario usar la prueba con datos pareados (paired t-test). Cuando se refiere a datos no independiente es que hay evidencia que los datos pueden estar relacionado de una forma. En el siguiente ejemplo tenemos la altura de los padres y el altura de el hijo. Hay evidencia que la genética influencia la altura de los humanos, también hay el ambiente. Si el ambiente (nutrición, etc) es la única variable que tiene influencia sobre la altura pudiese que no se debería encontrar una relación entre la altura del padre y el hijo. Si la genética es la única variable que impacta la altura de los humanos, en este caso deberíamos encontrar una muy fuerte correlación entre la alturas de los padres y los hijos. Los datos provienen del paquete UsingR y el archivo se llama father.son Primero mire los datos y los nombres de las variables. Paired Two-Sample T-test Code require(Hmisc) require(UsingR) # father.son data set head(father.son) ## fheight sheight heightDiff ## 1 65.04851 59.77827 5.27024 ## 2 63.25094 63.21404 0.03690 ## 3 64.95532 63.34242 1.61290 ## 4 65.75250 62.79238 2.96012 ## 5 61.13723 64.28113 -3.14390 ## 6 63.02254 64.24221 -1.21967 Code #install.packages(&quot;UsingR&quot;, dependencies = TRUE) 15.2 Visualizar la correlación Antes de hacer la prueba es recomendado hacer un gráfico de puntos para visualizar los datos y observar si hay un patrón. Vemos a medida que aumenta la altura de los padres los hijos tienden a estar más altos. parece que hay una correlación en la altura de los hijos basado en la altura del padre. Por consecuencia la altura de los hijos no son independiente de la altura de los padres. Aunque hay evidencia que el ambiente, tal como el acceso a recursos (comida, leche, etc) tiene impacto sobre la altura de los humanos, la genética también tiene impacto to sobre la altura de los humanos. Code ggplot(father.son, aes(fheight, sheight))+ geom_point()+ rlt_theme+ xlab(&quot;Alturas de los padres&quot;)+ ylab(&quot;Alturas de los hijos&quot;) 15.3 La prueba de t-pareado La prueba de t-con datos pareados es la misma que la prueba de t con un grupo, t.test(). La hipótesis nula es que la diferencia entre los datos dependientes es igual a cero. La d se refiere a la diferencia entre los pares de datos. Nota entonces que el análisis se hace evaluando si el promedio de las diferencias es igual a cero. Nota que el valor de t es absoluto \\(\\left|t\\right|\\), un valor negativo es igual que un valor positivo. Ho: \\(\\overline{x_d}=0\\) Ha: \\(\\overline{x_d}≠0\\) La prueba de t con datos pareados. \\[\\left|t\\right|=\\bar{\\frac{d}{\\frac{s_d}{\\sqrt{n}}}}\\] Si el valor absoluto de las estadísticas de la prueba \\(\\begin{array}{l}t=\\left|t\\right|\\\\\\end{array}\\) es mayor que el valor crítico, entonces la diferencia es significativa. El nivel critico del valor p corresponde al indicado en la tabla de la prueba tomando en cuanta el grado de libertad, la cantidad de error I y si es de un lado o ambos lados. Las opciones para esta prueba son las siguientes en roja t.test(x, y, alternative = c(two.sided, less, greater), mu =, paired = FALSE, var.equal = FALSE, conf.level = 0.95, …). El resultado: El valor de \\(\\left|t\\right|\\) observado es de 11.789, con un grado de libertad de 1077 (n=1078), y un valor de p &lt;0.0001. Por consecuencia se rechaza la hipótesis nula y se acepta la alterna. El intervalo de confianza del promedio es -1.163 a -0.831, con un promedio de -0.99. Esto significa que los padres tiende a estar una pulgada (-0.99) más bajo que los hijos. Code t.test(father.son$fheight, father.son$sheight, paired=TRUE) ## ## Paired t-test ## ## data: father.son$fheight and father.son$sheight ## t = -11.789, df = 1077, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -1.1629160 -0.8310296 ## sample estimates: ## mean difference ## -0.9969728 15.4 Visualizar la diferencias Podemos visualizar la diferencia entre los hijos y los padres. Vemos el promedio si no tuviese diferencia (la linea azul), esto es nuestra hipótesis nula, y el estimado (el promedio de la diferencias es rojo, con el intervalo de confianza en las lineas entrecortada). Si nuestro estimado (el intervalo de confianza de 95%) hubiese incluido la linea azul la prueba no seria significativa, y se aceptaría la hipótesis nula. Code father.son$heightDiff&lt;-father.son$fheight-father.son$sheight # para calcular la diferencia entre el padre y el hijo. ggplot(father.son, aes(x=fheight-sheight))+ geom_density()+ geom_vline(xintercept = mean(father.son$heightDiff), colour=&quot;red&quot;)+ geom_vline(xintercept = mean(father.son$father.son$heightDiff)+ 2*c(-1,1)*sd(father.son$heightDiff)/sqrt(nrow(father.son)), linetype=2)+ geom_vline(xintercept = 0, colour=&quot;blue&quot;)+ rlt_theme+ xlab(&quot;Diferencia en altura entre padres y hijos&quot;)+ scale_x_continuous(breaks = round(seq(min(father.son$heightDiff), max(father.son$heightDiff), by = .5),0))+ theme(axis.text.x = element_text(angle = 90)) 15.4.1 Supuesto de normalidad Cual metodo para determinar si las diferencias cumple normalidad? 15.5 Paired t-test, Números de niños abuela y madre 15.6 Ejercicio de clase Vamos a evaluar si la cantidad de hijos cambia entre su abuela y su madre. Code abuela=c(3,3,2, 3, 5, 3,2,3, 4,3,4) madre=c(2,2,2, 3,3, 3,2, 3, 1,2,2) df=data.frame(abuela,madre) df ## abuela madre ## 1 3 2 ## 2 3 2 ## 3 2 2 ## 4 3 3 ## 5 5 3 ## 6 3 3 ## 7 2 2 ## 8 3 3 ## 9 4 1 ## 10 3 2 ## 11 4 2 Code df$diff=df$abuela-df$madre df ## abuela madre diff ## 1 3 2 1 ## 2 3 2 1 ## 3 2 2 0 ## 4 3 3 0 ## 5 5 3 2 ## 6 3 3 0 ## 7 2 2 0 ## 8 3 3 0 ## 9 4 1 3 ## 10 3 2 1 ## 11 4 2 2 Code mean(df$diff) ## [1] 0.9090909 Code t.test(df$abuela,df$madre, paired=TRUE) ## ## Paired t-test ## ## data: df$abuela and df$madre ## t = 2.8868, df = 10, p-value = 0.0162 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 0.2074091 1.6107727 ## sample estimates: ## mean difference ## 0.9090909 15.7 Cultivador de Toronjas con parcelas pareadas Un cultivador heredo 18 parcelas donde hay árboles de toronjas cada una en diferentes municipios. El quiere saber si al añadir abono, la cosecha de toronjas aumenta. El podría decidir que de seleccionar 9 de estas parcelas y añadir abono y las otras 9 sin abono. El problema con este diseño experimental es que es bien conocido que el suelo varia de un sitio a otro y que el clima varia también. Es más apropiado que el divide cada parcela en 2, y que la mitad recibe el abono y la otra mitad sirva de control (sin abono). Cual sera el efecto del abono sobre la producción de toronjas en parcelas pareadas en Puerto Rico. La cantidad de Toronjas producidas por árbol en fincas pareadas, cada finca tiene una parcela con abono y la otra la otra parcela sin abono. Tenemos 18 diferentes sitios en PR donde se probo el efecto del abono sobre la producción de toronjas, se enseña solamente los primeros 8 pares de valores en la tabla. Cada parcela es del mismo tamaño con la misma cantidad de arboles. Los datos completos están en el próximo chunk. Code library(tibble) library(huxtable) Toronja=tribble( ~Fertilizante, ~Sin_Fertilizante, ~Municipio, 2250, 1920 , &quot;Utuado&quot;, 2410, 2020, &quot;Cabo Rojo&quot;, 2260, 2060, &quot;Manati&quot;, 2200, 1960, &quot;Yabucoa&quot;, 2360, 1960, &quot;Humacao&quot;, 2320, 2140,&quot;Caguas&quot;, 2240, 1980, &quot;San Juan&quot;, 2300, 1940, &quot;Jayuya&quot;, 2090, 1790,&quot;Ponce&quot; ) Toronja Toronja$dif_F_NF=Toronja$Fertilizante-Toronja$Sin_Fertilizante Toronja library(ggplot2) ggplot(Toronja, aes(dif_F_NF))+ geom_histogram() ggsave(&quot;Mi_super_grafico.png&quot;) huxtable(Toronja)%&gt;% theme_article(header_col = TRUE)%&gt;% set_bottom_border(row = 1, col = everywhere, value = 1)%&gt;% set_caption(&quot;La cantidad de toronjas producidas en parceles en diferentes municipios&quot;) Primero añadimos los datos en listas y la unimos en un df. Se calcula la diferencias de producción de toronjas por parcela. Cual es el promedio de las diferencias. Hacer la prueba de t con datos pareado. El resultado: El valor de t-observado es de 8.80, con un grado de libertad de 17 (n=18), y valor de p &lt;0.0001. Por consecuencia se rechaza la hipótesis nula y se acepta la alterna. El intervalo de confianza del promedio es 198.5 - 323.7, con un promedio de 261. Esto significa que a añadir fertilizante la producción de toronjas aumento de en promedio de 261 toronjas. Code Fert=c(2250,2410, 2260,2200, 2360, 2320,2240,2300,2090, 2250,2410, 2260,2200, 2360, 2320,2240,2300,2090) #Fert SFert=c(1920,2020,2060,1960, 1960,2140,1980,1940,2100, 1920,2020,2060,1960, 1960,2140,1980,1940,2100) #SFert df=data.frame(Fert,SFert) df$diff_produccion=df$Fert-df$SFert mean(df$diff_produccion) # el promedio de las diferencias t.test(df$Fert,df$SFert, paired=TRUE) 15.8 El número de Hojas por planta en diferentes momentos (tiempo). Los datos representa cuantas hojas tenían las mismas plantas en diferentes momentos de su muestreo. Por consecuencia los datos nos son independiente. Los datos provienen de datos recolectados en el Yunque en una pequeña orquídea epifita, Lepanthes eltoroensis Stimson. Aquí una foto de la planta. El archivo de datos tiene información sobre la cantidad de hojas que tiene cada una de las plantas marcadas después del huracán Georges (1998). La plantas fueron muestreado a cada 6 meses comenzando 6 meses después del huracán por 6 años (13 muestreos). Fueron seguidos 1084 plantas distintas, aunque no todos están muestreados a cada tiempo. Cada fila representa un individuo, si no hay información en un tiempo puede ser que la planta a) no fue encontrada en este muestreo, b) que la planta este muerta o que c) fue antes que la planta creciera (todavía no había germinado). Code library(readr) Lepanthes_eltoroensis_Georges_STUDENT &lt;- read_csv(&quot;Data_files_csv/Lepanthes_eltoroensis_Georges_STUDENT.csv&quot;) Lep=Lepanthes_eltoroensis_Georges_STUDENT head(Lep) library(tidyverse) length(Lep$T1) Compara si la cantidad de hojas por plante es igual entre el primer muestreo (1) y el segundo muestreo (2). y contesta la siguientes preguntas. Se someterá un documento html en Edmodo contestando las siguientes preguntas. Cual son sus conclusiones. ¿Cuantas plantas fueron muestreadas en ambos periodos? ¿Cual es la hipotesis nula? ¿Haz la prueba corecta para evaluar la hipotesis? ¿Cual es el valor de t observado? ¿Cual es el promedio de diferencias entre un muestreo y el otro? ¿Cual es el intervalo de confianza del promedio? ¿Cumple con el supuesto de esta prueba? enseña la evidencia. ¿Se acepta o rechaza la hipótesis nula? la plantas en el tiempo 2 tienen mayor hojas? la plantas en el tiempo 2 tienen menor hojas? la plantas tienen la misma cantidad de hojas? 15.9 Anxiedad y Alacranes Con un indice de Ansiedad. Más alto el número más ansioso. Code picture=c(1,2,5,2,8,4,5,0,7) dead=c(15,15,17,10,10,10,18,16,11) mean(picture) mean(dead) alacran=data.frame(picture,dead) head(alacran) t.test(alacran$dead, alacran$picture,paired=FALSE) li ## Supuestos de la prueba de t con datos pareados. Los supuestos de la prueba t-pareados. Las variables dependientes sean valores continuos (intervalos o razón). Qué los individuos sean observaciones independientes. Qué las diferencias sean normales. Qué no hay valores atípicos. "],["anova.html", "Chapter 16 ANOVA 16.1 ANOVA 16.2 Hipótesis en ANOVA 16.3 Crear un conjunto de datos 16.4 Visualizar los datos 16.5 Gráficar los datos 16.6 Un gráfico con el intervalo de confianza. 16.7 Graficar con nuestro nuevo data frame “sum”. 16.8 Estadística descriptiva de los Lagos 16.9 Los supuestos de ANOVA 16.10 Datos al azar 16.11 1. Datos Continuos 16.12 3. La prueba de Levene’s test 16.13 4. Normalidad 16.14 La prueba de ANOVA 16.15 PRUEBA de Post-Hoc 16.16 Prueba de Bonferroni 16.17 Prueba de Tukey 16.18 SUPER HEROES and INJURIES", " Chapter 16 ANOVA Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; Chunk para poder cambiar el color del texto 16.0.1 Instalar libreria si es necesario Code #install.packages(&quot;car&quot;) #install.packages(&quot;pastecs&quot;) #install.packages(&quot;multcomp&quot;) #install.packages(&quot;compute.es&quot;) #install.packages(&quot;WRS2&quot;, repos=&quot;http://R-Forge.R-project.org&quot;) 16.0.2 Activar libreria Code library(tidyverse) library(ggplot2) library(huxtable) library(car) library(pastecs) library(multcomp) library(compute.es) library(WRS2) 16.1 ANOVA Análisis de varianza es un método para comparar 3 o más promedios, al contrario de la prueba de t que es para comparar 2 promedios solamente. Entonces ANOVA es una extensión de la prueba t. La hipótesis nula es Ho: los promedios de los grupos son iguales. ANOVA fue desarrollado por Ronald Fisher y es basado en evaluar la varianza total del experimento y comparar esta con la varianza en los grupos. Típicamente si la varianza explicado entre los grupos es más grande que la varianza dentro los grupos se rechaza la hipótesis nula. A continuación veremos como hacer estos cálculos. Primero hay que explicar porque es necesario ANOVA y no hacer múltiples prueba de t. Recuerda que típicamente rechazamos la hipótesis nula cuando el valor de p es menor de 0.05, el tipo de error I. A cada vez que se hace una prueba t hay 5% de error. Por consecuencia si uno hace múltiples pruebas t, hay una posibilidad que se recheza la hipótesis nula cuando se debería aceptar. Cuan grande es ese error si uno hace múltiples pruebas t. Code library(tibble) Tipo_errorI=tribble( ~Cantidad_Grupo_k, ~C, ~&quot;0.05&quot;, ~&quot;0.01&quot;, &quot;2&quot;,&quot;1&quot;,&quot;0.05&quot;, &quot;0.01&quot;, &quot;3&quot;, &quot;3&quot;, &quot;0.14&quot;, &quot;0.03&quot;, &quot;4&quot;, &quot;6&quot;, &quot;0.26&quot;, &quot;0.06&quot;, &quot;5&quot;, &quot;10&quot;, &quot;0.40&quot;, &quot;0.10&quot;, &quot;6&quot;, &quot;15&quot;, &quot;0.54&quot;, &quot;0.14&quot; ) huxtable(Tipo_errorI)%&gt;% theme_article(header_col = FALSE)%&gt;% set_bottom_border(row = 1, col = everywhere, value = 1) %&gt;% set_caption(&quot;La probabilidad de cometer un error tipo I usando la prueba de t para cada pares de prueba (C)&quot;)%&gt;% add_footnote(&quot;* C=k(k-1)/2, que es la cantidad de comparación&quot;) Table 16.1: La probabilidad de cometer un error tipo I usando la prueba de t para cada pares de prueba (C) Cantidad_Grupo_kC0.050.01 210.050.01 330.140.03 460.260.06 5100.400.10 6150.540.14 * C=k(k-1)/2, que es la cantidad de comparación Nota que si tienes 4 grupos tendrá que hacer 6 pruebas de t, y eso eleva la probabilidad de cometer un tipo de error I a 26%, mucho más alto que el 5% que uno quisiera. Cuando uno hace la prueba de ANOVA y selecciona el nivel de error de 5%, es que el conjunto de todas las pruebas tiene ese nivel error posible. 16.2 Hipótesis en ANOVA La hipótesis nula en ANOVA, es que todos los grupos tienen el mismo promedio, o mejor dicho que no hay evidencia que los promedios sean distintos. Filosoficamente uno NUNCA uede decir que algo es similar es que uno puede decir que no hay evidencia que sean diferentes. Esto proviene de el punto imprtante que uno hace un muestreo de la población, por consecuencia siempre hay la posibilidad que los datos (el muestreo) NO representa la población y hay un tipo de error II (que no se rechaza la hipótesis nula cuando se debería rechazar). H0: \\(H_o:\\ \\mu_1=\\mu_2=\\mu_3=...=\\mu_k\\) Ha: Por lo menos uno de los grupos no es igual a los demás. NOTA importante la hipótesis alterna NO es que los grupos sean distintos, es que por los menos uno de ellos es distinto. Ejemplo: Vamos asumir que tenemos 3 grupos, k=3 y que la hipótesis nula es la siguiente Ho: G1=G2=G3, p &gt;= 0.05 Ha: Por lo menos uno de estos grupos no es igual a los demas. Si encontramos un valor de p &lt;0.05, rechazamos la hipótesis nula y de una de las posibles combinaciones pudiese ser G1=G2, G1=G3, pero G2 no es igual a G3. ¿Qué son las otras posibles combinaciones que resultaría en que se rechaza la hipótesis nula? 16.3 Crear un conjunto de datos Aquí observamos la cantidad de fósforo por parte de millón observado en la misma especie de planta cerca tres lagos de Puerto Rico . Los datos son ficticios es para demostrar el proceso de hacer los análisis. Se observa datos de plantas 3 lagos en Pueto Rico (Caraizo, DosBocas y Guineo). Nuestra hipótesis nula es que la cantidad de fósforo (partes por million) en la plantas es igual en los tres lagos. \\(H_o:\\ \\mu_C=\\mu_{DB}=\\mu_G\\) Por lo menos en uno de estos lagos las plantas tienen una concentración de fósforo diferente Code id&lt;-(1:16) Cant_Fos&lt;-c(55,56,64,45,44, 37,36,35,38,39, 12,28,15,16,11,9) Lagos&lt;-c(rep(1,5),rep(2,5), rep(3,6)) Lagos&lt;-factor(Lagos, levels = c(1:3), labels = c(&quot;Caraizo&quot;, &quot;DosBocas&quot;, &quot;Guineo&quot;)) fosforo&lt;-data.frame(id,Cant_Fos,Lagos) fosforo Table 16.2: idCant_FosLagos 155Caraizo 256Caraizo 364Caraizo 445Caraizo 544Caraizo 637DosBocas 736DosBocas 835DosBocas 938DosBocas 1039DosBocas 1112Guineo 1228Guineo 1315Guineo 1416Guineo 1511Guineo 169Guineo 16.4 Visualizar los datos Hacemos un gráfico de los datos. Calculamos el promedio de todos los valores de “Y” (concentración de fósforo en las plantas) y se gráfica, vemos que muchos de los valores de las plantas son por debajo los valores de la linea y muchos de los valores están por encima. Se observa que la concentración de fósforo en plantas que provienen de los lagos Caraizo y Guineo son lejos del promedio. Code mean_fosforo=mean(fosforo$Cant_Fos) mean_fosforo ## [1] 33.75 Code ggplot(fosforo, aes(Lagos, Cant_Fos, colour=Lagos))+ geom_jitter(width = 0.1)+ geom_hline(yintercept = mean_fosforo) # geom_hline = linea horizontal Otra alternativa y una que ayuda a entender como se hace el cálculos es observar la diferencias entre el valor de la “y” y el promedio, o sea los residuales. Nota que esto se parece a la grafica de residuales de la regresión lineal. Vimos también este tipo de gráfico para la prueba de t. Code plot(1:16, Cant_Fos, ylim=c(0, 60), ylab=&quot;y&quot;, xlab = &quot;order&quot;, pch=21, bg=&quot;red&quot;) abline(h=mean(Cant_Fos), col=&quot;blue&quot;) for(i in 1:16) lines(c(i,i), c(mean(Cant_Fos), Cant_Fos[i]), col=&quot;green&quot;) Ahora vamos a separar el gráfico y ver los residuales por grupo, en otra palabra, cual son los residuales entre los valores y el promedio dentro de los mismos grupos. Se observa en este caso que hay mucho menos varianza entre los valores de un mismo grupo. Este es un indice que los lagos explica la varianza (en parte) en concentración de fósforo en las plantas. Code plot(1:16, Cant_Fos, ylim=c(0, 70), ylab=&quot;y&quot;, xlab = &quot;order&quot;, pch=21, bg=&quot;black&quot;) abline(h=mean(Cant_Fos[Lagos==&quot;Caraizo&quot;]), col=&quot;blue&quot;) abline(h=mean(Cant_Fos[Lagos==&quot;DosBocas&quot;]), col=&quot;red&quot;) abline(h=mean(Cant_Fos[Lagos==&quot;Guineo&quot;]), col=&quot;orange&quot;) index&lt;- 1:length(Cant_Fos) for (i in 1:length(index)){ if(Lagos[i]==&quot;Caraizo&quot;) lines(c(index[i], index[i]), c(mean(Cant_Fos[Lagos==&quot;Caraizo&quot;]), Cant_Fos[i]), col=&quot;blue&quot;) else if (Lagos[i]==&quot;Guineo&quot;) lines(c(index[i], index[i]), c(mean(Cant_Fos[Lagos==&quot;Guineo&quot;]), Cant_Fos[i]), col=&quot;orange&quot;) else lines(c(index[i], index[i]), c(mean(Cant_Fos[Lagos==&quot;DosBocas&quot;]), Cant_Fos[i]), col=&quot;red&quot;) } Datos donde los grupos son iguales En este ejemplo de vemos dos de los grupos donde los residuales solapan, este es probable que resulta que estos dos grupos (azul y rojo) no sean diferentes. Code id&lt;-(1:16) Cant_Fos&lt;-c(52,66,60,54,64, 56,58,65,49,58, 21,24,22,21,21,21) Lagos&lt;-c(rep(1,5),rep(2,5), rep(3,6)) Lagos&lt;-factor(Lagos, levels = c(1:3), labels = c(&quot;Caraizo&quot;, &quot;DosBocas&quot;, &quot;Guineo&quot;)) fosforo2&lt;-data.frame(id,Cant_Fos,Lagos) attach(fosforo2) Code plot(1:16, Cant_Fos, ylim=c(0, 70), ylab=&quot;y&quot;, xlab = &quot;order&quot;, pch=21, bg=&quot;black&quot;) abline(h=mean(Cant_Fos[Lagos==&quot;Caraizo&quot;]), col=&quot;blue&quot;) abline(h=mean(Cant_Fos[Lagos==&quot;DosBocas&quot;]), col=&quot;red&quot;) abline(h=mean(Cant_Fos[Lagos==&quot;Guineo&quot;]), col=&quot;orange&quot;) index&lt;- 1:length(Cant_Fos) for (i in 1:length(index)){ if(Lagos[i]==&quot;Caraizo&quot;) lines(c(index[i], index[i]), c(mean(Cant_Fos[Lagos==&quot;Caraizo&quot;]), Cant_Fos[i]), col=&quot;blue&quot;) else if (Lagos[i]==&quot;Guineo&quot;) lines(c(index[i], index[i]), c(mean(Cant_Fos[Lagos==&quot;Guineo&quot;]), Cant_Fos[i]), col=&quot;orange&quot;) else lines(c(index[i], index[i]), c(mean(Cant_Fos[Lagos==&quot;DosBocas&quot;]), Cant_Fos[i]), col=&quot;red&quot;) } 16.5 Gráficar los datos Gráfica de los datos para observar si hay un patrón observable. Repito este punto múltiples veces ya que en mi carrera he visto mucha gente haciendo análisis de datos y hacen un análisis estadístico y rechazan la hipótesis nula. Si habría tomado el tiempo de visualizar los datos se habrían dado cuenta que no era posible este resultado porque los datos de los grupos solapan completamente. NOTA Aquí los tres pasos para producir un gráfico con el promedio de cada grupo. 1. los datos con geom_point 2. los promedios con stat_summary(fun.y = mean, geom = “point”), para calcular el promedio del grupo 3. Una linea que une los promedios con stat_summary(fun.y = mean, geom = “line”), note la diferencia entre los dos uno usa “point” el otro usa “line”. Code library(ggplot2) ggplot(fosforo, aes(x=Lagos, y=Cant_Fos, colour=Lagos))+ geom_point()+ stat_summary(fun = mean, geom = &quot;point&quot;, size = 2, aes(group=1), colour = &quot;black&quot;)+ stat_summary(fun = mean, geom = &quot;line&quot;, size = 1, aes(group=1), colour = &quot;red&quot;) 16.6 Un gráfico con el intervalo de confianza. Crear un data frame de los resultados con el package “Rmisc” y la función “summarySE”. Los pasos son identificar la variable continua (en este caso measurevar=“Cant_Fos”) y la variable discreta que identifica los grupos groupvars=“Lagos”. Esto crea un nuevo data frame con los datos resumidos que incluye, el nombre de los grupos (Lagos), el tamaño de muestra (N), el promedio de la variable (Cant_Fos), la desviación estandar (sd), el error estandar (se) y intervalo de confianza (ci). Code library(Rmisc) sum = summarySE(fosforo, measurevar=&quot;Cant_Fos&quot;, groupvars=&quot;Lagos&quot;) sum (#tab:summary data) LagosNCant_Fossdseci Caraizo552.88.353.73&nbsp;10.4&nbsp; DosBocas537&nbsp;&nbsp;1.580.7071.96 Guineo615.26.792.77&nbsp;7.13 16.7 Graficar con nuestro nuevo data frame “sum”. Para calcular el 95% del intervalo de confianza del promedio se usa la siguiente formula \\(\\overline{x}\\ \\pm2\\cdot se\\). Las barras representa el 95% de donde pudiese estar el promedio si repetimos el mismo experimento 100 veces. Code ggplot(sum, aes(x=Lagos, y=Cant_Fos)) + geom_point(colour=&quot;blue&quot;)+ geom_errorbar(aes(ymin=Cant_Fos-2*se, ymax=Cant_Fos+2*se), width=.2, size=0.7) 16.8 Estadística descriptiva de los Lagos Code library(pastecs) by(fosforo$Cant_Fos, fosforo$Lagos, stat.desc) ## fosforo$Lagos: Caraizo ## nbr.val nbr.null nbr.na min max range ## 5.0000000 0.0000000 0.0000000 44.0000000 64.0000000 20.0000000 ## sum median mean SE.mean CI.mean.0.95 var ## 264.0000000 55.0000000 52.8000000 3.7336309 10.3662213 69.7000000 ## std.dev coef.var ## 8.3486526 0.1581184 ## ------------------------------------------------------------ ## fosforo$Lagos: DosBocas ## nbr.val nbr.null nbr.na min max range ## 5.00000000 0.00000000 0.00000000 35.00000000 39.00000000 4.00000000 ## sum median mean SE.mean CI.mean.0.95 var ## 185.00000000 37.00000000 37.00000000 0.70710678 1.96324316 2.50000000 ## std.dev coef.var ## 1.58113883 0.04273348 ## ------------------------------------------------------------ ## fosforo$Lagos: Guineo ## nbr.val nbr.null nbr.na min max range ## 6.000000 0.000000 0.000000 9.000000 28.000000 19.000000 ## sum median mean SE.mean CI.mean.0.95 var ## 91.000000 13.500000 15.166667 2.773886 7.130501 46.166667 ## std.dev coef.var ## 6.794606 0.447996 16.9 Los supuestos de ANOVA Hay 4 supuestos que tenemos que evaluar cuando se hace un ANOVA. Los datos de cada grupo es una muestra al azar de la poblaciones La característica medida es son continuas. Igualdad de varianza: el error en la varianza en cada grupo es igual La variables continuas tienen una distribución normal. 16.10 Datos al azar Este paso es uno de diseño experimental. Que los datos sean representativos de la poblaciones de interés, y que no sean sesgados a un subgrupo. Por ejemplo uno esta probando una vacuno para COVID-19 y la prueba evalúa solamente con gente en muy buena condición física (por ejemplos atletas). La selección de los participantes tiene que reflejar la población a quien se estaría ofreciendo la vacuna. 16.11 1. Datos Continuos Los datos tienen que valores continuos, no pueden ser discretos. Por ejemplo, no pueden ser binarios (vivo/muerto), tampoco no pueden ser conteos (0,1,2,3), si hay poca variación. *** ## 2. Igualdad de varianza La cantidad de dispersión en cada grupo tiene que ser bien similar uno al otro. Esto lo podemos comprobar con una prueba. La hipótesis nula es que cada grupo tiene una varianza igual. La hipotesis alterna es que por lo menos uno de los grupos no tiene la misma varianza. \\[Ho: {s}^{2}_1={s}^{2}_2={s}^{2}_3…{s}^{2}_k\\] Ha: Por lo menos uno d elos grupos no tiene la misma varianza que los otros. (similar a la Ha de ANOVA) 16.12 3. La prueba de Levene’s test La prueba de Levene es probablemente la prueba de igualdad de varianza la más común aunque hay otras alternativas también. Puede encontrar información sobre la prueba de Levene y otras de la pruebas aquí https://en.wikipedia.org/wiki/Levene%27s_test. Para evaluar sin hay diferencias en la varianza entre los grupos de usa la función leveneTest(). Si el valor de p es mayor de 0.05 se acepta la hipótesis nula. Si no cumple con el supuesto de igualdad de varianza ver el modulo de Kruskal-Wallis para una alternariva como evaluar los datos Con los datos de la concentración de fósforo en las plantas de tres lagos, la prueba de Levene da un resultado de p &gt; 0.21, lo que indica que no hay evidencia que la varianza es distinta entre los grupos, por consecuencia se acepta la hipótesis nula. Code library(car) leveneTest(fosforo$Cant_Fos, fosforo$Lagos) (#tab:levene test) DfF valuePr(&gt;F) 21.760.211 13&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16.13 4. Normalidad Tenemos que evaluar si los datos tienen una distribución normal. Como se ha discutido en un modulo anterior hay múltiples alternativas. Vamos a limitarnos a usar la prueba de qqplot. Vemos que los datos más o menos siguen la linea, entonces podemos usar ANOVA. En este caso tenemos pocos datos pero si tuviesemos más seria apropiado evaluar cada una aparte. Lo más sencillo seria de cambiar la primera linea del siguiente script ggplot(fosforo, aes(sample = Cant_Fos, group=Lagos)). En este caso tendríamos 3 lineas. Si no cumple con el supuesto de normalidad ver el modulo de Kruskal-Wallis para una alternariva como evaluar los datos Code ggplot(fosforo, aes(sample = Cant_Fos)) + stat_qq() + stat_qq_line(colour=&quot;blue&quot;)+ xlab(&quot;Valores teóricos&quot;)+ ylab(&quot;Valores observados&quot;) 16.14 La prueba de ANOVA Finalmente llegamos a la prueba de ANOVA, se usa la función aov(). En la primera linea vemos el resultado de comparar los tres lagos, ven que hay 2 grados de libertad (df=2), esto quiere decir que esta incluido en el analisis 3 grapos, porque el grado de libertad de calcula tomando la suma de la cantidad de grupos k-1, y este ejercicio tenemos 3-1=2. En la misma linea obsertva el valor de p, vemos que se rechaza la hipótesis nula (p &lt;0.05). Ya sabemos que por lo menos uno de los grupos no es igual a los demás. Pero todavía no sabemos que pares son diferentes o si todos. En la segunda linea se observa lo otros datos del experimento, lo que aquí se llama los residuales. Code LagosModel&lt;-aov(Cant_Fos~Lagos, data = fosforo) summary(LagosModel) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Lagos 2 3939 1970 49.28 8.55e-07 *** ## Residuals 13 520 40 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Una alternativa para evaluar si los datos tienen una igualdad de varianza y normalidad es usar la función plot(), esta función presenta 4 gráficos donde vamos aquí explicar solamente las dos primeras. En el primer gráfico se observa una distribución de los residuales por grupo. Si los datos están más o menos distribuido de forma similar entre los grupos (que los datos de cada grupo tiene más o menos la misma cantidad de datos negativos y positivos alrededor del residual cero y que esta distribución se ve similar) se suguiere que hay igualdad de varianza entre los grupos. En el segundo gráfico se observa en qqplot. Si los datos están cerca de la linea entrecortada se asume que tiene una distribución normal. Nota que hay tres datos que tienen números (5, 3, 12), estos son datos que posiblemente sean atípicos, y hay que evaluar si estos datos impacta el resultados (veremos esto más tarde, con la prueba de Cooks). Code plot(LagosModel) 16.15 PRUEBA de Post-Hoc Importante este paso se hace solamente si se rechaza la hipótesis nula de la prueba de ANOVA. Si aceptamos la hipótesis nula ya se acabo, no hay más nada que hacer y este paso aquí no se evalúa. Este tipo de prueba Post-Hoc se refiere a una prueba que se hace después de otra. Ya se hizo la de ANOVA y se rechazo y ahora queremos evaluar cual de los grupos es distinto uno al otro. Hay en la literatura más de 10 pruebas que se puede utilizar después de un ANOVA, para tener un poco más de información pueden ir al siguiente website https://www.statisticshowto.com/post-hoc/. Aquí vamos a presentar solamente dos de estás. Estas dos son frecuentemente utilizadas en ciencias medicas por ser las primeras haber sido desarrolladas. Nota que el nivel de tipo de error I, es por el conjunto total de las pruebas hecha. Si selecciona un alfa de 0.05, entonces la probabilidad de cometer el error tipo I es de 5% para el total de pruebas. Bonferroni test Tukey test 16.16 Prueba de Bonferroni Vemos ahora el se hizo 3 pruebas, y cada una tiene un valor de p menor de 5%, por consecuencia cada grupo es distinto uno del otro. Code pairwise.t.test(fosforo$Cant_Fos, fosforo$Lagos, p.adjust.method = &quot;bonferroni&quot;) # Nota aqui se usa los datos originales, el error de todos las pruebas se limita a 5%. ## ## Pairwise comparisons using t tests with pooled SD ## ## data: fosforo$Cant_Fos and fosforo$Lagos ## ## Caraizo DosBocas ## DosBocas 0.00497 - ## Guineo 6.6e-07 0.00022 ## ## P value adjustment method: bonferroni 16.17 Prueba de Tukey En la prueba de Tukey vemos el resultado de las pruebas Post-Hoc. El resultado es lo mismo que la prueba anterior donde cada grupo es significativamente diferente uno del otro. En mucha ocasiones el resulto puede diferir. Si esto ocurre hay que evaluar bien cual es el nivel de confiabilidad que queremos. Algunos pruebas Post_Hoc tienden a rechazar con meas frecuencia que otra. Code library(multcomp) postHocs.1&lt;-glht(LagosModel, linfct = mcp(Lagos = &quot;Tukey&quot;)) summary(postHocs.1) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = Cant_Fos ~ Lagos, data = fosforo) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## DosBocas - Caraizo == 0 -15.800 3.999 -3.951 0.00437 ** ## Guineo - Caraizo == 0 -37.633 3.828 -9.830 &lt; 0.001 *** ## Guineo - DosBocas == 0 -21.833 3.828 -5.703 &lt; 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) 16.18 SUPER HEROES and INJURIES Vea la sección de ejercicio 16.18.0.1 Rename the categories with super hero names Evaluar la distribución de los datos de respuestas (los en Y) Evaluar la homogeneidad de varianza Visualizar los datos Puntos y promedios y intervalo de confianza Hacer la prueba de ANOVA con aov() Evaluar la figura de residuales Evaluar la gráfica de qq, para la normalidad Hacer la prueba de post-hoc si es necesario!!!!! "],["correlación-y-covarianza.html", "Chapter 17 Correlación y Covarianza", " Chapter 17 Correlación y Covarianza "],["regresión-lineal-1.html", "Chapter 18 Regresión Lineal 18.1 la función lm() 18.2 Visualización de la regresión 18.3 El impacto de valores atípico 18.4 La venta de discos de música 18.5 Cook’s Distance 18.6 Repaso de los PASOS 18.7 Paso 1 18.8 Paso 3 18.9 Alternativa para Gráficar los residuales 18.10 Porque podemos usar la alternativas anterior 18.11 Ejercicio #1 18.12 Ejercicio #2 18.13 Datos sobre la orquidea Dipodium", " Chapter 18 Regresión Lineal Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; Activar las librerias, averiguar que TIENE instalado estos paquetes Code library(QuantPsyc) library(car) library(boot) library(ggplot2) library(tidyverse) library(sjPlot) La regresión lineal es el modelo básico de evaluar si hay una relación lineal o sea recta entre dos variable. Esta relación entre las variables puedes ser positiva o negativa. Hay otro tipos de regresión, que incluye regresión no lineal tal como cuadrática \\[x^2\\] o cúbica \\[x^3\\], logarítmica \\[log(x)\\] entre muchas otras alternativas. Aquí estaremos evaluando solamente la regresión lineal Primero paso es subir los datos: El números de barres en un bario y la cantidad de asesinados en este barrio (Datos ficticios) Code library(readr) pubs &lt;- read_csv(&quot;Data_files_csv/pubs.csv&quot;) pubs Table 18.1: pubsmortality 101e+03 202e+03 303e+03 404e+03 505e+03 606e+03 707e+03 5001e+04 Code # Cambiamos los nombres de las columnas pubs=pubs%&gt;% dplyr::rename(barres=pubs, mortalidad=mortality) 18.1 la función lm() Como hacer un regresión lineal (Linear Regression) simple, usando la función lm(), para “linear model”= modelo lineal. Una regresión necesita dos variable continuas (vea el módulo de correlación). Es importante que estas variable tenga una distribución normales. La diferencia entre una correlación y una regresión es que la primera es un análisis que describe el patrón y en la segunda es que no solamente describe el patrón pero hace predicción sobre la relación entre las variables. Usando la regresión uno calcula tambien una linea que describe la relación entre las variables. Esta variable se puede describe como \\(y=m_x+b\\) donde la m representa la pendiente y la b representa el intercepto. También lo pueden ver en libros de la siguiente forma \\(y=\\alpha+\\beta_x\\) donde la \\(\\beta\\) beta representa la pendiente y la \\(\\alpha\\) el intercepto. La formula de lm() se compone de lm(y~x, data= “df”). Nota la tilde ~. Hay dos pruebas la priemra para determinar si \\(\\alpha\\) es distinto de cero. La hipótesis nula es Ho: el intercepto \\(\\alpha\\) es igual a cero Ha: el intercepto, \\(\\alpha\\) no es igual a cero. Entonces el punto donde la linea intercepta el cero puede estar mayor de o menor de cero. La segunda hipótesis nula es que la pendiente es diferente de cero, esto quiere decir que la pendiente no sugiere un patrón de aumentar y disminuir entre las dos variables. Ho: la pendiente \\(\\beta\\) es igual a cero Ha: la pendiente, \\(\\alpha\\) no es igual a cero. Entonces la relación entre las dos variables es o positiva o negativa. Ahora evaluamos los resultados de la regresión entre el número de barres en un vecindarios y la mortalidad en este mismo sector. Se observa que los coeficientes de la linea son \\(y=3352+14.3*x\\). Entonce el intercepto en cero comienza en 3352 fatalidades y por cada bar suplementario hay 14.3 más fatalidad. Ahora para determinar si estos valores son significativo hay que evaluar el valor de p en cada linea. La hipótesis nula del intercepto tiene un valor de p =0.005, que sugiere que se debería rechazar la hipótesis nula, y por consecuencia aceptamos la hipótesis alterna. La pendiente tiene un valor de p=0.015 y también se rechaza la hipotesis nula. Code pubReg &lt;- lm(mortalidad~barres, data = pubs) #summary(pubReg) # Si no se acuerda de la funcíon que sigue tab_model( pubReg,show.df = TRUE, CSS = list( css.depvarhead = &#39;color: red;&#39;, css.centeralign = &#39;text-align: left;&#39;, css.firsttablecol = &#39;font-weight: bold;&#39;, css.summary = &#39;color: blue;&#39; ) )   mortalidad Predictors Estimates CI p df (Intercept) 3351.96 1440.34 – 5263.57 0.005 6.00 barres 14.34 3.82 – 24.86 0.016 6.00 Observations 8 R2 / R2 adjusted 0.649 / 0.591 18.2 Visualización de la regresión Se observa que hay un aumento en fatalidades con aumento en el número de barres. Pero nota el valor a la derecha que parece ser muy atípico comparado a los otros. Code ggplot(pubs, aes(x=barres, y=mortalidad))+ geom_smooth(method = lm)+ # modelo lineal geom_point() 18.3 El impacto de valores atípico En cierta ocasiones valores fuera de lo normal pueden hacer grandes cambios en el resultado, en este caso la regresión. ¿Cual es el efecto del valor grande? Removemos ese valor del archivo de datos y revaluamos el modelo (la regresión lineal). Nota que ahora el modelo es sumamente diferente \\(y=-163.7+103.2*x\\). ¿Ahora se rechaza las dos hipótesis? Code pubsnew &lt;- pubs[ which(pubs$barres&lt;80), ] # remover el valor grande pubsnew=pubsnew %&gt;% add_row(barres = 4, mortalidad = 0) # Añadiendo un par de valores pubRegNew &lt;- lm(mortalidad~barres, data = pubsnew) #summary(pubRegNew) tab_model( pubRegNew,show.df = TRUE, CSS = list( css.depvarhead = &#39;color: red;&#39;, css.centeralign = &#39;text-align: left;&#39;, css.firsttablecol = &#39;font-weight: bold;&#39;, css.summary = &#39;color: blue;&#39; ) )   mortalidad Predictors Estimates CI p df (Intercept) -163.70 -374.14 – 46.73 0.106 6.00 barres 103.20 98.18 – 108.23 &lt;0.001 6.00 Observations 8 R2 / R2 adjusted 0.998 / 0.997 Code ggplot(pubsnew,aes(x=barres, y=mortalidad))+ geom_smooth(method=lm)+ geom_point() 18.4 La venta de discos de música Ahora un set de datos más complejo y más realista a los que uno encontraría en un estudio de en medicina, sociología o ecológica. Los datos representa la cantidad de dinero dedicado a la promoción de diferentes CD’s de una compañia de música y la cantidad de CD (CD/downloads) vendido. El la primera linea se observa la cantidad de libras esterlina, £ (UK) dedicado a la promoción del album de música, en la primera linea vemos que se gasto £10,256, y después la cantidad de CD vendido fue 330. Code library(readr) Album_Sales_1_new &lt;- read_csv(&quot;Data_files_csv/Album_Sales_1_new.csv&quot;) head(Album_Sales_1_new) (#tab:advertizing and sales) advertssales 10.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;330 986&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;120 1.45e+03360 1.19e+03270 575&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;220 569&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;170 Code length(Album_Sales_1_new$adverts) # cuantas files de datos hay en el data frame ## [1] 200 Comenzamos con hacer un gráfico entre las dos variables. Nota que en la parte de geom_smooth(), tiene que incluir method=lm, esto significa que el método de construir la linea usara la regresión lineal. Se añade a la función lineal \\(\\epsilon\\) que representa los errores de los valores al comparar con la linea que representa el mejor modelo. \\[Y_{ i }=\\beta _{ 0 }+\\beta _{ 1 }X_{ i }+\\epsilon _{ i }\\] Recuerda que \\(\\beta _{ 0 }\\) es el intercepto y el \\(\\beta _{ 1 }X_{ i }\\) es la pendiente. El área sombreada es el área de 95 de intervalo de confianza. Esto quiere decir que la mejor linea, intercepto y pendiente podría variar en este rango si repetimos el experimento. Nota aquí todas las alternativas, añadí los dos extremos, con una pendiente mayor (roja) y una menor (violeta). Cada punto representa la venta de CD con su correspondiente cantidad dedicada a la promoción. Los \\(epsilon\\) seria la diferencia entre la mejor linea y el valor original, esto se llama tambien los residuales. Code library(ggplot2) ggplot(Album_Sales_1_new,aes(x=adverts, y=sales))+ geom_smooth(method=lm, se = TRUE)+ geom_point()+ geom_segment(aes(x=0, y=120, xend=2250, yend=380), colour=&quot;red&quot;)+ geom_segment(aes(x=0, y=150, xend=2250, yend=320), colour=&quot;purple&quot;) El modelo lineal con la función lm(). ¿Como interpretas los coeficientes y si estos son significativos, si se rechaza la hipótesis nula? Code library(sjPlot) head(Album_Sales_1_new) (#tab:sales model) advertssales 10.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;330 986&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;120 1.45e+03360 1.19e+03270 575&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;220 569&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;170 Code model1=lm(sales~adverts, Album_Sales_1_new) #summary(model1) tab_model( model1,show.df = TRUE, CSS = list( css.depvarhead = &#39;color: red;&#39;, css.centeralign = &#39;text-align: left;&#39;, css.firsttablecol = &#39;font-weight: bold;&#39;, css.summary = &#39;color: blue;&#39; ) )   sales Predictors Estimates CI p df (Intercept) 134.14 119.28 – 149.00 &lt;0.001 198.00 adverts 0.10 0.08 – 0.12 &lt;0.001 198.00 Observations 200 R2 / R2 adjusted 0.335 / 0.331 18.4.1 Supuestos de la regresión lineal Igualdad de varianza: En el primer gráfico evaluar si los datos están distribuido más o menos igual. y que no un más variación un un área del gráfico que otro. Normalidad de los datos: En el segundo gráfico evaluar la figura de qqplot. Evaluar si hay datos sesgados (atípicos) que influencia los resultados En el cuarto gráfico evaluar si hay valores que tienen mucho peso si se incluyen o no en el análisis. Estos van a ser identificado En el presente gráfico hay tres valores que hay que evaluar (1,42,169), estos valores se tiene que asegurar que son correctos. Siempre es bueno remover los valores sesgados y rehacer el análisis para observar cuan diferente son los resultas. Code plot(model1) # Evaluar los supuestos, 1. Igualdad de varianza, 2. Normalidad, 4. Datos sesgados (Cook&#39;s Distance) 18.5 Cook’s Distance Evaluar si hay unos valores que sesgan los resultados. FROM WIKIPEDIA Definition. Data points with large residuals (outliers) and/or high leverage may distort the outcome and accuracy of a regression. Cook’s distance measures the effect of deleting a given observation. Points with a large Cook’s distance are considered to merit closer examination in the analysis. Detecting highly influential observations There are different opinions regarding what cut-off values to use for spotting highly influential points. A simple operational guideline of D_i&gt;1 has been suggested. Others have indicated that D_i&gt;4/n, where n is the number of observations, might be used. Aqui enseño como añadir 1. los valores de “cook.distance” a su archivo 2. Añadir una columna de “secuencia” de los datos 3. Crear una gráfica de las distancia de Cook. 4. Which values have Di larger than 1, which values have Cook’s distances larger 4/n? Code 4/length(Album_Sales_1_new$adverts) ## [1] 0.02 Code Album_Sales_1_new$cooks.distance&lt;-cooks.distance(model1) head(Album_Sales_1_new) (#tab:Cook distance) advertssalescooks.distance 10.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3300.0572&nbsp;&nbsp; 986&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1200.011&nbsp;&nbsp;&nbsp; 1.45e+033600.0178&nbsp;&nbsp; 1.19e+032700.000662 575&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2200.000548 569&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1700.000207 Code Album_Sales_1_new$sequence=c(1:200) head(Album_Sales_1_new) (#tab:Cook distance) advertssalescooks.distancesequence 10.3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3300.0572&nbsp;&nbsp;1 986&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1200.011&nbsp;&nbsp;&nbsp;2 1.45e+033600.0178&nbsp;&nbsp;3 1.19e+032700.0006624 575&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2200.0005485 569&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1700.0002076 Code tail(Album_Sales_1_new) (#tab:Cook distance) advertssalescooks.distancesequence 701&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2500.00141&nbsp;195 911&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1900.000804196 889&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2400.000321197 801&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2500.00101&nbsp;198 1.5e+032300.00608&nbsp;199 786&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1100.00649&nbsp;200 Code ggplot(Album_Sales_1_new, aes(sequence, cooks.distance))+ geom_point()+ geom_hline(aes(yintercept=4/length(Album_Sales_1_new$adverts), colour=&quot;red&quot;)) 18.6 Repaso de los PASOS 18.7 Paso 1 Primer paso, mirar los coeficientes. El resultado: El coeficiente (intercepto) y la pendiente del model1 18.7.1 Paso 2 Evaluar si los coeficientes son diferentes de cero. La primera hipótesis, Determinar si el intercepto es igual a cero. Mira el valor de p, Pr(&gt;|t|), determinar si el valor es menor de 0.05, si lo es se rechaza la Ho y por consecuencia tenemos confianza que el intercepto no incluye cero. La segunda hipótesis nula Deteminar si la pendiente es igual a cero. Mira el valor de p, Pr(&gt;|t|), como el valor es menor de p=0.05, se rechaza la Ho y por consecuencia tenemos confianza que la pendiente no incluye cero. 18.8 Paso 3 Evaluar si los datos cumple con los supuestos. Igualdad de varianza, usa la gráfica de residuales Normalidad, qqplot Valores sesgados, la prueba de Cook’s Code advertizingReg &lt;- lm(sales~adverts, data = Album_Sales_1_new) summary(advertizingReg) ## ## Call: ## lm(formula = sales ~ adverts, data = Album_Sales_1_new) ## ## Residuals: ## Min 1Q Median 3Q Max ## -152.949 -43.796 -0.393 37.040 211.866 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.341e+02 7.537e+00 17.799 &lt;2e-16 *** ## adverts 9.612e-02 9.632e-03 9.979 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 65.99 on 198 degrees of freedom ## Multiple R-squared: 0.3346, Adjusted R-squared: 0.3313 ## F-statistic: 99.59 on 1 and 198 DF, p-value: &lt; 2.2e-16 Code tab_model( advertizingReg,show.df = TRUE, CSS = list( css.depvarhead = &#39;color: red;&#39;, css.centeralign = &#39;text-align: left;&#39;, css.firsttablecol = &#39;font-weight: bold;&#39;, css.summary = &#39;color: blue;&#39; ) )   sales Predictors Estimates CI p df (Intercept) 134.14 119.28 – 149.00 &lt;0.001 198.00 adverts 0.10 0.08 – 0.12 &lt;0.001 198.00 Observations 200 R2 / R2 adjusted 0.335 / 0.331 18.9 Alternativa para Gráficar los residuales 18.9.1 Plot the residuals and the fitted values 18.9.1.1 Evaluating residuals: If we observe that the residuals are randomly distributed (no pattern, a straigth line), then we can assume that there is equality of variance along the “x” axis. 18.9.1.2 Definition of Residuals A quantity remaining after other things have been subtracted or allowed for. FROM Wikipedia A residual (or fitting deviation), on the other hand, is an observable estimate of the unobservable statistical error. Code # &quot;advertizingReg&quot;, nota que este no es un data frame pero un modelo # The main figure ggplot(Album_Sales_1_new,aes(x=adverts, y=sales))+ geom_smooth(method=lm, se = TRUE)+ geom_point() Code # Graficando los residuales, metodo 1 ggplot(model1, aes(x=.fitted, y=.resid))+ geom_point()+ geom_smooth(method=lm) 18.10 Porque podemos usar la alternativas anterior Cuando R corre un analisis, hace muchos calculos y guarda parate de estos calculos como lista de datos. Para ver algunos de los valores calculado uno pone el nombre del modelo y la añade el $ y deberia aparecer la lista de los valores calculados. o otra alternativa es usar la función ls() = list() para ver el nombre de las variables Code ls(model1) ## [1] &quot;assign&quot; &quot;call&quot; &quot;coefficients&quot; &quot;df.residual&quot; ## [5] &quot;effects&quot; &quot;fitted.values&quot; &quot;model&quot; &quot;qr&quot; ## [9] &quot;rank&quot; &quot;residuals&quot; &quot;terms&quot; &quot;xlevels&quot; Code # model1$residuals # Por ejemplo para ver los residuales del modelo 18.11 Ejercicio #1 Usa los enviado por MSTeam llamado “Alturas_Humanos En este archivo vemos tres columnas. Genero, Altura de la persona (Altura_cm) y Peso de la persona (Peso_kg) Evalua cada paso para determinar si hay una relación entre la altura y el peso de las personas. Haz un gráfico de la relación entre la altura y el peso Evalúa el modelo de regresión entre las dos variables Evalúa los supuestos Code library(readr) Alturas_Humanos &lt;- read_csv(&quot;Data_files_csv/Alturas_Humanos.csv&quot;) head(Alturas_Humanos) Table 18.2: GeneroAltura_cmPeso_kg Hombres17496 Hombres18987 Mujer185110 Mujer195104 Hombres14961 Hombres189104 18.12 Ejercicio #2 18.13 Datos sobre la orquidea Dipodium Los datos se encuentra en el paquete ggversa debajo el nombre de dipodium. Evalua todos los pasos para ver si la altura de inflorescencia es un predictor de la cantidad de flores que tiene una planta. "],["regresión-logistica.html", "Chapter 19 Regresión Logistica 19.1 Brassavola cucullata 19.2 La variable de respuesta, Y. 19.3 Modelo Lineal Generalizado 19.4 Los supuestos de la regresión logistica. 19.5 Comparación de modelos lineal y logistico 19.6 Regresión logística: 19.7 Visualizando una regresión logistica 19.8 Reducir solapamiento de los puntos 19.9 Gráfico con ajuste binomial 19.10 Solapamiento de los ajustes binomial por grupo 19.11 Selecionar el mejor modelo", " Chapter 19 Regresión Logistica Fecha de la ultima revisión ## [1] &quot;2023-08-30&quot; Code library(tidyverse) Esta regresión es utilizada cuando la variable dependiente tiene solamente dos alternativas (representadas de forma numérica, 0 y 1) y la variable independiente es una variable continua. 19.1 Brassavola cucullata Los datos fueron recolectado de dos pequeñas islas del Caribe, San Eustaquio y Saba. Brassavola cucullata pertenece a la subtribu Laeliinae y es una especie epífita y rupícola que puede formar grandes racimos de brotes. Cada brote está compuesto por un solo tallo de 3.5-12.5 cm de largo y 1-3.5 mm de diámetro y tiene una sola hoja semi-tereta de 16-35 cm de largo y solo un poco más gruesa que el tallo. Las inflorescencias terminales miden 3-30 mm de largo y suelen tener una sola flor. Las flores son en gran parte blancas con las partes delgadas del perianto que a menudo se vuelven de color amarillo pálido hacia sus ápices. El labelo es ovado-acuminado y fimbriado alrededor de la columna. El cunículo se extiende hacia el ovario inferior y no tiene néctar. Las flores engañosas tienen una fragancia nocturna dulce y espesa, que puede perdurar hasta el día. La producción de frutos depende de los polinizadores. Las cápsulas tardan varios meses en desarrollarse y son pediceladas y picudas (restos de la columna); el cuerpo de la cápsula mide entre 2 y 5 cm de largo y produce muchos miles de semillas polvorientas (Ackerman y Collaborators 2014). En cada una de las tres poblaciones, etiquetamos todas las plantas de B. cucullata que pudimos encontrar. Observamos si cada planta era epífita o epilítica, medimos la altura sobre el suelo, buscamos evidencia de herbivoría foliar, medimos la longitud de la hoja más larga y contamos el número de brotes de hojas, flores y frutos. Si las flores estaban presentes, registramos si habían sido visitadas con éxito o no mediante una inspección visual para la eliminación de polinarios o polinias en el estigma. Estos datos se obtuvieron una vez al año durante la época de floración. Nuestras observaciones en la población de Quill abarcaron 2009-2013, en Boven 2010-2013 y en Saba 2011-2014. Figure 19.1: La especie Brasavolla cucullata en la isla de San Eustaquio Puede encontrar el manuscrito en este enlace, que evalúa la biología de la orquídea y la posibilidad de extinción y como las cabras impacta su supervivencias. https://www.journals.uchicago.edu/doi/pdf/10.1086/709399 Code library(readr) Student_Brassavola &lt;- read_csv(&quot;Data_files_csv/Student_Brassavola.csv&quot;) completeBrass=na.omit(Student_Brassavola) # remove NA head(completeBrass) Table 19.1: IslandYearPl_NumLeaf_NumLLLBud_NumFl_NumFr_NumBQSFlowers_Y_N Saba2.01e+03A17012026010Saba1 Saba2.01e+03A1702618000Saba0 Saba2.01e+03A1703513000Saba0 Statia2.01e+031023331000Boven0 Statia2.01e+031024034000Boven0 Statia2.01e+031021023010Boven1 Code #library(tidyverse) #library(dplyr) unique(completeBrass$Fr_Num) ## [1] 0 2 1 3 Code # completeBrass$Fr_Y_N2=ifelse(completeBrass$Fr_Num&gt;0 ,1,0) Metodo de la función base completeBrass$Fr_Y_N1=ifelse(completeBrass$Fr_Num&gt;0 ,1,0) # Método de dplyr unique(completeBrass$Fr_Y_N1) # deberia tener solamente dos alternativas, &quot;0&quot; y &quot;1&quot;, Frutos no y si ## [1] 0 1 Evaluar la tendencias centrales y la dispersión de las variables y cambio de nombre de las variables al español. Code Brass=completeBrass%&gt;% dplyr::rename(Isla=Island, Ano=Year, Numero_planta=Pl_Num, Cant_hojas=Leaf_Num, Largo_Hoja_cm=LLL, Cant_capullo=Bud_Num, Cant_Flores=Fl_Num, Cant_Frutos=Fr_Num, BQS=BQS, Flor_si_no=Flowers_Y_N, Frutos_si_no=Fr_Y_N1) Code summary(Brass) ## Isla Ano Numero_planta Cant_hojas ## Length:1436 Min. :2009 Length:1436 Min. : 0.00 ## Class :character 1st Qu.:2011 Class :character 1st Qu.: 3.00 ## Mode :character Median :2011 Mode :character Median : 7.00 ## Mean :2011 Mean : 16.66 ## 3rd Qu.:2012 3rd Qu.: 17.00 ## Max. :2014 Max. :336.00 ## Largo_Hoja_cm Cant_capullo Cant_Flores Cant_Frutos ## Min. : 0.00 Min. :0.00000 Min. :0.0000 Min. :0.00000 ## 1st Qu.: 8.50 1st Qu.:0.00000 1st Qu.:0.0000 1st Qu.:0.00000 ## Median : 19.00 Median :0.00000 Median :0.0000 Median :0.00000 ## Mean : 18.12 Mean :0.05153 Mean :0.1247 Mean :0.04735 ## 3rd Qu.: 26.00 3rd Qu.:0.00000 3rd Qu.:0.0000 3rd Qu.:0.00000 ## Max. :108.00 Max. :4.00000 Max. :7.0000 Max. :3.00000 ## BQS Flor_si_no Frutos_si_no ## Length:1436 Min. :0.00000 Min. :0.00000 ## Class :character 1st Qu.:0.00000 1st Qu.:0.00000 ## Mode :character Median :0.00000 Median :0.00000 ## Mean :0.08705 Mean :0.03552 ## 3rd Qu.:0.00000 3rd Qu.:0.00000 ## Max. :1.00000 Max. :1.00000 19.2 La variable de respuesta, Y. You can also embed plots, for example: 19.3 Modelo Lineal Generalizado En este modulo se hace una primera introducción a un otro tipo de herramienta para el análisis de datos, denominado Modelo Lineal Generalizado, GLM. Lo interesante de esta acercamiento es que aun que uno tiene una variable de respuesta que no cumple con distribución normal hay múltiples opciones para los análisis. En este modulo solamente se estará presentando el tipo de datos donde la variable de respuesta (Y) es binomial. Hay tres componentes en cualquier GLM: Componente aleatorio: se refiere a la distribución de probabilidad de la variable de respuesta (Y); por ejemplo, distribución binomial (0, 1,: Si o NO: Vivo o Muerto). Nota que la variable Y puede tener muchas otras tipo de distribución incluyendo la distribución normal, lognormal, proporción y m,uchos otros. Variable predictivas: especifica las variables explicativas \\(X_1,\\ X_2,\\ X_3,...X_k\\) en el modelo, la combinación lineal se puede expresar con la siguiente forma; por ejemplo, \\(\\beta_0+\\beta_1\\cdot x_1+\\beta_2\\cdot x_2,\\ ...+\\beta_k\\cdot x_k2\\) como hemos visto en una regresión lineal. Función de enlace: η o g (μ): especifica el enlace entre componentes aleatorios y sistemáticos. Dice cómo el valor esperado de la respuesta se relaciona con las variables de la ecuación lineal explicativa. 19.4 Los supuestos de la regresión logistica. El resultado es la variable es binaria o también conocida como dicótoma (sí o no: presente o ausente, 1 o 0). Existe una relación lineal entre el logit (p) de la variable de repuesta y las variables predictora. No hay valores extremos o valores atípicos en los predictores continuos. No hay correlaciones altas (es decir, multicolinealidad) entre los variables predictores (vea modulo de Correlación). 19.5 Comparación de modelos lineal y logistico l primer paso es entender cual es la diferencia entre una regresión lineal y una regresión logística. Podemos visualizar ambas formula y ver como difieren. La regresión lineal: \\[Y_i=\\beta_0+\\beta_1X_i+\\beta_2X_i\\] 19.6 Regresión logística: p=P(Y=1) o sea la probabilidad que p tenga el valor de 1 o 1-p= 1-P(Y=1) que seria el valor de 0 en su conjunto de datos. \\[\\log\\frac{p}{1-p}=\\beta_0+\\beta_1X_i+\\beta_2X_i\\] Nota que la primera ecuación es un modelo que trata de predecir el valor de Y en la segunda se estima la probabilidad de que el valor de predictora tenga una valor de 1 o 0. Las probabilidades van a variar de 0 a 1 o sea de 0% a 100%. El vocabulario correcto es que las respuesta son binarias también dicho de la distribución de Bernoulli. Van a ver en la literatura que la formula se representa tambien de la siguiente forma, donde lo escribe como \\(logit(p)\\). \\[logit\\left(p\\right)=\\log\\frac{p}{1-p}=\\beta_0+\\beta_1X_i+\\beta_2X_i\\] En el siguiente enlace se puede encontrar más información https://en.wikipedia.org/wiki/Logistic_regression Se evalúa tres modelos: 1. la probabilidad de tener flores es relacionado a la cantidad de hojas (el tamaño de la planta). 2. la probabilidad de tener flores es relacionado a la hoja más larga de la planta (el tamaño de la planta). 3. la probabilidad de tener flores es relacionado a la hoja más larga de la planta y a la cantidad de hojas. 19.6.1 Generalized Linear Model = glm Code BrassModel.1 &lt;- glm(Flor_si_no ~ Cant_hojas, data = Brass, family = binomial()) summary(BrassModel.1) ## ## Call: ## glm(formula = Flor_si_no ~ Cant_hojas, family = binomial(), data = Brass) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.088221 0.134013 -23.04 &lt;2e-16 *** ## Cant_hojas 0.029925 0.002987 10.02 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 849.11 on 1435 degrees of freedom ## Residual deviance: 722.57 on 1434 degrees of freedom ## AIC: 726.57 ## ## Number of Fisher Scoring iterations: 5 Code BrassModel.2 &lt;- glm(Flor_si_no ~ Largo_Hoja_cm, data = Brass, family = binomial()) summary(BrassModel.2) ## ## Call: ## glm(formula = Flor_si_no ~ Largo_Hoja_cm, family = binomial(), ## data = Brass) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -4.96559 0.33283 -14.919 &lt;2e-16 *** ## Largo_Hoja_cm 0.11451 0.01199 9.553 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 849.11 on 1435 degrees of freedom ## Residual deviance: 722.30 on 1434 degrees of freedom ## AIC: 726.3 ## ## Number of Fisher Scoring iterations: 6 Code BrassModel.3 &lt;- glm(Flor_si_no ~ Cant_hojas+Largo_Hoja_cm, data = Brass, family = binomial()) summary(BrassModel.3) ## ## Call: ## glm(formula = Flor_si_no ~ Cant_hojas + Largo_Hoja_cm, family = binomial(), ## data = Brass) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -4.673981 0.330208 -14.155 &lt; 2e-16 *** ## Cant_hojas 0.019103 0.003132 6.100 1.06e-09 *** ## Largo_Hoja_cm 0.080198 0.013034 6.153 7.60e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 849.11 on 1435 degrees of freedom ## Residual deviance: 677.99 on 1433 degrees of freedom ## AIC: 683.99 ## ## Number of Fisher Scoring iterations: 6 19.6.2 Removiendo el intercepto Si no le interesa el intercepto se añade un “-1” después de la #Los valores de interes en nuestro caso son el intercepto y la pendiente (valor que se encuentra debajo del intercepto). Code names(Brass) ## [1] &quot;Isla&quot; &quot;Ano&quot; &quot;Numero_planta&quot; &quot;Cant_hojas&quot; ## [5] &quot;Largo_Hoja_cm&quot; &quot;Cant_capullo&quot; &quot;Cant_Flores&quot; &quot;Cant_Frutos&quot; ## [9] &quot;BQS&quot; &quot;Flor_si_no&quot; &quot;Frutos_si_no&quot; Code BrassModel.1.1 &lt;- glm(Flor_si_no ~ Cant_hojas+BQS+Largo_Hoja_cm-1, data = Brass, family = binomial()) summary(BrassModel.1.1) ## ## Call: ## glm(formula = Flor_si_no ~ Cant_hojas + BQS + Largo_Hoja_cm - ## 1, family = binomial(), data = Brass) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Cant_hojas 0.020693 0.003221 6.425 1.31e-10 *** ## BQSBoven -5.425491 0.428570 -12.660 &lt; 2e-16 *** ## BQSQuill -4.704079 0.392591 -11.982 &lt; 2e-16 *** ## BQSSaba -4.586157 0.328376 -13.966 &lt; 2e-16 *** ## Largo_Hoja_cm 0.083145 0.013310 6.247 4.19e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1990.72 on 1436 degrees of freedom ## Residual deviance: 668.85 on 1431 degrees of freedom ## AIC: 678.85 ## ## Number of Fisher Scoring iterations: 6 19.6.3 Estimado las probabilidades Predecir el número de frutas usando la ecuación, utilizando los resultados del modelo anterior \\[P(Y)\\quad =\\quad \\frac { 1 }{ 1+{ e }^{ -(b+m*{ x }_{ i }) } }\\] \\[P(Y)\\quad =\\quad \\frac { 1 }{ 1+{ e }^{ -((intercepto)+pendiente*variable.predictora) } }\\] # Se usa esta ecuacion para predecir un valor de ‘Y’ especifico para un valor de una variable ‘X’ de interes. Code summary(BrassModel.1) ## ## Call: ## glm(formula = Flor_si_no ~ Cant_hojas, family = binomial(), data = Brass) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.088221 0.134013 -23.04 &lt;2e-16 *** ## Cant_hojas 0.029925 0.002987 10.02 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 849.11 on 1435 degrees of freedom ## Residual deviance: 722.57 on 1434 degrees of freedom ## AIC: 726.57 ## ## Number of Fisher Scoring iterations: 5 Code exp(1) #= e ## [1] 2.718282 Code e=exp(1) e ## [1] 2.718282 Code P_10=1/(1+2.7182818284^-(-3.065 +0.0297*150)) P_10 ## [1] 0.8005922 Code P_10=1/(1+exp(1)^-(-3.065 +0.0297*100)) P_10 ## [1] 0.4762678 Code P_25=1/(1+exp(-(-3.065 +0.0297*25))) P_25 ## [1] 0.08927658 Code P_50=1/(1+e^-(-3.065 +0.0297*50)) P_50 ## [1] 0.1707955 Code P_70=1/(1+e^-(-3.065 +0.0297*70)) P_70 ## [1] 0.2717029 Code P_150=1/(1+e^-(-3.065 +0.0297*150)) P_150 ## [1] 0.8005922 19.7 Visualizando una regresión logistica Code names(Brass) ## [1] &quot;Isla&quot; &quot;Ano&quot; &quot;Numero_planta&quot; &quot;Cant_hojas&quot; ## [5] &quot;Largo_Hoja_cm&quot; &quot;Cant_capullo&quot; &quot;Cant_Flores&quot; &quot;Cant_Frutos&quot; ## [9] &quot;BQS&quot; &quot;Flor_si_no&quot; &quot;Frutos_si_no&quot; Code library(ggplot2) ggplot(Brass, aes(Cant_hojas,Flor_si_no))+ geom_point() 19.8 Reducir solapamiento de los puntos Usar geom_jitter ggplot(el archivo de datos, aes(las variables continuas)) • geom jitter(alpha, color, fill, shape, size) ◦ alpha: la intensidad del color ◦ color: el color de la línea alrededor de las barras ◦ fill: el color de las barras ◦ linetype: representa el estilo de línea; ver sección “Especificación Estética” ◦ size: representa el grosor de la línea ◦ weight: para modificar el valor original; entonces no sería, por ejemplo, el conteo/suma de los valores si no un valor ponderado (promedio ponderado) Code ggplot(Brass, aes(Cant_hojas,Flor_si_no))+ geom_jitter(height = 0.10) 19.9 Gráfico con ajuste binomial Code names(Brass) ## [1] &quot;Isla&quot; &quot;Ano&quot; &quot;Numero_planta&quot; &quot;Cant_hojas&quot; ## [5] &quot;Largo_Hoja_cm&quot; &quot;Cant_capullo&quot; &quot;Cant_Flores&quot; &quot;Cant_Frutos&quot; ## [9] &quot;BQS&quot; &quot;Flor_si_no&quot; &quot;Frutos_si_no&quot; Code ggplot(Brass, aes(Cant_hojas,Flor_si_no))+ geom_point(alpha=.5) + stat_smooth(method=&quot;glm&quot;, se=TRUE, method.args = list(family=binomial)) 19.9.1 El modelo de regresión binomial Code summary(BrassModel.1) ## ## Call: ## glm(formula = Flor_si_no ~ Cant_hojas, family = binomial(), data = Brass) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.088221 0.134013 -23.04 &lt;2e-16 *** ## Cant_hojas 0.029925 0.002987 10.02 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 849.11 on 1435 degrees of freedom ## Residual deviance: 722.57 on 1434 degrees of freedom ## AIC: 726.57 ## ## Number of Fisher Scoring iterations: 5 19.9.2 Vusualizando diferentes grupos En este gráfico se osbserva el valor de la pendiente, el mismo aumenta cuando el numero de hojas se aproxima a 100 (por ende al acercarnos a este valor el valor de nuestra variable de respuesta es mayor aumenta o es mayor). Code names(Brass) ## [1] &quot;Isla&quot; &quot;Ano&quot; &quot;Numero_planta&quot; &quot;Cant_hojas&quot; ## [5] &quot;Largo_Hoja_cm&quot; &quot;Cant_capullo&quot; &quot;Cant_Flores&quot; &quot;Cant_Frutos&quot; ## [9] &quot;BQS&quot; &quot;Flor_si_no&quot; &quot;Frutos_si_no&quot; Code ggplot(Brass, aes(Cant_hojas,Flor_si_no))+ geom_point(alpha=.5) + stat_smooth(method=&quot;glm&quot;, se=FALSE, method.args = list(family=binomial))+ facet_wrap(~Isla) 19.10 Solapamiento de los ajustes binomial por grupo Code names(Brass) ## [1] &quot;Isla&quot; &quot;Ano&quot; &quot;Numero_planta&quot; &quot;Cant_hojas&quot; ## [5] &quot;Largo_Hoja_cm&quot; &quot;Cant_capullo&quot; &quot;Cant_Flores&quot; &quot;Cant_Frutos&quot; ## [9] &quot;BQS&quot; &quot;Flor_si_no&quot; &quot;Frutos_si_no&quot; Code ggplot(Brass, aes(Cant_hojas,Flor_si_no, colour=BQS))+ geom_point(alpha=.5) + stat_smooth(method=&quot;glm&quot;, se=TRUE, method.args = list(family=binomial)) 19.10.1 Evaluate using the Length of the longest leaf Code names(Brass) ## [1] &quot;Isla&quot; &quot;Ano&quot; &quot;Numero_planta&quot; &quot;Cant_hojas&quot; ## [5] &quot;Largo_Hoja_cm&quot; &quot;Cant_capullo&quot; &quot;Cant_Flores&quot; &quot;Cant_Frutos&quot; ## [9] &quot;BQS&quot; &quot;Flor_si_no&quot; &quot;Frutos_si_no&quot; Code ggplot(Brass, aes(Largo_Hoja_cm,Flor_si_no))+ geom_jitter(height = 0.25) 19.10.2 Remover el valor sesgado El valor se remueve ya que no es posible una hoja de más de un metro 19.10.2.1 Nota que se hace un subgrupo (subset) de los datos, usando la función subset(el data frame, la condición) Code names(Brass) ## [1] &quot;Isla&quot; &quot;Ano&quot; &quot;Numero_planta&quot; &quot;Cant_hojas&quot; ## [5] &quot;Largo_Hoja_cm&quot; &quot;Cant_capullo&quot; &quot;Cant_Flores&quot; &quot;Cant_Frutos&quot; ## [9] &quot;BQS&quot; &quot;Flor_si_no&quot; &quot;Frutos_si_no&quot; Code ggplot(subset(Brass,Largo_Hoja_cm&lt;90), aes(Largo_Hoja_cm,Flor_si_no, colour=BQS))+ geom_jitter(height = 0.10)+ stat_smooth(method=&quot;glm&quot;, se=FALSE, method.args = list(family=binomial)) 19.11 Selecionar el mejor modelo Vea modulo T16 Criterio de Información "],["selecionando-modelos-con-akaike.html", "Chapter 20 Selecionando modelos con AKAIKE 20.1 Datos, hipótesis y modelos", " Chapter 20 Selecionando modelos con AKAIKE 20.1 Datos, hipótesis y modelos La ciencia es un proceso para aprender sobre nuestro entorno en donde múltiples ideas, de vez en cuando contradictorias, trata de explicar como el mundo funciona. Típicamente uno comienza con una idea, una expresión verbal, que se desarrolla como una hipótesis. Luego es necesario expresar esa hipótesis con una ecuación matemática o sea un modelo. El concepto de modelos en la ciencia es que explica un proceso simplificado (por ejemplo biológico) que da una apreciación sobre los factores que son responsable para el patrón observado. Por consecuencia cuan bien los datos reflejan el modelo también refleja un apoyo sobre la hipótesis. Hay dos acercamiento principales para inferir. El método tradicional es determinar si la hipótesis nula puede ser rechazado basado un conjunto de datos. Rechazar la hipótesis es rechazada cuando una prueba estadística resulta en un valor por encima de un umbral, típicamente p &lt; 0.05. Rechazar la hipótesis nula es evidencia para muchos que la hipótesis alterna es CORRECTA. Aunque parece ser un juego de palabra, es que realmente estamos solamente diciendo que no hay apoyo para la hipótesis nula. La razón es que no estamos probando si la hipótesis alterna es veridica. Es importante recordar que la descripción de la hipótesis alterna (la descripción de esa) puede ser equivocada. El acercamiento alterno, la selección de modelo ofrece una alternativa en donde uno compara múltiples hipótesis y produce su inferencia de estos resultados. La selección de modelos es basado en la teoría de verosimilitud (likelihood). Las ventajas es que el investigador no esta limitado a evaluar un solo modelo donde el umbral es uno que es arbitrario (el modelo nulo con un valor de p &lt;0.05). Los modelos pueden ser comparado uno con el otro y organizado por su peso (weight o sea el apoyo estadístico), ofreciendo una medida relativa de apoyo contra las otras hipótesis. En caso que hay modelos que tienen el mismo apoyo uno puede seleccionar los mejores modelos y calcular un modelo promedio. "],["como-funciona-la-selección-de-modelos.html", "Chapter 21 #Como funciona la selección de modelos? 21.1 \\(R^2\\) 21.2 Pruebas de modelos nulos 21.3 Cual método es más apropriado? 21.4 Estimación de parámetros y múltiples modelos 21.5 Selección de Modelos entre muchos 21.6 Model Averaging: 21.7 Inferencias de los modelos de selección 21.8 Paso a Paso", " Chapter 21 #Como funciona la selección de modelos? El acercamiento filosófico de selección de modelos es evaluar múltiples hipótesis y evaluar la evidencia que apoya estas. Por consecuencia el primer paso es articular un grupo de hipótesis razonables. Segundo es que cada hipótesis tiene que ser adaptado a los datos observados con una función matemática. El tercer paso es seleccionar un método de selección de modelos y comparar los resultados. 21.1 \\(R^2\\) El acercamiento tradicional en la literatura es el \\(R^2\\) o el coeficiente de determinación. Que es un acercamiento sencillo de selección de modelo. Donde mayor es el valor de \\(R^2\\) mayor es el ajuste (Fit) del modelo. Este acercamiento no toma en cuenta la complejidad de los modelos y siempre selecciona modelos más complejos. La razón es que selecciona modelos más complejos es que a añadir más variables a un modelo (por ejemplo regresión lineal múltiples), añadir otra variable explica en parte la variación aunque esta nueva variable explica muy poco, pero ya que explica un componente aumenta el \\(R^2\\) . Por consecuencia no toma en cuenta el concepto de parsimonia, donde deberíamos seleccionar el modelos más sencillo tomando encenta el ajuste y la complejidad del modelo. Un método de selección de modelos debería tomar en cuenta la complejidad de los modelos y penalizar por modelos excesivamente complejos. 21.1.1 Ejemplo de Construcción de selección por \\(R^2\\) Seleccionamos los datos de modulo regresión multiples (TF5). Sobre el Biomass Index y comoo esta corelacionado con la edad, el nivel de colesterol y glucosa en la sangre. Code library(readxl) reg.multiple &lt;- read_excel(&quot;Data_files_csv/mod_empiricos.xlsx&quot;, sheet = &quot;bmi&quot;) # para ver las primeras seis filas de datos head(reg.multiple) Table 21.1: BMIAgeCholesterolGlucose 19.32117895 24.55725098 24.746176102 47.947171105 44.261222101 29.97415672 21.1.1.1 Installar los siguientes paquetes si no lo tienen instalado Code if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(&quot;MuMIn&quot;, &quot;formattable&quot;) Se construye un modelo con todos los parametros. Vemos que el \\(R^2= 0.0785\\). Code library(car) library(sjPlot) model &lt;- lm(BMI ~ Age + Cholesterol + Glucose, data = reg.multiple) tab_model(model)   BMI Predictors Estimates CI p (Intercept) 16.82 6.65 – 26.98 0.002 Age 0.04 -0.07 – 0.15 0.469 Cholesterol 0.05 -0.00 – 0.10 0.058 Glucose 0.02 -0.01 – 0.05 0.192 Observations 58 R2 / R2 adjusted 0.127 / 0.079 Ahora evaluamos todas las posibles combinaciones de modelos. Considera la columna de \\(R^2\\) y los valores para cada modelo. Los que se observa es que el modelos con más variables tiene un \\(R^2\\) más alto seguido con modelos con dos variables. La pregunta principal, un modelo con cuatro variables con un \\(R^2=.127\\) es significativamente mejor que un modelo de 2 variables con un \\(R^2=.1185\\). Usando el método tradicional no hay mecanismos para seleccionar y evaluar cual de los modelos es el mejor tomando en cuenta la complejidad del modelo. NOTA: NA en la tabla quiere decir que esta variable no esta incluida en el modelo. Code library(MASS) library(MuMIn) options(na.action = &quot;na.fail&quot;) model2=lm(BMI ~ Age + Cholesterol + Glucose, data = reg.multiple) # El Modelo más completo #model2 #summary(model2) ALL_models=dredge(model2, extra=&quot;R^2&quot;) # Evaluación de todas las compbinaciones/alternativas (modelos) Code library(formattable) formattable(ALL_models, digits=5, format=&quot;html&quot;) (Intercept) Age Cholesterol Glucose R^2 df logLik AICc delta weight 7 17.952 NA 0.050975 0.022541 0.118463 4 -187.63 384.01 0.00000 0.260568 3 20.012 NA 0.054149 NA 0.079020 3 -188.90 384.24 0.22846 0.232441 4 17.967 0.060198 0.049483 NA 0.098811 4 -188.27 385.29 1.27881 0.137477 8 16.815 0.041027 0.048190 0.019738 0.127045 5 -187.34 385.84 1.83172 0.104272 5 27.167 NA NA 0.025015 0.048912 3 -189.83 386.10 2.09427 0.091445 1 30.108 NA NA NA 0.000000 2 -191.28 386.78 2.77661 0.065011 2 26.304 0.078579 NA NA 0.034720 3 -190.26 386.96 2.95332 0.059514 6 24.855 0.057793 NA 0.020876 0.066354 4 -189.29 387.34 3.33101 0.049272 21.2 Pruebas de modelos nulos La prueba de verosimilitud (PV) es el método más utilizado de las pruebas de hipótesis nula. La PV compara pares de modelos, cuando el la verosimilitud de un modelos más complejo es significativamente más grande que el modelo sencillo, el modelo complejo es aceptado y vise versa. Tipicamente se usa como indice el chi cuadrado \\(\\chi^2\\). En este caso al contrario del \\(R^2\\), la selección de un modelo más complejo cuando tiene un PV más grande tiene beneficio aunque sea más complejo el modelo. La desventaja es que prueba no es independiente por consecuencia infla el error de tipo I o sea el \\(\\alpha\\). Otro punto importante es que la complejidad se añade de forma sucesiva a los modelos, por consecuencia Tabla de métodos comunes para selección de modelos En la siguiente tabla tenemos mencionado cinco métodos de selección de modelos. El primero que fue desarrollado fue el de Akaike Information criterion ( ref), por consecuencia es el más utilizado por ser el más conocido. Pero hay múltiples otros que no están mencionado aquí como el Bayes Factor y el Mallow’s \\(C_p\\). Puede encontrar más información en el siguiente enlace. https://en.wikipedia.org/wiki/Model_selection#Criteria Selección de modelos Formula Criterio de selección \\(Verosimilitud\\) \\(\\\\-2\\left\\{\\ln\\left[L(\\theta_p\\ |y\\right)]+\\ln\\left[L(\\theta_{p+q}\\ | y\\right)]\\right\\}\\) Ajuste \\(AIC\\) \\(\\\\AIC=-2\\ln\\left[L(\\theta_p\\ |y\\right)]+2p\\) Ajuste y complejidad \\(AIC_c\\) \\(\\\\AIC_c=-2\\ln\\left[L(\\theta_p\\ |y\\right)]+2p\\left(\\frac{n}{n-p-1}\\right)\\) Ajuste y complejidad, con corrección para tamaño de muestra pequeña \\(Schwartz\\) \\(\\\\SC=-2\\ln\\left[L(\\theta_p\\ |y\\right)]+p\\cdot\\ln\\left(n\\right)\\) Ajuste y complejidad, tamaño de muestra \\(R_{adj}^2\\) \\(R_{adj}^2=1-\\frac{RSS/n-p-1}{\\frac{\\sum_{n=i}^n\\left(y_i-\\overline{y}\\right)^2}{n-1}}\\) Ajuste ** Las ideas y conceptos mencionado siguen en parte Johnson and Omland 2004. 21.3 Cual método es más apropriado? Métodos que maximizan la verosimilitud solamente tiene una limitaciones en respeto a la parsimonia del modelo. En múltiples áreas de estudio se esta moviendo a métodos que no incluye solamente la verosimilitud pero la complejidad de los modelos. En general el meetodo que más se usa es el AIC en parte porque esta fundado en el Criterio de Información de Kullback-Leibler, pero hay otros que prefieren por ejemplo el criterio de información de Schwarz debido que este selecciona modelos más parsimonia. Nota que en este último toma en cuenta no solamente el ajuste, la complejidad pero el tamaño de muestra. El Schwarz es conocido también como el Bayesian Information Criterion, BIC, aunque no tiene nada de Bayesiano en el método de análisis. Para aclarar, el BIC no usa información previa para hacer los cálculos, y se puede usar tanto con análisis tradicional como Bayesiano. 21.4 Estimación de parámetros y múltiples modelos En muchos estudios el objetivo principal es estimar los parámetros para poder inferir algún proceso biológico o comportamiento humano. Por ejemplo, ¿cual es la dosis apropiada de algún antibiótico para reducir el crecimiento de bacteria y el tiempo del tratamiento?. Cuando hay un buen apoyo para un modelo especifico, los estimados de los parámetros de la verosimilitud pueden ser utilizados. Pero de vez en cuando hay apoyo para múltiples modelos, en otra palabra hay apoyo iguales para múltiples modelos, lo que resulta un problema seleccionar un modelo que sea mejor que otro. En este caso si hay más de un modelo se utiliza el promedio de los modelos. Los estimados de los parámetros de un modelo promedio son robustos en dos aspectos, 1) reduce el sesgo de seleccionar modelos y 2) toma en cuenta la incertidumbre en los modelos. 21.5 Selección de Modelos entre muchos ¿Como seleccionar el mejor modelo entre muchos? Si por ejemplo usamos el indice de Akaike (AIC), cada modelo fue ajustado a los datos y el indice de \\(AIC_i\\) fue calculado, la diferencia entre los valores de AIC, \\(\\Delta_i\\) y el mejor modelo, \\(AIC_{\\min}\\) es calculado. El mejor modelo en el conjunto evaluado es el modelo con un AIC más pequeño, \\(AIC_{\\min}\\). \\(\\Delta _i=AIC_i-AIC_{\\min }\\) La verosimilitud (likelihood) de un modelo, \\(g_i\\), dado los datos, \\(y\\), es calculado de la siguiente forma. \\(L(g_i\\ |y)=\\exp\\left(\\frac{-1}{2\\cdot\\Delta_i}\\right)\\), Comparar pares de modelos, particularmente el mejor modelo y los otros, tiene un indice que se llama evidence ratio, ER y traducido aquí como la razón de evidencia. \\(ER=\\frac{L(g_{mejor}\\ |y)}{L(g_i\\ |y)}\\), Los valores de verosimilitud se pueden normalizar para que la suma de los modelos sea 1. \\(W_i=\\frac{\\exp\\left(-\\frac{1}{2\\cdot\\Delta_i}\\right)}{\\sum_{j=i}^R\\exp\\left(-\\frac{1}{2\\cdot\\Delta j}\\right)}\\), Este valor conocido como el weight de Akaike, o el peso de los modelos puede ser interpretado como una probabilidad que el modelo \\(i\\) es el mejor modelo de los modelos evaluados. 21.6 Model Averaging: Cuando no hay un modelo único apoyado por los datos, no hay apoyo sustancial para un modelo único. Modelos que no tienen mucho apoyo pudiese incluir ciertas condiciones, por ejemplo si se usa el peso de los modelos y este no es muy grande \\(w_{best}&lt;0.09\\) o si la diferencia entre los modelos tienen un \\(\\Delta AIC\\) de menor 2. En este caso se necesita calcular los promedios ponderado de los parámetros, \\(\\tilde{\\theta}\\). \\(\\tilde{\\theta}=\\sum_{n=1}^Rw_i\\tilde{\\theta}_i\\) donde el \\(\\tilde{\\theta}_i\\) es el estimado de \\(\\tilde{\\theta}\\) del modelo \\(i_{th}\\) de los *mejores* modelos. De esta forma los parámetros del modelo están ponderado por su apoyo \\(w_{best}\\). En adición se puede calcular la varianza de los parámetros con la siguiente formula. \\(\\hat{var}(\\tilde{\\theta})=\\sum_{n=1}^Rw_i[\\hat{var}\\left(\\tilde{\\theta}\\ |g_i\\right)+\\ (\\tilde{\\theta}-\\hat{\\theta})^2 ]\\) donde \\(\\hat{var}\\left(\\tilde{\\theta}\\ |g_i\\right)\\) es el estimado de la varianza de \\(\\theta\\) del modelo \\(i_{th}\\). El estimador de varianza puede ser utilizado para evaluar la precisión de los estimados del conjunto de modelos considerados. Esto permite generar intervalos de confianza de los parámetros para tomar en consideración la incertidumbre de los modelos de selección. hacer una lista de las condiciones para selección de modelos con su referencias 21.7 Inferencias de los modelos de selección La selección de modelos es una herramienta para inferir procesos no observados basado en datos que demuestra un patrón. Datos que claramente apoya una hipótesis entre muchas evaluadas puede inferir procesos que pudiese haber generado los datos observados. 21.8 Paso a Paso 21.8.1 Primer paso: Construcción de los modelos El primer paso es construir los modelos que queremos comparar, para facilitar el ejemplo usamos un modelos complejo y comparamos todas las diferentes alternativas. NOTA: que este no es necesariamente el mejor acercamiento, ya que uno debería tener a priori una serie de modelos candidatos. Los datos son para evaluar sin hay efecto de cambio de nivel de ansiedad y depresión en la población de Puerto Rico luego del Huracán María. Los datos presentado son solamente parcial y incluye solamente un de los indices el del nivel de depresión después de 5 o más semanas luego del Huracán (Tremblay et al. sin publicar). La hipótesis es que algunos factores sociales y/o económico influencia el nivel de depresión en la gente. Code library(readr) DFMaria_student &lt;- read_csv(&quot;Data_files_csv/DFMaria_student.csv&quot;) Metadata: Sexo, 1= Mujer; 2 = Hombres Escolaridad, major el número más escolaridad tiene Num_Pers_Hogar, Cantidad de persona que comparte el hogar familiar Sala_Mens_Antes, El salario mensual antes del Huracán María, mayor el número mayor el salario Sala_Mens_Desp, El salario mensual después del Huracán María, mayor el número mayor el salario Index_Dep5T, Un indice de depresión 5 o más semanas después del Huracán. 21.8.2 Limpiar los datos El primer paso es remover todos los participantes donde le falta algún información. Code DFMaria_student=na.omit(DFMaria_student) 21.8.3 Construcción del modelo Code head(DFMaria_student) Table 21.2: ...1SexoEscolaridadNum_Pers_HogarSala_Mens_AntesSala_Mens_DespIndex_Dep5T 11434419 21432216 3174229 4142532 52456617 6252278 Code Huracan_Dep=lm(Index_Dep5T~factor(Sexo)+Escolaridad+Num_Pers_Hogar+ Sala_Mens_Antes+ Sala_Mens_Desp, data=DFMaria_student) Code ggplot(DFMaria_student, aes(y=Index_Dep5T,x=Sala_Mens_Desp))+ geom_smooth(method = lm) 21.8.3.1 Observar el resultado del modelo lineal completo. Code summary(Huracan_Dep) ## ## Call: ## lm(formula = Index_Dep5T ~ factor(Sexo) + Escolaridad + Num_Pers_Hogar + ## Sala_Mens_Antes + Sala_Mens_Desp, data = DFMaria_student) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.1426 -3.8984 -0.3931 4.0240 20.6993 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 13.37228 0.86017 15.546 &lt;2e-16 *** ## factor(Sexo)2 -0.71014 0.45979 -1.544 0.1228 ## Escolaridad -0.34298 0.18922 -1.813 0.0702 . ## Num_Pers_Hogar 0.03879 0.17797 0.218 0.8275 ## Sala_Mens_Antes 0.47255 0.27245 1.734 0.0831 . ## Sala_Mens_Desp -0.58913 0.27367 -2.153 0.0316 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.872 on 995 degrees of freedom ## Multiple R-squared: 0.01324, Adjusted R-squared: 0.008285 ## F-statistic: 2.671 on 5 and 995 DF, p-value: 0.02084 21.8.3.2 Evaluar todas los modelos. Se ordena los modelos comenzando con el mejor, y si resta el valor de AICc con el mejor modelo, menor es el AICc mejor es el modelo. Los modelos que se estará aceptando son los que tienen un delta de menos &lt;-2.00 (comparando con el mejor modelo), \\(\\Delta_i=AIC_i-AIC_{\\min}\\). En otra palabra los modelos que difieren más de un AICc de 2.0 no se aceptan como buenos modelos. En este caso los seis primeros modelos son igual de bueno, y no hay evidencia que uno es mejor que el otro. Cuando hay más de un modelo se tiene que calcular los promedios ponderados de los parámetros \\(\\beta_i\\) . Table 21.3: Criterios de Selección de Modelos AIC_BIC_deltaInterpretación 0-2Poca evidencia que los modelos son diferentes 2-4Evidencia que los modelos son diferentes &gt;4Mucha evidencia que los modelos son diferentes Con la función dredge del paquete MuMIn podemos evaluar todas las combinaciones de modelos Code library(MASS) library(MuMIn) options(na.action = &quot;na.fail&quot;) Huracan_Dep=lm(Index_Dep5T~Escolaridad+Num_Pers_Hogar+ Sala_Mens_Antes+ Sala_Mens_Desp, data=DFMaria_student) # El Modelo más completo #model2 #summary(model2) ALL_models=dredge(Huracan_Dep, rank=&quot;AIC&quot;, extra = c(BIC, &quot;R^2&quot;)) # Evaluación de todas las combinaciones/alternativas (modelos) library(formattable) formattable(ALL_models, digits=4, format=&quot;html&quot;) (Intercept) Escolaridad Num_Pers_Hogar Sala_Mens_Antes Sala_Mens_Desp BIC R^2 df logLik AIC delta weight 14 13.19 -0.3027 NA 0.45991 -0.6005 6730 1.082e-02 5 -3348 6706 0.0000 0.189345 13 12.40 NA NA 0.43763 -0.6402 6726 8.232e-03 4 -3349 6706 0.6199 0.138880 10 13.30 -0.2866 NA NA -0.1716 6726 7.985e-03 4 -3349 6707 0.8694 0.122596 9 12.55 NA NA NA -0.2290 6722 5.655e-03 3 -3350 6707 1.2183 0.102969 2 13.03 -0.3999 NA NA NA 6722 5.229e-03 3 -3351 6707 1.6469 0.083108 16 13.07 -0.3014 0.04136 0.45627 -0.6000 6737 1.088e-02 6 -3348 6708 1.9458 0.071570 15 12.26 NA 0.05008 0.43335 -0.6393 6733 8.311e-03 5 -3349 6708 2.5406 0.053159 12 13.13 -0.2849 0.05848 NA -0.1757 6733 8.093e-03 5 -3349 6709 2.7609 0.047613 6 13.19 -0.3395 NA -0.09285 NA 6728 6.046e-03 4 -3350 6709 2.8240 0.046134 11 12.36 NA 0.06593 NA -0.2332 6728 5.791e-03 4 -3350 6709 3.0807 0.040578 4 12.96 -0.4003 0.02282 NA NA 6729 5.245e-03 4 -3351 6709 3.6302 0.030830 5 12.30 NA NA -0.15932 NA 6725 2.758e-03 3 -3352 6710 4.1302 0.024010 8 13.06 -0.3381 0.04460 -0.09625 NA 6735 6.108e-03 5 -3350 6711 4.7613 0.017513 1 11.66 NA NA NA NA 6720 0.000e+00 2 -3353 6711 4.8945 0.016384 7 12.14 NA 0.05470 -0.16313 NA 6731 2.851e-03 4 -3352 6712 6.0361 0.009258 3 11.61 NA 0.01597 NA NA 6727 8.130e-06 3 -3353 6713 6.8864 0.006052 21.8.3.3 Calcular el coeficientes ponderados Code #allmodels=format(round(ALL_models, digits=3), scientific=FALSE) #library(data.table) #write.csv(allmodels, &quot;allmodelsdata.csv&quot;) 21.8.4 Seleccionar los modelos Seleccionar los modelos que tienen un delta AICc menor de 2 y calcular el promedio de los coeficientes de los modelos. Nota el conjunto de coeficientes debajo subset, esto son los coeficientes de las variables del conjunto de modelos que tienen un delta AICc menor de 2. Code # calculate the model average model.avg(ALL_models, subset = delta &lt; 2) ## ## Call: ## model.avg(object = ALL_models, subset = delta &lt; 2) ## ## Component models: ## &#39;134&#39; &#39;34&#39; &#39;14&#39; &#39;4&#39; &#39;1&#39; &#39;1234&#39; ## ## Coefficients: ## (Intercept) Escolaridad Sala_Mens_Antes Sala_Mens_Desp Num_Pers_Hogar ## full 12.93159 -0.2078493 0.2547956 -0.4095744 0.004178587 ## subset 12.93159 -0.3155782 0.4515174 -0.4640050 0.041363512 Code # get the subset of the best models into a data frame bestModels &lt;- get.models(ALL_models, subset=delta&lt;2) bestModels &lt;- model.avg(bestModels) bestModels=summary(bestModels) # bestModels$coefficients 21.8.5 Extraer los parametros del modelo, usando las sigueientes funciones Code bestModelsResults=data.frame(bestModels$coefmat.subset) names(bestModelsResults) ## [1] &quot;Estimate&quot; &quot;Std..Error&quot; &quot;Adjusted.SE&quot; &quot;z.value&quot; &quot;Pr...z..&quot; Code bestModelsResults Table 21.4: EstimateStd..ErrorAdjusted.SEz.valuePr...z.. 12.9&nbsp;&nbsp;&nbsp;0.7030.70418.4&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.316&nbsp;0.1890.19&nbsp;1.67&nbsp;0.0959 0.452&nbsp;0.2720.2721.66&nbsp;0.0974 -0.464&nbsp;0.3030.3031.53&nbsp;0.126&nbsp; 0.04140.1780.1780.2320.817&nbsp; Code BMR=setNames(cbind(rownames(bestModelsResults), bestModelsResults, row.names = NULL), c(&quot;Variables&quot;, &quot;Coef_Estimate&quot;, &quot;Std_Error&quot;, &quot;AdjustedSE&quot;, &quot;z_value&quot;, &quot;p_value&quot;)) BMR=as.data.frame(BMR) #BMR is.data.frame(BMR) ## [1] TRUE 21.8.6 Intervalos de Confianza Los Intervalos de confianza de los parámetros se extraje del modelo usando la siguiente funciones. Code library(ggplot2) library(coefplot) # Calcular el intervalo de confianza de 2.5% y de 97.5% BMR$LowerBound=BMR$Coef_Estimate-BMR$AdjustedSE*2 BMR$UpperBound=BMR$Coef_Estimate+BMR$AdjustedSE*2 BMR Table 21.5: VariablesCoef_EstimateStd_ErrorAdjustedSEz_valuep_valueLowerBoundUpperBound (Intercept)12.9&nbsp;&nbsp;&nbsp;0.7030.70418.4&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;11.5&nbsp;&nbsp;&nbsp;14.3&nbsp;&nbsp;&nbsp; Escolaridad-0.316&nbsp;0.1890.19&nbsp;1.67&nbsp;0.0959-0.695&nbsp;0.0635 Sala_Mens_Antes0.452&nbsp;0.2720.2721.66&nbsp;0.0974-0.09340.996&nbsp; Sala_Mens_Desp-0.464&nbsp;0.3030.3031.53&nbsp;0.126&nbsp;-1.07&nbsp;&nbsp;0.143&nbsp; Num_Pers_Hogar0.04140.1780.1780.2320.817&nbsp;-0.315&nbsp;0.398&nbsp; Code names(BMR) ## [1] &quot;Variables&quot; &quot;Coef_Estimate&quot; &quot;Std_Error&quot; &quot;AdjustedSE&quot; ## [5] &quot;z_value&quot; &quot;p_value&quot; &quot;LowerBound&quot; &quot;UpperBound&quot; 21.8.7 Visualizar los coeficientes con los intervalos de confianza Code ggplot(BMR, mapping=aes(x=Variables, y = Coef_Estimate, ymin = LowerBound, ymax = UpperBound, colour=Variables))+ geom_point()+ geom_hline(yintercept=0.0, colour=&quot;blue&quot;)+ coord_flip()+ geom_pointrange()+ xlab(&quot;Variables&quot;)+ ylab(&quot;Mean Coefficients: Indice de depresión&quot;)+ rlt_theme+ theme(legend.position=&quot;none&quot;) Code ggsave(&quot;Indice_depresión.png&quot;) Referencias: Johnson, J. B., K. S. Omland. 2004. Model selection in ecology and evolution. TRENDS in Ecology and Evolution. 19:101-108. doi: 10.1016/j.tree.2003.10.013. “Activities reported in this website was supported by the National Institute of General Medical Sciences of the National Institutes of Health under Award Number R25GM121270. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.”`` aic "],["pruebas-no-parametricas.html", "Chapter 22 Pruebas no parametricas 22.1 Non-parametric tests 22.2 Los paquetes 22.3 Activating packages 22.4 Wilcoxon rank-sum test 22.5 The hypothesis: 22.6 The level of depression posterior to the intake of alcohol is the same as those which take ecstasy. 22.7 Enter raw data 22.8 Or Import the data 22.9 Exploratory analysis 22.10 Descriptive statistics. 22.11 Test of equality of variance 22.12 Wilcoxon rank-sum test 22.13 This is how to assing the Rank by Hand…… This is an example, the scripts will do this automatically. 22.14 Wilcoxon test: A non-parametric test 22.15 the following approach is better because it can deal with ties (values that are equal) 22.16 Class Excercise 22.17 How many time have you gone to Disney, and is there a difference between genders? 22.18 Comparing two related conditions: the Wilcoxon signed-rank test (similar to paired t-test) 22.19 Krukall-Wallis Test 22.20 Soya and the effect on sperm production in human males. 22.21 Abstract 22.22 Hacer un boxplot de los datos en un nuevo chunk 22.23 Kruskall Wallis test is similar to an ANOVA without assuming normal distribution or equality of variance.", " Chapter 22 Pruebas no parametricas 22.1 Non-parametric tests All the previous tests assume that the data have different characteristics, such as normal distribution and homogeneity of variance. If the data CANNOT comply with these assumptions then the previous tests should not be used and alternative tests have to be explored. One set of tests are known as “Non-Parametric tests” or “Distribution Free Tests”. Most of these tests do no use the original data but use the Ranks of the data. That is is done by assigning “new values” to the original data. The lowest value is assigned the rank of 1, the the next lowest value the rank of 2, and so on. Thus the highest value has the highest rank. Then the analysis are on the ranks and NOT on the original values. 22.2 Los paquetes Code #install.packages(&quot;car&quot;) #install.packages(&quot;clinfun&quot;) #install.packages(&quot;ggplot2&quot;) #install.packages(&quot;pastecs&quot;) #install.packages(&quot;pgirmess&quot;) 22.3 Activating packages Code library(car) # Companion to applied Regression library(clinfun) # Clinical Trial Design and Data Analysis Functions library(ggplot2) # Graphic production library(pastecs) # Package for analysis of Space -Time ecological Series library(pgirmess) # Spatial Analysis and Data Mining for Field Ecologist 22.4 Wilcoxon rank-sum test The function “gl()” is a function that generates factors by specifying the pattern of their levels gl(n, k, lenght=n*k, labels=1:n, ordered=FALSE) 22.5 The hypothesis: 22.6 The level of depression posterior to the intake of alcohol is the same as those which take ecstasy. 22.6.1 Is this the null or alternate hipothesis? The data come from 20 participants, 10 drinking alcohol and 10 taking ecstasy. Posterior to their consumption the “Beck Depression Inventory” was conducted on each of the participants. The scale is from 0 (happy) to 63 (truly depressed) https://www.ismanet.org/doctoryourspirit/pdfs/Beck-Depression-Inventory-BDI.pdf https://en.wikipedia.org/wiki/Beck_Depression_Inventory 22.7 Enter raw data Code sundayBDI&lt;-c(15, 35, 16, 18, 19, 17, 27, 16, 13, 20, 16, 15, 20, 15, 16, 13, 14, 19, 18, 18) wedsBDI&lt;-c(28, 35, 35, 24, 39, 32, 27, 29, 36, 35, 5, 6, 30, 8, 9, 7, 6, 17, 3, 10) drug&lt;-gl(2, 10, labels = c(&quot;Ecstasy&quot;, &quot;Alcohol&quot;)) Gender=gl(2, 10, labels = c(&quot;Male&quot;, &quot;Female&quot;)) drugData&lt;-data.frame(Gender, drug, sundayBDI, wedsBDI) drugData (#tab:Enter data) GenderdrugsundayBDIwedsBDI MaleEcstasy1528 MaleEcstasy3535 MaleEcstasy1635 MaleEcstasy1824 MaleEcstasy1939 MaleEcstasy1732 MaleEcstasy2727 MaleEcstasy1629 MaleEcstasy1336 MaleEcstasy2035 FemaleAlcohol165 FemaleAlcohol156 FemaleAlcohol2030 FemaleAlcohol158 FemaleAlcohol169 FemaleAlcohol137 FemaleAlcohol146 FemaleAlcohol1917 FemaleAlcohol183 FemaleAlcohol1810 22.8 Or Import the data 22.9 Exploratory analysis Code library(readr) Drug &lt;- read_csv(&quot;Data_files_csv/Drug.csv&quot;) head(Drug) Table 22.1: drugsundayBDIwedsBDI Ecstasy1528 Ecstasy3535 Ecstasy1635 Ecstasy1824 Ecstasy1939 Ecstasy1732 22.10 Descriptive statistics. Note here we can use drugData[,c(2:3)], that we want the stats for column 2 and 3, and these be seperated by the drug (column 1). NOTE the shapiro wilks test on the last line. Code names(drugData) ## [1] &quot;Gender&quot; &quot;drug&quot; &quot;sundayBDI&quot; &quot;wedsBDI&quot; Code by(drugData[,c(3:4)], drugData$drug, stat.desc, basic=TRUE, norm=TRUE) ## drugData$drug: Ecstasy ## sundayBDI wedsBDI ## nbr.val 10.00000000 10.0000000 ## nbr.null 0.00000000 0.0000000 ## nbr.na 0.00000000 0.0000000 ## min 13.00000000 24.0000000 ## max 35.00000000 39.0000000 ## range 22.00000000 15.0000000 ## sum 196.00000000 320.0000000 ## median 17.50000000 33.5000000 ## mean 19.60000000 32.0000000 ## SE.mean 2.08806130 1.5129074 ## CI.mean.0.95 4.72352283 3.4224344 ## var 43.60000000 22.8888889 ## std.dev 6.60302961 4.7842334 ## coef.var 0.33688927 0.1495073 ## skewness 1.23571300 -0.2191665 ## skew.2SE 0.89929826 -0.1594999 ## kurtosis 0.26030385 -1.4810114 ## kurt.2SE 0.09754697 -0.5549982 ## normtest.W 0.81063991 0.9411413 ## normtest.p 0.01952060 0.5657814 ## ------------------------------------------------------------ ## drugData$drug: Alcohol ## sundayBDI wedsBDI ## nbr.val 10.00000000 1.000000e+01 ## nbr.null 0.00000000 0.000000e+00 ## nbr.na 0.00000000 0.000000e+00 ## min 13.00000000 3.000000e+00 ## max 20.00000000 3.000000e+01 ## range 7.00000000 2.700000e+01 ## sum 164.00000000 1.010000e+02 ## median 16.00000000 7.500000e+00 ## mean 16.40000000 1.010000e+01 ## SE.mean 0.71802197 2.514182e+00 ## CI.mean.0.95 1.62427855 5.687475e+00 ## var 5.15555556 6.321111e+01 ## std.dev 2.27058485 7.950542e+00 ## coef.var 0.13845030 7.871823e-01 ## skewness 0.11686189 1.500374e+00 ## skew.2SE 0.08504701 1.091907e+00 ## kurtosis -1.49015904 1.079110e+00 ## kurt.2SE -0.55842624 4.043886e-01 ## normtest.W 0.95946584 7.534665e-01 ## normtest.p 0.77976459 3.933024e-03 Code #shapiro.test(drugData$sundayBDI) # this is to look at all the data, it is not the appropriate way to do the analisis of normality, why? #shapiro.test(drugData$wedsBDI) # this is to look at all the data, it is not the appropriate way to do the analisis of normality, why? 22.10.1 Do a histogram by factor level for anxiety for Sunday. Code library(ggplot2) ggplot(drugData, aes(x=sundayBDI, fill=drug))+ geom_histogram(colour=&quot;white&quot;)+ facet_grid(~drug) 22.11 Test of equality of variance This is one of the assumptions of parametric tests Code #leveneTest(drugData$sundayBDI, drugData$drug, center = &quot;mean&quot;) leveneTest(drugData$sundayBDI, drugData$drug, center = &quot;median&quot;) (#tab:equality of variance) DfF valuePr(&gt;F) 11.880.187 18&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code #leveneTest(drugData$wedsBDI, drugData$drug, center = &quot;mean&quot;) leveneTest(drugData$wedsBDI, drugData$drug, center = &quot;median&quot;) (#tab:equality of variance) DfF valuePr(&gt;F) 10.09110.766 18&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 22.12 Wilcoxon rank-sum test wilcox.test(x, y = NULL, alternative = c(“two.sided”, “less”, “greater”), mu = 0, paired = FALSE, exact = FALSE, correct = FALSE, conf.level = 0.95, na.action = na.exclude) 22.13 This is how to assing the Rank by Hand…… This is an example, the scripts will do this automatically. Look for the smallest value……in the wedsBDI…… Code drugData$wedsRank=rank(drugData$wedsBDI) drugData Table 22.2: GenderdrugsundayBDIwedsBDIwedsRank MaleEcstasy152812&nbsp;&nbsp; MaleEcstasy353517&nbsp;&nbsp; MaleEcstasy163517&nbsp;&nbsp; MaleEcstasy182410&nbsp;&nbsp; MaleEcstasy193920&nbsp;&nbsp; MaleEcstasy173215&nbsp;&nbsp; MaleEcstasy272711&nbsp;&nbsp; MaleEcstasy162913&nbsp;&nbsp; MaleEcstasy133619&nbsp;&nbsp; MaleEcstasy203517&nbsp;&nbsp; FemaleAlcohol1652&nbsp;&nbsp; FemaleAlcohol1563.5 FemaleAlcohol203014&nbsp;&nbsp; FemaleAlcohol1586&nbsp;&nbsp; FemaleAlcohol1697&nbsp;&nbsp; FemaleAlcohol1375&nbsp;&nbsp; FemaleAlcohol1463.5 FemaleAlcohol19179&nbsp;&nbsp; FemaleAlcohol1831&nbsp;&nbsp; FemaleAlcohol18108&nbsp;&nbsp; 22.14 Wilcoxon test: A non-parametric test Code names(drugData) ## [1] &quot;Gender&quot; &quot;drug&quot; &quot;sundayBDI&quot; &quot;wedsBDI&quot; &quot;wedsRank&quot; Code head(drugData) (#tab:wilcoxon test) GenderdrugsundayBDIwedsBDIwedsRank MaleEcstasy152812 MaleEcstasy353517 MaleEcstasy163517 MaleEcstasy182410 MaleEcstasy193920 MaleEcstasy173215 Code sunModel&lt;-wilcox.test(sundayBDI ~ drug, data = drugData) sunModel ## ## Wilcoxon rank sum test with continuity correction ## ## data: sundayBDI by drug ## W = 64.5, p-value = 0.2861 ## alternative hypothesis: true location shift is not equal to 0 Code wedModel&lt;-wilcox.test(wedsBDI ~ drug, data = drugData) wedModel ## ## Wilcoxon rank sum test with continuity correction ## ## data: wedsBDI by drug ## W = 96, p-value = 0.000569 ## alternative hypothesis: true location shift is not equal to 0 22.15 the following approach is better because it can deal with ties (values that are equal) Code sunModel2&lt;-wilcox.test(sundayBDI ~ drug, data = drugData, exact = FALSE, correct= FALSE, conf.int=T) sunModel2 ## ## Wilcoxon rank sum test ## ## data: sundayBDI by drug ## W = 64.5, p-value = 0.2692 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## -1.000049 5.000033 ## sample estimates: ## difference in location ## 1.000023 Code wedModel2&lt;-wilcox.test(wedsBDI ~ drug, data = drugData, exact = FALSE, correct= FALSE, conf.int=T) wedModel2 ## ## Wilcoxon rank sum test ## ## data: wedsBDI by drug ## W = 96, p-value = 0.0004943 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## 18.00001 28.99996 ## sample estimates: ## difference in location ## 23.55281 22.16 Class Excercise 22.17 How many time have you gone to Disney, and is there a difference between genders? Use Wilcoxon Test Code Disney=c(3,5,0,1,2, 0,2,0,2,3, 2,1,4, 3, 2, 1, 2, 6,7, 11, 7, 9) Gender=c(&quot;F&quot;,&quot;F&quot;,&quot;F&quot;,&quot;F&quot;,&quot;F&quot;, &quot;F&quot;,&quot;F&quot;,&quot;F&quot;,&quot;F&quot;,&quot;F&quot;, &quot;F&quot;,&quot;F&quot;,&quot;F&quot;,&quot;F&quot;, &quot;M&quot;,&quot;M&quot;,&quot;M&quot;,&quot;M&quot;,&quot;M&quot;, &quot;M&quot;,&quot;M&quot;,&quot;M&quot;) DF=data.frame(Disney,Gender) DF Table 22.3: DisneyGender 3F 5F 0F 1F 2F 0F 2F 0F 2F 3F 2F 1F 4F 3F 2M 1M 2M 6M 7M 11M 7M 9M Code ggplot(DF, aes(y=Disney, x=Gender))+ geom_boxplot() Code ggplot(DF, aes(x=Disney, fill=Gender))+ geom_histogram()+ facet_grid(~Gender) Code wilcox.test(Disney ~ Gender, data = DF,exact = FALSE, correct= FALSE, conf.int=T ) ## ## Wilcoxon rank sum test ## ## data: Disney by Gender ## W = 24, p-value = 0.02681 ## alternative hypothesis: true location shift is not equal to 0 ## 95 percent confidence interval: ## -6.999942e+00 -2.032046e-05 ## sample estimates: ## difference in location ## -3.999936 22.18 Comparing two related conditions: the Wilcoxon signed-rank test (similar to paired t-test) 22.18.1 Do not confuse with the Wilcoxon rank-sum test (similar to unpaired t-test) We now want to compare the results from sunday and Wendsday, but now the data come from the same individuals. ## BDI = Becks depression index Change Code drugData$BDIchange&lt;-drugData$wedsBDI-drugData$sundayBDI # calculate differences drugData$BDIchange ## [1] 13 0 19 6 20 15 0 13 23 15 -11 -9 10 -7 -7 -6 -8 -2 -15 ## [20] -8 Code head(drugData) Table 22.4: GenderdrugsundayBDIwedsBDIwedsRankBDIchange MaleEcstasy15281213 MaleEcstasy3535170 MaleEcstasy16351719 MaleEcstasy1824106 MaleEcstasy19392020 MaleEcstasy17321515 Code drugData Table 22.4: GenderdrugsundayBDIwedsBDIwedsRankBDIchange MaleEcstasy152812&nbsp;&nbsp;13 MaleEcstasy353517&nbsp;&nbsp;0 MaleEcstasy163517&nbsp;&nbsp;19 MaleEcstasy182410&nbsp;&nbsp;6 MaleEcstasy193920&nbsp;&nbsp;20 MaleEcstasy173215&nbsp;&nbsp;15 MaleEcstasy272711&nbsp;&nbsp;0 MaleEcstasy162913&nbsp;&nbsp;13 MaleEcstasy133619&nbsp;&nbsp;23 MaleEcstasy203517&nbsp;&nbsp;15 FemaleAlcohol1652&nbsp;&nbsp;-11 FemaleAlcohol1563.5-9 FemaleAlcohol203014&nbsp;&nbsp;10 FemaleAlcohol1586&nbsp;&nbsp;-7 FemaleAlcohol1697&nbsp;&nbsp;-7 FemaleAlcohol1375&nbsp;&nbsp;-6 FemaleAlcohol1463.5-8 FemaleAlcohol19179&nbsp;&nbsp;-2 FemaleAlcohol1831&nbsp;&nbsp;-15 FemaleAlcohol18108&nbsp;&nbsp;-8 Code by(drugData$BDIchange, drugData$drug, stat.desc, basic = FALSE, norm = TRUE) ## drugData$drug: Ecstasy ## median mean SE.mean CI.mean.0.95 var std.dev ## 14.0000000 12.4000000 2.5307004 5.7248420 64.0444444 8.0027773 ## coef.var skewness skew.2SE kurtosis kurt.2SE normtest.W ## 0.6453853 -0.4140842 -0.3013525 -1.3686700 -0.5128991 0.9087803 ## normtest.p ## 0.2727175 ## ------------------------------------------------------------ ## drugData$drug: Alcohol ## median mean SE.mean CI.mean.0.95 var std.dev ## -7.50000000 -6.30000000 2.09788253 4.74573999 44.01111111 6.63408706 ## coef.var skewness skew.2SE kurtosis kurt.2SE normtest.W ## -1.05302969 1.23907117 0.90174219 0.98664006 0.36973617 0.82795980 ## normtest.p ## 0.03161929 Code boxplot&lt;-ggplot(drugData, aes(drug, BDIchange)) + geom_boxplot() boxplot Code alcoholData&lt;-subset(drugData, drug == &quot;Alcohol&quot;) # subset the data for alcohol ecstasyData&lt;-subset(drugData, drug == &quot;Ecstasy&quot;) # subset the data for ecstasy alcoholModel&lt;-wilcox.test(alcoholData$wedsBDI, alcoholData$sundayBDI, paired = TRUE, exact = TRUE, correct= FALSE) alcoholModel ## ## Wilcoxon signed rank test ## ## data: alcoholData$wedsBDI and alcoholData$sundayBDI ## V = 8, p-value = 0.04657 ## alternative hypothesis: true location shift is not equal to 0 Code ecstasyModel&lt;-wilcox.test(ecstasyData$wedsBDI, ecstasyData$sundayBDI, paired = TRUE, exact = FALSE,correct= FALSE) # Note that the option &quot;exact=FALSE&quot; has to be added becase there are ties. ecstasyModel ## ## Wilcoxon signed rank test ## ## data: ecstasyData$wedsBDI and ecstasyData$sundayBDI ## V = 36, p-value = 0.01151 ## alternative hypothesis: true location shift is not equal to 0 22.19 Krukall-Wallis Test This is a test similar to ANOVA, thus multiple groups, 3+ grupos However, you test for the differences in than rank among groups (not the mean). The null hypothesis is that the sum or mean rank in Ho: G1 = G2 = G3……Gk The alternative hypothesis is that at least one of the groups rank is different from another one. 22.20 Soya and the effect on sperm production in human males. 22.20.1 Soy food and isoflavone intake in relation to semen quality parameters among men from an infertility clinic Jorge E. Chavarro Thomas L. Toth Sonita M. Sadio Russ Hauser Hum Reprod. 2008 Nov;23(11):2584-90. doi: 10.1093/humrep/den243. Epub 2008 Jul 23. They found that the amount of sperm production is reduced in males which consume more soya 22.21 Abstract 22.21.1 BACKGROUND: High isoflavone intake has been related to decreased fertility in animal studies, but data in humans are scarce. Thus, we examined the association of soy foods and isoflavones intake with semen quality parameters. 22.21.2 METHODS: The intake of 15 soy-based foods in the previous 3 months was assessed for 99 male partners of subfertile couples who presented for semen analyses to the Massachusetts General Hospital Fertility Center. Linear and quantile regression were used to determine the association of soy foods and isoflavones intake with semen quality parameters while adjusting for personal characteristics. 22.21.3 RESULTS: There was an inverse association between soy food intake and sperm concentration that remained significant after accounting for age, abstinence time, body mass index, caffeine and alcohol intake and smoking. In the multivariate-adjusted analyses, men in the highest category of soy food intake had 41 million sperm/ml less than men who did not consume soy foods (95% confidence interval = -74, -8; P, trend = 0.02). Results for individual soy isoflavones were similar to the results for soy foods and were strongest for glycitein, but did not reach statistical significance. The inverse relation between soy food intake and sperm concentration was more pronounced in the high end of the distribution (90th and 75th percentile) and among overweight or obese men. Soy food and soy isoflavone intake were unrelated to sperm motility, sperm morphology or ejaculate volume. 22.21.4 CONCLUSIONS: These data suggest that higher intake of soy foods and soy isoflavones is associated with lower sperm concentration. Now let us look at the data from Field, soya.csv. Code library(readr) Soyadf &lt;- read_csv(&quot;Data_files_csv/Soya.csv&quot;) head(Soyadf) Table 22.5: SoyaSperm No Soya Meals0.35 No Soya Meals0.58 No Soya Meals0.88 No Soya Meals0.92 No Soya Meals1.22 No Soya Meals1.51 Code unique(Soyadf$Soya) ## [1] &quot;No Soya Meals&quot; &quot;1 Soya Meal Per Week&quot; &quot;4 Soyal Meals Per Week&quot; ## [4] &quot;7 Soya Meals Per Week&quot; 22.22 Hacer un boxplot de los datos en un nuevo chunk Code library(ggplot2) ggplot(Soyadf, aes(x=Soya, y=Sperm, fill=Soya))+ geom_boxplot()+ theme(axis.text.x = element_text(angle = 90)) Descriptive statistics When adding “norm=TRUE” will perform Shapiro_Wilks Normality test. Code library(pastecs) by(Soyadf$Sperm, Soyadf$Soya, stat.desc, basic = FALSE, norm = TRUE) ## Soyadf$Soya: 1 Soya Meal Per Week ## median mean SE.mean CI.mean.0.95 var std.dev ## 2.595000000 4.606000000 1.044821919 2.186837409 21.833056842 4.672585670 ## coef.var skewness skew.2SE kurtosis kurt.2SE normtest.W ## 1.014456290 1.350565932 1.318645901 1.422731699 0.716825470 0.825831600 ## normtest.p ## 0.002153894 ## ------------------------------------------------------------ ## Soyadf$Soya: 4 Soyal Meals Per Week ## median mean SE.mean CI.mean.0.95 var std.dev ## 2.945000e+00 4.110500e+00 9.861233e-01 2.063980e+00 1.944878e+01 4.410078e+00 ## coef.var skewness skew.2SE kurtosis kurt.2SE normtest.W ## 1.072881e+00 1.822237e+00 1.779169e+00 2.792615e+00 1.407024e+00 7.427433e-01 ## normtest.p ## 1.359072e-04 ## ------------------------------------------------------------ ## Soyadf$Soya: 7 Soya Meals Per Week ## median mean SE.mean CI.mean.0.95 var std.dev ## 1.3350000 1.6535000 0.2479774 0.5190226 1.2298555 1.1089885 ## coef.var skewness skew.2SE kurtosis kurt.2SE normtest.W ## 0.6706916 0.6086712 0.5942855 -0.9161653 -0.4615984 0.9122606 ## normtest.p ## 0.0703908 ## ------------------------------------------------------------ ## Soyadf$Soya: No Soya Meals ## median mean SE.mean CI.mean.0.95 var std.dev ## 3.095000000 4.987000000 1.136926165 2.379613812 25.852022105 5.084488382 ## coef.var skewness skew.2SE kurtosis kurt.2SE normtest.W ## 1.019548502 1.546140856 1.509598499 2.328051363 1.172959394 0.805255802 ## normtest.p ## 0.001035917 22.23 Kruskall Wallis test is similar to an ANOVA without assuming normal distribution or equality of variance. HO: R1=R2=R3=R4 HA: Por lo menos uno los grupos es diferente Code # Traditional approach kruskal.test(Sperm~as.factor(Soya), data=Soyadf) ## ## Kruskal-Wallis rank sum test ## ## data: Sperm by as.factor(Soya) ## Kruskal-Wallis chi-squared = 8.6589, df = 3, p-value = 0.03419 Code library(coin) #Approximative (Monte Carlo) Fisher-Pitman test modelkt=kruskal_test(Sperm~as.factor(Soya), data=Soyadf, distribution = approximate(nresample = 10000)) modelkt ## ## Approximative Kruskal-Wallis Test ## ## data: Sperm by ## as.factor(Soya) (1 Soya Meal Per Week, 4 Soyal Meals Per Week, 7 Soya Meals Per Week, No Soya Meals) ## chi-squared = 8.6589, p-value = 0.0306 Code #op &lt;- par(no.readonly = TRUE) # save current settings #layout(matrix(1:3, nrow = 3)) #s1 &lt;- support(modelkt); d1 &lt;- dperm(modelkt, s1) #plot(s1, d1, type = &quot;h&quot;, main = &quot;Mid-score: 0&quot;, # xlab = &quot;Test Statistic&quot;, ylab = &quot;Density&quot;) #pperm(modelkt, q=c(0.05, 0.5, 0.95)) #s=support(modelkt) #quantile(s, c(.025, 0.975)) Code Soyadf$Ranks=rank(Soyadf$Sperm) head(Soyadf) Table 22.6: SoyaSpermRanks No Soya Meals0.354 No Soya Meals0.589 No Soya Meals0.8817 No Soya Meals0.9218 No Soya Meals1.2222 No Soya Meals1.5130 Code by(Soyadf$Ranks, Soyadf$Soya, median) ## Soyadf$Soya: 1 Soya Meal Per Week ## [1] 43 ## ------------------------------------------------------------ ## Soyadf$Soya: 4 Soyal Meals Per Week ## [1] 48.5 ## ------------------------------------------------------------ ## Soyadf$Soya: 7 Soya Meals Per Week ## [1] 25.5 ## ------------------------------------------------------------ ## Soyadf$Soya: No Soya Meals ## [1] 50.5 Post Hoc TUKEY like test (Nemenyi test) The values shown are the p=values, the pair are significantly different if the p is below 0.05 22.23.1 Note dist=“Tukey”, correction for ties done Code library(PMCMRplus) kwAllPairsNemenyiTest(Sperm~as.factor(Soya) , data=Soyadf) ## 1 Soya Meal Per Week 4 Soyal Meals Per Week ## 4 Soyal Meals Per Week 1.000 - ## 7 Soya Meals Per Week 0.101 0.101 ## No Soya Meals 0.991 0.991 ## 7 Soya Meals Per Week ## 4 Soyal Meals Per Week - ## 7 Soya Meals Per Week - ## No Soya Meals 0.048 Code model1=kwAllPairsNemenyiTest(Sperm~as.factor(Soya) , data=Soyadf) # para más detalles summary(model1) ## q value Pr(&gt;|q|) ## 4 Soyal Meals Per Week - 1 Soya Meal Per Week == 0 0.000 1.000000 ## 7 Soya Meals Per Week - 1 Soya Meal Per Week == 0 3.233 0.101209 ## No Soya Meals - 1 Soya Meal Per Week == 0 0.423 0.990680 ## 7 Soya Meals Per Week - 4 Soyal Meals Per Week == 0 3.233 0.101209 ## No Soya Meals - 4 Soyal Meals Per Week == 0 0.423 0.990680 ## No Soya Meals - 7 Soya Meals Per Week == 0 3.657 0.047845 * Code # Try &quot;Chi Square&quot; = Chisq "],["cross.html", "Chapter 23 Cross-references 23.1 Chapters and sub-chapters 23.2 Captioned figures and tables", " Chapter 23 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. 23.1 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter ??. If you prefer text as the link instead of a numbered reference use: any text you want can go here. 23.2 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure 23.1. Code par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 23.1: Here is a nice figure! Don’t miss Table 23.1. Code knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 23.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 "],["footnotes-and-citations.html", "Chapter 24 Footnotes and citations 24.1 Footnotes 24.2 Citations 24.3 Links to websites", " Chapter 24 Footnotes and citations 24.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one 1. Let’s add a second footnote. In this case we add information on the origin of matrix algebra 2 Mi tercer footnote es filosofico 3 24.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2023) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. 24.2.0.1 Here is second citation. Evolutionary processes in orchids are likely to be a interaction between natural selection and genetic drift (Tremblay et al. 2005). 24.2.0.2 Here is a third citation un articulo de Damon excepcional (Damon 2000) 24.3 Links to websites The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations https://www.researchgate.net/profile/Raymond-Tremblay References "],["sharing-your-book.html", "Chapter 25 Sharing your book 25.1 Publishing 25.2 404 pages 25.3 Metadata for sharing", " Chapter 25 Sharing your book 25.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 25.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 25.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: Code ?bookdown::gitbook "],["references.html", "References", " References "],["ejercicios-a.html", "A Ejercicios A A.1 En esta actividad estarán comenzando a utilizar la plataforma R.", " A Ejercicios A A.1 En esta actividad estarán comenzando a utilizar la plataforma R. Recuerda que este libro esta disponible gratuitamente en el internet tanto en Español, https://es.r4ds.hadley.nz/index.html como en Ingles https://r4ds.had.co.nz/index.html. NOTA que si no tiene experiencia esto le va tomar tiempo. A.1.1 Primer paso Haber instalado R Haber Instalado RStudio Haber Instalado RMarkdown en Rstudio A.1.2 Segundo paso Seguir el Capitulo #1, y practicar instalar los paquetes “Packages”, por ejemplo el paquete de “tidyverse” Probar las funciones básica de suma, resta, división y multiplicación en R. "],["ejercicios-b.html", "B Ejercicios B B.1 Tarea para entregar, fecha limite el 24 de agosto a la media noche 11:59pm B.2 Segundo paso", " B Ejercicios B B.1 Tarea para entregar, fecha limite el 24 de agosto a la media noche 11:59pm En esta actividad seguirán utilizando la plataforma R para visualizar los datos. Ud someterá su trabajo como un documento .html y lo cargará a Edmodo. Recuerda que este libro esta disponible gratuitamente en el internet tanto en Español Español, https://es.r4ds.hadley.nz/index.html como en Ingles, https://r4ds.had.co.nz/index.html . En Edmodo ya le envie los enlaces. B.2 Segundo paso Del libro R4DS, leer y entender las secciones 3.4 HASTA 3.6.1. Reproducir la mayoría de las gráficas y someter el trabajo. B.2.1 Tercer Paso Leer el capitulo #2, entender lo que quiere decir cada uno de los términos en la figura. Por ejemplo que quiere decir modelos “model” en estadística? B.2.2 Cuarto Paso Abrir un documento nuevo de RMarkdown Quitar/remover lo que no es necesario Seguir los pasos hasta la sección 3.3 del libro r4ds y reproducir las gráficas como aparece en el libro y contestar las preguntas y hacer los ejercicios. "],["ejercicios-c.html", "C Ejercicios C C.1 Ejercicio de practica", " C Ejercicios C C.1 Ejercicio de practica Los siguientes ejercicios son para practicar el uso de R y RStudio. Se asume que Uds. practica lo siguiente. Tiene acceso a R y Rstudio, RMarkdown, el internet, libros. Después de hacer los ejercicios discuta tus resultados con otros estudiantes. Este ejercicio NO tiene puntuación. R Practica Usa R como una calculadora C.1.1 Ejercicio #1 Pon esta formula en R correctamente y calcula el resultado. \\(1+2(3+4)\\) C.1.2 Ejercicio #2 Pon esta fomula en R correctamente y calcula el resultado. \\(\\sqrt{(4+1)(2+1)}\\) C.1.3 Ejercicio #3 Re-esribir esta fomula en R correctamente y calcula el resultado. \\((2 + 3) * 4\\) C.1.4 Ejercicio #4 Calcular lo siguiente en R, enseña el codigo y el resultado \\[\\frac{0.25-2}{\\sqrt{(0.2(1-0.2)/100})}\\] C.1.5 Ejercicio #5 Asigna una variable a los valores del 2 hasta el 5. Después usando las variable multiplica todos los valores. C.1.6 Ejercicio #6 El data set rivers se sube con R. Escribe rivers en un chunk y determina cual es el ultimo valor del archivo y cual es su posición en la lista. C.1.7 Ejercicio #7 Instala y activa el paquete UsingR y evalúa los datos que se encuentra en el archivo/data frame exe.pay. Calcula cual es el promedio, mínimo y máximo de los datos usando las funciones mean, min y max. C.1.8 Ejercicio #8 El data set que se llama Orange es un data frame con tres variables. Como se llama las variables? C.1.9 Ejercicio #9 Calcula la edad promedia de los arboles de naranja que esta en el archivo Orange C.1.10 Ejercicio #10 Haz un gráfico de puntos entre la x=circunferencia del árbol y la y=edad, y añadele un color diferente a cada árbol. "],["ejercicios-d.html", "D Ejercicios D D.1 ANOVA exercices", " D Ejercicios D D.1 ANOVA exercices Code library(tidyverse) library(gt) library(Rmisc) library(multcomp) library(car) D.1.1 El estudiante entregará el trabajo en el formato de .html en MSTeam. Uds tuvieron su experiencia de como montar un documento en .Rmd y convertirlo en .html. (no se aceptará trabajo en Word). ES SUMAMENTE IMPORTANTE: que el trabajo sea bien organizado y profesional. Hará puntos extra por la presentación (10 puntos). - recuerda que NO se enseña todos los datos. D.1.2 Los datos se encuentrán en la pestaña del website debajo “Los Datos”, “Archivos de Datos”. El nombre del archivo se llama “Births In USA since 1933”; USAbirthbymonth.csv D.1.3 Human Mortality Database D.1.3.1 Reliability and Accuracy Matter The Human Mortality Database (HMD) is the world´s leading scientific data resource on mortality in developed countries. The HMD provides detailed high-quality harmonized mortality and population estimates to researchers, students, journalists, policy analysts, and others interested in the human longevity. The HMD follows open data principles. https://www.mortality.org/Home/Index Usando los datos de natalidad en estados unidos desde 1933 a 2020. En el archivo encontrarán tres columnas informativas, Year, Month y Births (total de nacimiento en este mes y año) Los datos estan en el website dabajo la pestaña de datos Archivos de datos. D.1.4 Aqui los primeras 6 filas del df #dgdqvqadci table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #dgdqvqadci thead, #dgdqvqadci tbody, #dgdqvqadci tfoot, #dgdqvqadci tr, #dgdqvqadci td, #dgdqvqadci th { border-style: none; } #dgdqvqadci p { margin: 0; padding: 0; } #dgdqvqadci .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dgdqvqadci .gt_caption { padding-top: 4px; padding-bottom: 4px; } #dgdqvqadci .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dgdqvqadci .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #dgdqvqadci .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dgdqvqadci .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dgdqvqadci .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dgdqvqadci .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dgdqvqadci .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dgdqvqadci .gt_column_spanner_outer:first-child { padding-left: 0; } #dgdqvqadci .gt_column_spanner_outer:last-child { padding-right: 0; } #dgdqvqadci .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dgdqvqadci .gt_spanner_row { border-bottom-style: hidden; } #dgdqvqadci .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #dgdqvqadci .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dgdqvqadci .gt_from_md > :first-child { margin-top: 0; } #dgdqvqadci .gt_from_md > :last-child { margin-bottom: 0; } #dgdqvqadci .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dgdqvqadci .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #dgdqvqadci .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #dgdqvqadci .gt_row_group_first td { border-top-width: 2px; } #dgdqvqadci .gt_row_group_first th { border-top-width: 2px; } #dgdqvqadci .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dgdqvqadci .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #dgdqvqadci .gt_first_summary_row.thick { border-top-width: 2px; } #dgdqvqadci .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dgdqvqadci .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dgdqvqadci .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dgdqvqadci .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #dgdqvqadci .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dgdqvqadci .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dgdqvqadci .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dgdqvqadci .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #dgdqvqadci .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dgdqvqadci .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #dgdqvqadci .gt_left { text-align: left; } #dgdqvqadci .gt_center { text-align: center; } #dgdqvqadci .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dgdqvqadci .gt_font_normal { font-weight: normal; } #dgdqvqadci .gt_font_bold { font-weight: bold; } #dgdqvqadci .gt_font_italic { font-style: italic; } #dgdqvqadci .gt_super { font-size: 65%; } #dgdqvqadci .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #dgdqvqadci .gt_asterisk { font-size: 100%; vertical-align: 0; } #dgdqvqadci .gt_indent_1 { text-indent: 5px; } #dgdqvqadci .gt_indent_2 { text-indent: 10px; } #dgdqvqadci .gt_indent_3 { text-indent: 15px; } #dgdqvqadci .gt_indent_4 { text-indent: 20px; } #dgdqvqadci .gt_indent_5 { text-indent: 25px; } PopName Year Month Births USA 1933 1 180545 USA 1934 1 182698 USA 1935 1 186051 USA 1936 1 182221 USA 1937 1 182232 USA 1938 1 194557 Cambiar los nombres de la variable de mes numérica a factor dando a las variables el nombre del mes que le corresponde. (5 pts) Haz un gráfico del promedio de nacimiento y la variación en natalidad por mes. (3 pts) Haz un gráfico del promedio y intervalo de 95% por mes (5 pts) Haz la prueba que corresponde para determinar si los grupos son iguales (8 pts). Cual es la hipótesis NULA? Cual es la hipótesis ALTERNA? Cual es el resultado de la prueba? Cual es el grado de libertad? Cuantos datos totales hay en el análisis? Evalúa los supuestos de esta prueba, explicando si acepta que los datos cumple con los supuestos (10 pts) Homogeneidad de Varianza Normalidad Explica claramente cada prueba y si interpretación Haz la prueba de Post-Hoc de Bonferroni y contesta la siguientes pregunta. (6 pts) Cual(es) es/son los mes(es) que la natalidad difiere de enero. Cual(es) es/son los mes(es) que la natalidad difiere de agosto. "],["ejercicios-e.html", "E Ejercicios E E.1 ANOVA Excercise 2", " E Ejercicios E E.1 ANOVA Excercise 2 E.1.1 Superheroes y Lesiones Los datos representa la gravedad de lesiones que tienen niños que se disfrazan de su superheroes favorito y después llegan a un hospital por alguna lesión. Los niños son categorizados con un nivel gravedad de lesión, más alto el valor más serio era la lesión. Los datos provienen de Field et al.  Subir los datos de Superhero.csv Code library(readr) Superhero &lt;- read_csv(&quot;Data_files_csv/Superhero.csv&quot;) head(Superhero) (#tab:data super heroes2) heroinjury 151 131 158 120 147 137 Code unique(Superhero$heronames) ## NULL Renombrar los nombres de las categorías para los tipos de Superheroes. En el archivo como están identificados las categorías de superheroes? Code #Superhero Superhero$heronames&lt;-factor(Superhero$hero, levels = c(1:4), labels = c(&quot;Spiderman&quot;,&quot;Superman&quot;, &quot;Hulk&quot;, &quot;Ninja Turtle&quot;)) Superhero (#tab:rename variables2) heroinjuryheronames 151Spiderman 131Spiderman 158Spiderman 120Spiderman 147Spiderman 137Spiderman 149Spiderman 140Spiderman 269Superman 232Superman 285Superman 266Superman 258Superman 252Superman 326Hulk 343Hulk 310Hulk 345Hulk 330Hulk 335Hulk 353Hulk 341Hulk 418Ninja Turtle 418Ninja Turtle 430Ninja Turtle 430Ninja Turtle 430Ninja Turtle 441Ninja Turtle 418Ninja Turtle 425Ninja Turtle Code names(Superhero) ## [1] &quot;hero&quot; &quot;injury&quot; &quot;heronames&quot; E.1.2 La preguntas Contestar cada una de las siguientes preguntas. Evaluar la distribución de los datos de respuestas (los en Y) Evaluar la homogeneidad de varianza Visualizar los datos Puntos y promedios y intervalo de confianza Hacer la prueba de ANOVA con aov() Evaluar la figura de residuales Evaluar la gráfica de qq, para la normalidad Hacer la prueba de post-hoc si es necesario!!!!! "],["ejercicios-f.html", "F Ejercicios F F.1 Ejercicio de Corelación:", " F Ejercicios F F.1 Ejercicio de Corelación: F.1.1 Despues de hacer los ejercicios habrá preguntas en MSTeam para contestar. Objetivos: Determinar si el estudiante puede evaluar si las variables tienen una distribución normal o no Basado en lo anterior seleccionar la prueba de correlación correspondiente Calcular el coeficiente de determinación Visualizar la correlación F.1.2 Los Datos The data were obtained from Andrews, D.F. and Herzberg, A.M. (1985) Data: A Collection of Problems from Many Fields for the Student and Research Worker. Springer-Verlag. Las variables en el archivo urine en el paquete boot r = Indicator of the presence of calcium oxalate crystals. gravity = The specific gravity of the urine. ph = The pH reading of the urine. osmo = The osmolarity of the urine. Osmolarity is proportional to the concentration of molecules in solution. cond = The conductivity of the urine. Conductivity is proportional to the concentration of charged ions in solution. urea = The urea concentration in millimoles per litre. calc = The calcium concentration in millimoles per litre. Code library(boot) head(urine) Table F.1: rgravityphosmocondureacalc 01.024.91725&nbsp;&nbsp;4432.45 01.025.7457720&nbsp;&nbsp;2964.49 01.017.2&nbsp;32114.91012.36 01.015.5140812.62242.15 01&nbsp;&nbsp;&nbsp;6.521877.5911.16 01.025.2766825.32523.34 Evaluar si las 6 variables (excluye la variable “r”) cumple con distribución normales. Usa dos de los métodos que hemos aprendido para evaluar cada variable si cumple con distribución normal. Explicar que prueba utilizas y interpretas los resultados. Usando el gráfico de qq-plot gráfica la correlación “menos normal” de las pruebas anteriores. Salva este gráfico en .png o .jpeg. Estimado de correlación entre las seis variables Tomando en cuenta lo que observaste en la pruebas anterior, selecciona la prueba correcta entre Pearson o Kendall, para evaluar la correlaciones entre las variables. Tiene que seleccionar la prueba correcta. Cual variables tienen una correlación mayor Cual variables tiene la correlación menor Coeficiente de determinación Calcula el coeficiente de determinación entre: calcium y urea ph y calc Cual de estos pares explica mejor la relación entre una variable y la otra (2 puntos) ¿Como se interpreta el coeficiente de determinación? Usa la funcción ggMarginal del paquete ggEXTRA Selecciona un par de variables de la correlación anterior: Prepare un gráfico para demostrar la correlación y su distribución usando ggMarginal. Interpretar el gráfico y compara con la prueba de normalidad que hiciste anteriormente salva el grafico en formato .jpeg o .png ¿Cual son los supuestos para usar la correlación de Pearson? "],["ejercicios-g.html", "G Ejercicios G G.1 Regresión Logística", " G Ejercicios G G.1 Regresión Logística Este ejercicio es para practicar como hacer una Regresión logística Los temas incluye. Construir un modelo de una regresión logística Determinar si los coeficientes son diferentes de cero Construir un gráfico de la relación logística usando ggplot2 Determinar los valores de probabilidades especifico para algunos valores “X” G.1.1 Karn and Penrose data Set G.1.2 Los Datos Los datos provienen de un estudio realizado por Mary N. Karn and L. S. Penrose publicado en Annals of Eugenics, titulado Birth Weight and gestation time in relation to maternal age, parity and infant survival publicado en 1951. Estaremos usando solamente una parte de los datos. El periodo de gestación y el peso de los bebés varones al nacer y su supervivencia (fallecio= 0 y sobrevivio= 1). Para facilitar el trabajo he modificado los datos un poco para cumplir con las tareas asignada. En el archivo “Karn_Penrose_infant_survivorship.csv” tiene datos sobre 7036 nacimientos entre los años 1935 y 1946. El archivo tiene 4 columnas: Line_number = la secuencia de los datos Gestation_Time_days = El periodo de gestación en días Weigth_lb = El peso del bebe en libras Surv_Index = “0” o “1” Code library(ggplot2) library(readr) Karn_Penrose_infant_survivorship &lt;- read_csv(&quot;Data_files_csv/Karn_Penrose_infant_survivorship.csv&quot;) KPdata=Karn_Penrose_infant_survivorship Pregunta: Explique en sus propias palabras cuales son las hipótesis que se pueden probar. Especificamente mencione si la hipótesis es una hipótesis nula o alterna. (4 puntos) Pregunta: Graficar la variable de respuesta (2 puntos) Pregunta: Grafique las variables explicativas Periodo de gestación (2 puntos) Peso de los varones al nacer (2 puntos) Evaluando la distribución de la variable de respuesta Pregunta: Usando la prueba correcta evalúa la relación entre la supervivencia y: periodo de gestación (2 puntos) peso de los varones al nacer (2 puntos) determina si los coeficientes son significativos de cada una de las pruebas y explica que quiere decir la prueba (4 puntos) Graficar la Relación entre la supervivencia y el peso de los bebes (2 puntos) Cual es la probabilidad de un bebe de 4 lbs sobrevivir (2 puntos) Cual es la probabilidad de un bebe de 7 lbs sobrevivir (2 puntos) Preguntar a su familia cual era el peso de nacer cuando Ud. nacio, calcula la probabilidad de sobrevivir (3 puntos) "],["ejercicios-h.html", "H Ejercicios H H.1 Bondad de Ajuste", " H Ejercicios H H.1 Bondad de Ajuste Code library(tidyverse) library(gt) library(gmodels) H.1.1 Encontrarán dos ejercicios de los análisis de Bondad de Ajuste. H.1.2 Ejercicio #1 H.1.3 Musaraña Un total de 125 individuals de un mamifero pequeño, musaraña fueron localizado dentro de una jaula, con la misma cantidad de 6 diferentes comida, la frequencia de que cada una de las musaraña selecionarón un tipo de comida esta en la tabla Photo from: https://www.laguiadelvaron.com/wp-content/uploads/2020/08/reaparece-musarana-elefante-www.laguiadelvaron-1.jpg Code musaraña=tribble( ~Tipo_comida, ~frecuencia, &quot;C1&quot;, 13, &quot;C2&quot;, 26, &quot;C3&quot;, 39, &quot;C4&quot;, 14, &quot;C5&quot;, 28 ) gt(musaraña) #kaallxmnzb table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #kaallxmnzb thead, #kaallxmnzb tbody, #kaallxmnzb tfoot, #kaallxmnzb tr, #kaallxmnzb td, #kaallxmnzb th { border-style: none; } #kaallxmnzb p { margin: 0; padding: 0; } #kaallxmnzb .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #kaallxmnzb .gt_caption { padding-top: 4px; padding-bottom: 4px; } #kaallxmnzb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #kaallxmnzb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #kaallxmnzb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kaallxmnzb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kaallxmnzb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #kaallxmnzb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #kaallxmnzb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #kaallxmnzb .gt_column_spanner_outer:first-child { padding-left: 0; } #kaallxmnzb .gt_column_spanner_outer:last-child { padding-right: 0; } #kaallxmnzb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #kaallxmnzb .gt_spanner_row { border-bottom-style: hidden; } #kaallxmnzb .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #kaallxmnzb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #kaallxmnzb .gt_from_md > :first-child { margin-top: 0; } #kaallxmnzb .gt_from_md > :last-child { margin-bottom: 0; } #kaallxmnzb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #kaallxmnzb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #kaallxmnzb .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #kaallxmnzb .gt_row_group_first td { border-top-width: 2px; } #kaallxmnzb .gt_row_group_first th { border-top-width: 2px; } #kaallxmnzb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kaallxmnzb .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #kaallxmnzb .gt_first_summary_row.thick { border-top-width: 2px; } #kaallxmnzb .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kaallxmnzb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #kaallxmnzb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #kaallxmnzb .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #kaallxmnzb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #kaallxmnzb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #kaallxmnzb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kaallxmnzb .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kaallxmnzb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #kaallxmnzb .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #kaallxmnzb .gt_left { text-align: left; } #kaallxmnzb .gt_center { text-align: center; } #kaallxmnzb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #kaallxmnzb .gt_font_normal { font-weight: normal; } #kaallxmnzb .gt_font_bold { font-weight: bold; } #kaallxmnzb .gt_font_italic { font-style: italic; } #kaallxmnzb .gt_super { font-size: 65%; } #kaallxmnzb .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #kaallxmnzb .gt_asterisk { font-size: 100%; vertical-align: 0; } #kaallxmnzb .gt_indent_1 { text-indent: 5px; } #kaallxmnzb .gt_indent_2 { text-indent: 10px; } #kaallxmnzb .gt_indent_3 { text-indent: 15px; } #kaallxmnzb .gt_indent_4 { text-indent: 20px; } #kaallxmnzb .gt_indent_5 { text-indent: 25px; } Tipo_comida frecuencia C1 13 C2 26 C3 39 C4 14 C5 28 Contesta las siguientes preguntas Cual es el (son) valor(es) esperado para cada grupo. Prueba si hay preferencia o no para una comida H.1.4 Ejercicio #1 H.1.5 Mofetas y rabia Los siguientes datos son las frecuencias de mofetas encontrada con rabia en dos diferentes región geográficas. ## _ ## platform x86_64-apple-darwin20 ## arch x86_64 ## os darwin20 ## system x86_64, darwin20 ## status ## major 4 ## minor 3.1 ## year 2023 ## month 06 ## day 16 ## svn rev 84548 ## language R ## version.string R version 4.3.1 (2023-06-16) ## nickname Beagle Scouts Photo from: https://www.britannica.com/animal/skunk Code mofetas=tribble( ~TRegion, ~con_rabia, ~sin_rabia, &quot;Region1&quot;, 14, 29, &quot;Region2&quot;, 12, 38 ) gt(mofetas) #oyxhisgick table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #oyxhisgick thead, #oyxhisgick tbody, #oyxhisgick tfoot, #oyxhisgick tr, #oyxhisgick td, #oyxhisgick th { border-style: none; } #oyxhisgick p { margin: 0; padding: 0; } #oyxhisgick .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #oyxhisgick .gt_caption { padding-top: 4px; padding-bottom: 4px; } #oyxhisgick .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #oyxhisgick .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #oyxhisgick .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oyxhisgick .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oyxhisgick .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oyxhisgick .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #oyxhisgick .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #oyxhisgick .gt_column_spanner_outer:first-child { padding-left: 0; } #oyxhisgick .gt_column_spanner_outer:last-child { padding-right: 0; } #oyxhisgick .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #oyxhisgick .gt_spanner_row { border-bottom-style: hidden; } #oyxhisgick .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #oyxhisgick .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #oyxhisgick .gt_from_md > :first-child { margin-top: 0; } #oyxhisgick .gt_from_md > :last-child { margin-bottom: 0; } #oyxhisgick .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #oyxhisgick .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #oyxhisgick .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #oyxhisgick .gt_row_group_first td { border-top-width: 2px; } #oyxhisgick .gt_row_group_first th { border-top-width: 2px; } #oyxhisgick .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oyxhisgick .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #oyxhisgick .gt_first_summary_row.thick { border-top-width: 2px; } #oyxhisgick .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oyxhisgick .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oyxhisgick .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #oyxhisgick .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #oyxhisgick .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #oyxhisgick .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oyxhisgick .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oyxhisgick .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #oyxhisgick .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oyxhisgick .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #oyxhisgick .gt_left { text-align: left; } #oyxhisgick .gt_center { text-align: center; } #oyxhisgick .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #oyxhisgick .gt_font_normal { font-weight: normal; } #oyxhisgick .gt_font_bold { font-weight: bold; } #oyxhisgick .gt_font_italic { font-style: italic; } #oyxhisgick .gt_super { font-size: 65%; } #oyxhisgick .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #oyxhisgick .gt_asterisk { font-size: 100%; vertical-align: 0; } #oyxhisgick .gt_indent_1 { text-indent: 5px; } #oyxhisgick .gt_indent_2 { text-indent: 10px; } #oyxhisgick .gt_indent_3 { text-indent: 15px; } #oyxhisgick .gt_indent_4 { text-indent: 20px; } #oyxhisgick .gt_indent_5 { text-indent: 25px; } TRegion con_rabia sin_rabia Region1 14 29 Region2 12 38 Cual es la hipótesis nula? Conprueba la hipótesis para determinar si tener rabia es igual en las dos regiones? Cual es el valor esperado de la mofetas sin rabia en la region 2? H.1.6 AHORA contesta las preguntas en MSTeam. Hay una fecha limite para la entrega de los ejercicios. "],["ejercicios-i.html", "I Ejercicios I I.1 Evaluación de distribución normal", " I Ejercicios I I.1 Evaluación de distribución normal Este documento tiene algunos ejercicios para evaluar si una distribución es normal. Los códigos (scripts) se encuentran en el archivo T8 La Distribución Normal. Tema: construir un histograma de los datos sobreponer una distribución teórica sobre el histograma evaluar si los datos tienen una distribución normal usando qqplot evaluar se los datos tienen una distribución normal usando la prueba de Shaipro_Wilks y Anderson-Darling I.1.1 Construir un histograma con los siguientes datos Usa el paquete ggversa, y el archivo SparrowsElphick y haga un histograma de los pesos (wt) de los pajaros capturados Foto de : https://birdcallsradio.com/episode-097-chris-elphick/ Code library(ggversa) gt(head(SparrowsElphick)) #qxbmogyhsh table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #qxbmogyhsh thead, #qxbmogyhsh tbody, #qxbmogyhsh tfoot, #qxbmogyhsh tr, #qxbmogyhsh td, #qxbmogyhsh th { border-style: none; } #qxbmogyhsh p { margin: 0; padding: 0; } #qxbmogyhsh .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qxbmogyhsh .gt_caption { padding-top: 4px; padding-bottom: 4px; } #qxbmogyhsh .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qxbmogyhsh .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #qxbmogyhsh .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qxbmogyhsh .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qxbmogyhsh .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qxbmogyhsh .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qxbmogyhsh .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qxbmogyhsh .gt_column_spanner_outer:first-child { padding-left: 0; } #qxbmogyhsh .gt_column_spanner_outer:last-child { padding-right: 0; } #qxbmogyhsh .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qxbmogyhsh .gt_spanner_row { border-bottom-style: hidden; } #qxbmogyhsh .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #qxbmogyhsh .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qxbmogyhsh .gt_from_md > :first-child { margin-top: 0; } #qxbmogyhsh .gt_from_md > :last-child { margin-bottom: 0; } #qxbmogyhsh .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qxbmogyhsh .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #qxbmogyhsh .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #qxbmogyhsh .gt_row_group_first td { border-top-width: 2px; } #qxbmogyhsh .gt_row_group_first th { border-top-width: 2px; } #qxbmogyhsh .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qxbmogyhsh .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #qxbmogyhsh .gt_first_summary_row.thick { border-top-width: 2px; } #qxbmogyhsh .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qxbmogyhsh .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qxbmogyhsh .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qxbmogyhsh .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #qxbmogyhsh .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qxbmogyhsh .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qxbmogyhsh .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qxbmogyhsh .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qxbmogyhsh .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qxbmogyhsh .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qxbmogyhsh .gt_left { text-align: left; } #qxbmogyhsh .gt_center { text-align: center; } #qxbmogyhsh .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qxbmogyhsh .gt_font_normal { font-weight: normal; } #qxbmogyhsh .gt_font_bold { font-weight: bold; } #qxbmogyhsh .gt_font_italic { font-style: italic; } #qxbmogyhsh .gt_super { font-size: 65%; } #qxbmogyhsh .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #qxbmogyhsh .gt_asterisk { font-size: 100%; vertical-align: 0; } #qxbmogyhsh .gt_indent_1 { text-indent: 5px; } #qxbmogyhsh .gt_indent_2 { text-indent: 10px; } #qxbmogyhsh .gt_indent_3 { text-indent: 15px; } #qxbmogyhsh .gt_indent_4 { text-indent: 20px; } #qxbmogyhsh .gt_indent_5 { text-indent: 25px; } wingcrd flatwing tarsus head culmen nalospi wt bandstat initials Year Month Day Location SpeciesCode Sex Age 59.0 60.0 22.3 31.2 12.3 13.0 9.5 1 2 2002 9 19 4 1 0 2 54.0 55.0 20.3 28.3 10.8 7.8 12.2 1 2 2002 10 4 4 3 0 2 53.0 54.0 21.6 30.2 12.5 8.5 13.8 1 2 2002 10 4 4 3 0 2 55.0 56.0 19.7 30.4 12.1 8.3 13.8 1 8 2002 7 30 9 1 0 2 55.0 56.0 20.3 28.7 11.2 8.0 14.1 1 3 2002 10 4 4 3 0 2 53.5 54.5 20.8 30.6 12.8 8.6 14.8 1 7 2004 8 2 1 1 0 2 I.1.2 Constuye un histograma de la distribución de los pesos de los pajaros. las lineas blancas alrededor de las barras que se cambio el nombre del eje de “x” que se cambio el nombre del eje de “y” Ahora a esta misma gráfica añádele la distribución normal teórica, el gráfico I.1.3 QQPLOT Ahora haz un gráfico de qqplot y determina si la distribución de los datos de peso de los finches tienen una distribución normal. I.1.4 Shapiro-Wilk test Haz la prueba de Shapiro-Wilks para determinar si la distribución de los datos son significativamente diferente de una distribución normal. Basado en los supuestos de esta prueba ¿Se debería utiliza la “Shapiro-Wilks” para evaluar la distribución normal. I.1.4.1 Lograste tener este resultado? I.1.5 Anderson-Darling Haz la prueba de Anderson-Darling para determinar si la distribución de los datos son significativamente diferente de una distribución normal. ¿La distribución de los pesos es significativamente diferente de una distribución normal? I.1.5.1 Lograste tener este resultado? "],["ejercicios-j.html", "J Ejercicios J J.1 Pruebas de una muestra", " J Ejercicios J J.1 Pruebas de una muestra Los siguientes ejercicios provienen de los conceptos aprendidos en “Pruebas de una muestra” ANTES de abrir el quiz en MSTeam haz todos los ejercicios aqui. Title: Ultrasound evaluation of the morphometric patterns of lymph nodes of the head and neck in young and middle-aged individuals. Ogassavara et al. 2016, 49:225-228, Radiologia Brasileira. doi: 10.1590/0100-3984.2015.0002. En este trabajo evaluaron los ganglios linfáticos de 20 individuos sanos. Encontraron que la media de los ganglios linfáticos mastoideos de los hombres era de 0,9 cm con una desviación estándar de 0,4 cm. ¿Cuál es el intervalo de confianza al 95% de los ganglios linfáticos mastoideos en hombres? . Usando los mismo datos de la pregunta #1. Title: Ultrasound evaluation of the morphometric patterns of lymph nodes of the head and neck in young and middle-aged individuals. Ogassavara et al. 2016, 49:225-228, Radiologia Brasileira. doi: 10.1590/0100-3984.2015.0002. En este trabajo evaluaron los ganglios linfáticos de 20 individuos sanos. Encontraron que la media de los ganglios linfáticos mastoideos de los hombres era de 0,9 cm con una desviación estándar de 0,4 cm. Ya se pudo medir el tamaño de los ganglios linfáticos mastoideos de TODOS los hombres del planeta, y se determino que que el promedio es de 0.7 cm con una desviación estándar de 0,2 cm. Usando los siguientes datos haga la prueba correspondiente en R para determinar el valor de t, observado y el valor critico. J.1.1 Ejercicio de práctica 1: Amigos de Facebook Mucha gente creen que la cantidad promedio de amigos en Facebook es 338 con una desviación estandard de 43.2. En un muestro al azar de 50 estudiantes universitarios en un pais se calculo que el promedio de estos estudiantes es de 350 amigos. Al nivel de 5% de error determina si hay evidencia que los estudiante tenga mayor numero de amigos que el promedio anunciado por Facebook Cual es valor de t Cual es el valor de t critico ¿Se rechaza o acepta la hipótesis nula? J.1.2 Ejercicio de práctica 2: Dias de enfermedades Un dueño de una impresa dice que su insiste que la cantidad de días promedio de enfermedades de sus empleados es menor que el promedio nacional de 10. Los datos de 40 empleados sigue. Determina si hay evidencia para creer el comentario del dueño de esta impresa. Code dias_E=tribble( ~dias_e, 0,6,12,3,3,5,4,1, 3,9,6,0,7,6,3,4, 7,4,7,1,0,8,12,3, 2,5,10,5,15,3,2,5, 3,11,8,2,2,4,1,9 ) dias_E Table J.1: dias_e 0 6 12 3 3 5 4 1 3 9 6 0 7 6 3 4 7 4 7 1 0 8 12 3 2 5 10 5 15 3 2 5 3 11 8 2 2 4 1 9 ¿Cual es la hipótesis nula? Cual es el valor de “t” Cual es le valor de “p” Aceptas o rechazas la hipótesis nula ¿Cual es el intervalo de confianza del número de días enfermo de estos trabajadores? "],["ejercicios-k.html", "K Ejercicios K K.1 prueba de t con datos pareados.", " K Ejercicios K K.1 prueba de t con datos pareados. K.1.1 El siguiente ejercicio es para una prueba corta donde tendrán que contestar en MSTeam. El tema es sobre la prueba de t con datos pareados. La prueba corta tiene los siguientes objetivos. Evalúa cada pregunta antes de abrir el documento en MSTeam (Tendrán un tiempo limitado el momento que abré MSTeam) Poder subir los datos a R Hacer la “prueba de t” Interpretar los resultados Subir una gráfico de los resultados a MSTeam Explicar cúal(es) es(son) el/los supuesto(s) de esta prueba Hacer una prueba para determinar si el/los supuesto(s) es/son validado(s) Escribir claramente la hipótesis nula Escribir claramente la hipótesis alterna Los datos provienen de una investigación donde se evaluó el impacto del huracán Georges son una pequeña orquídea endémica de Puerto Rico en el Yunque. La especies es Lepanthes eltoroensis y crece sobre árboles. Usa los datos del archivo “Lepanthes_eltoroensis_Georges_STUDENT.csv” - Los datos están en archivo atado tanto al email como en MSTeam. En el archivo encontrará datos sobre la cantidad de hojas que tiene cada planta. Los datos fueron recopilado por 6 años a cada dos meses. El primer muestreo fue la columna T1, y el último muestreo T12 (despues de 6 años). El primer muestreo fue después del huracán Georges. Usando estas dos columnas evalúa si las plantas tenían la misma cantidad de hojas al principio y al final de 6 años. Code library(readr) Lepanthes_eltoroensis_Georges_STUDENT &lt;- read_csv(&quot;Data_files_csv/Lepanthes_eltoroensis_Georges_STUDENT.csv&quot;) Lep=Lepanthes_eltoroensis_Georges_STUDENT K.1.2 1. Calcula el promedio y la desviación estandard del número de hoja en cada tiempo. K.1.3 2. Haz la prueba de t-con datos pareados K.1.4 3. Haz un gráficos “histograma” de las diferencias entre el tiempo T12 y T1. Para salvar el gráfico usa ggsave(“nombre_de_tu_grafico.png”). Para subir lo a MSTeam. Ahora su gráfico sera salvado en su proyecto con el nombre que le dio. K.1.5 4. Determina si la prueba cumple con el/los supuesto(s) de una prueba de t con datos pareados? "],["ejercicios-sobre-prueba-de-t-con-datos-independiente.html", "L Ejercicios sobre prueba de t con datos independiente L.1 El siguiente ejercicio es para una prueba corta donde tendrán que contestar en MSTeam.", " L Ejercicios sobre prueba de t con datos independiente L.1 El siguiente ejercicio es para una prueba corta donde tendrán que contestar en MSTeam. El tema es sobre la prueba de t con datos independiente. La prueba corta tiene los siguientes objetivos. Evalúa cada pregunta antes de abrir el documento en MSTeam (Tendrán un tiempo limitado el momento que abré MSTeam) Los datos son de pacientes que tienen Esclorosis muscular (MS). A cada uno de estos pacientes se evaluó los niveles de IgG, un indicador de anticuerpo. Información básica sobre el anticuerpo, tambien conocido como Immunoglobin. L.1.1 Tabla de que es IgG y algunos de sus causas Table L.1: IgQue esPosible cause cuando es bajoPosible cause cuando es alto IgGMajor type of antibody found in the blood that can enter tissues and fight infection. In its four forms, provides the majority of antibody-based immunity against invading pathogens. The only antibody capable of crossing the placenta to give passive immunity to the fetus.Low levels occur in Waldenstrom's macroglobulinemia, where high levels of IgM antibodies may inhibit the growth of B-cells that make IgG. Other conditions that cause low levels include some types of leukemia and a type of kidney damage (nephrotic syndrome). In rare cases, some people are born with a lack of IgG antibodies. These people are more likely to develop infections.May mean a long-term (chronic) infection, such as AIDS, is present. Levels of IgG are higher in IgG MGUS, IgG multiple myeloma, long-term hepatitis, and multiple sclerosis (MS). In multiple myeloma, tumor cells make only one type of IgG antibody (monoclonal); the other conditions cause an increase in many types of IgG antibodies (polyclonal). La prueba corta tiene los siguientes objetivos. Evalúa cada pregunta antes de abrir el documento en MSTeam (Tendrán un tiempo limitado el momento que abré MSTeam) Poder subir los datos a R Hacer la “prueba de t” que corresponde Interpretar los resultados Subir una gráfico de los resultados a MSTeam Explicar cúal(es) es(son) el/los supuesto(s) de esta prueba Hacer una prueba para determinar si el/los supuesto(s) es/son validado(s) Escribir claramente la hipótesis nula Escribir claramente la hipótesis alterna ¿Cuales son las hipótesis de los supuestos? Los datos Code library(readxl) Immuno_markers_MS &lt;- read_excel(&quot;Data_files_csv/Immuno_markers_MS.xlsx&quot;) Imm=Immuno_markers_MS En este archivo tiene tres columnas. El sexo del paciente, “F” o “M”. Un indice de los IgG, en una mustra de cada paciente con MS Un indice de IgG synthesis rate : The reference interval is –9.9 to +3.3 mg per day. Negative values are considered normal. Multiple sclerosis patients usually have a synthesis rate &gt;8.0. L.1.2 1. Calcular el promedio y desviación estandard y el tamaño de muestra de los dos grupos del nivel de IgG L.1.3 2. Hacer la prueba para evaluar si las mujeres y hombres tienen un IgG diferente L.1.4 3. Haz un histograma de la variable “IgG” por genero, a) un color diferente por “Gender” Para salvar el gráfico usa ggsave(“nombre_de_tu_grafico.png”). Para subir lo a MSTeam. Ahora su gráfico sera salvado en su proyecto con el nombre que le dio. L.1.5 4. Determina si la prueba cumple con el/los supuesto(s) de una prueba de t con datos independientes? "],["ejercicios-m.html", "M Ejercicios M M.1 Ejercicio de Regresión", " M Ejercicios M M.1 Ejercicio de Regresión M.1.1 Fungal growth Fungal growth from soil samples were cultured in the presence of different concentrations of Cadnium (in µM). The density of fungal growth (x 10^6/ml) in each of the cultures was determined after a period of incubation. Para conocer más sobre estas interacciones vea el siguiente enlace. https://bmcmicrobiol.biomedcentral.com/articles/10.1186/s12866-022-02488-z Code DATA=tribble(~Cadnium, ~Fungal_Growth, 0, 6.6, 0, 6.9, 0, 7.2, 1, 6.8, 1, 6.0, 1, 5.6, 2, 6.4, 2, 6.0, 2, 5.4, 4, 4.8, 4, 4.4, 4, 3.9, 6, 2.6, 6, 3.1, 6, 3.4, 8, 1.0, 8, 1.3, 8, 1.7, 10, 0.2, 10, 0.3, 10, 0.5) DATA Table M.1: CadniumFungal_Growth 06.6 06.9 07.2 16.8 16&nbsp;&nbsp; 15.6 26.4 26&nbsp;&nbsp; 25.4 44.8 44.4 43.9 62.6 63.1 63.4 81&nbsp;&nbsp; 81.3 81.7 100.2 100.3 100.5 Haz un gráfico de la relación entre la concentración de Cadnium y el crecimiento de hongos Añade la mejor linea ( la regresión lineal) Tenga el gráfico listo para subir a MSTeam Evalúa el modelo de la regresión lineal Se acepta o rechaza LAS hipótesis Evalúa los supuestos de esta prueba. M.1.2 Contesta las preguntas en MSTeam M.1.3 Distancia de las estrellas más brillantes de las que son 100 años luz o menos M.1.4 Calcular el promedio, mediana, moda y rango de los datos de las estrellas más cercana a la tierra Code Distancia_Estrellas=tribble( ~Distancia, 8.6,36.7,42.2,16.8,33.7,87.9,4.4,25.3,11.4,25.1,51.5 ) gt(Distancia_Estrellas) #oimymtwtmm table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #oimymtwtmm thead, #oimymtwtmm tbody, #oimymtwtmm tfoot, #oimymtwtmm tr, #oimymtwtmm td, #oimymtwtmm th { border-style: none; } #oimymtwtmm p { margin: 0; padding: 0; } #oimymtwtmm .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #oimymtwtmm .gt_caption { padding-top: 4px; padding-bottom: 4px; } #oimymtwtmm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #oimymtwtmm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #oimymtwtmm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oimymtwtmm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oimymtwtmm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #oimymtwtmm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #oimymtwtmm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #oimymtwtmm .gt_column_spanner_outer:first-child { padding-left: 0; } #oimymtwtmm .gt_column_spanner_outer:last-child { padding-right: 0; } #oimymtwtmm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #oimymtwtmm .gt_spanner_row { border-bottom-style: hidden; } #oimymtwtmm .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #oimymtwtmm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #oimymtwtmm .gt_from_md > :first-child { margin-top: 0; } #oimymtwtmm .gt_from_md > :last-child { margin-bottom: 0; } #oimymtwtmm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #oimymtwtmm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #oimymtwtmm .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #oimymtwtmm .gt_row_group_first td { border-top-width: 2px; } #oimymtwtmm .gt_row_group_first th { border-top-width: 2px; } #oimymtwtmm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oimymtwtmm .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #oimymtwtmm .gt_first_summary_row.thick { border-top-width: 2px; } #oimymtwtmm .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oimymtwtmm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #oimymtwtmm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #oimymtwtmm .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #oimymtwtmm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #oimymtwtmm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #oimymtwtmm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oimymtwtmm .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #oimymtwtmm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #oimymtwtmm .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #oimymtwtmm .gt_left { text-align: left; } #oimymtwtmm .gt_center { text-align: center; } #oimymtwtmm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #oimymtwtmm .gt_font_normal { font-weight: normal; } #oimymtwtmm .gt_font_bold { font-weight: bold; } #oimymtwtmm .gt_font_italic { font-style: italic; } #oimymtwtmm .gt_super { font-size: 65%; } #oimymtwtmm .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #oimymtwtmm .gt_asterisk { font-size: 100%; vertical-align: 0; } #oimymtwtmm .gt_indent_1 { text-indent: 5px; } #oimymtwtmm .gt_indent_2 { text-indent: 10px; } #oimymtwtmm .gt_indent_3 { text-indent: 15px; } #oimymtwtmm .gt_indent_4 { text-indent: 20px; } #oimymtwtmm .gt_indent_5 { text-indent: 25px; } Distancia 8.6 36.7 42.2 16.8 33.7 87.9 4.4 25.3 11.4 25.1 51.5 M.1.5 Los datos representan las poblaciones (en 1’000) en Puerto Rico en el año 2020 M.1.5.1 Calular los cuantiles mencionado en la pregunta Code PR_poblacion=tribble( ~Poblacion, 18.0, 38.1,55.1,24.2,24.6,25.6,87.7,15.8,22.7,28.9,185.2,47.1,127.2 ) gt(PR_poblacion) #mxhpatzpmn table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #mxhpatzpmn thead, #mxhpatzpmn tbody, #mxhpatzpmn tfoot, #mxhpatzpmn tr, #mxhpatzpmn td, #mxhpatzpmn th { border-style: none; } #mxhpatzpmn p { margin: 0; padding: 0; } #mxhpatzpmn .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mxhpatzpmn .gt_caption { padding-top: 4px; padding-bottom: 4px; } #mxhpatzpmn .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mxhpatzpmn .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mxhpatzpmn .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mxhpatzpmn .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mxhpatzpmn .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mxhpatzpmn .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mxhpatzpmn .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mxhpatzpmn .gt_column_spanner_outer:first-child { padding-left: 0; } #mxhpatzpmn .gt_column_spanner_outer:last-child { padding-right: 0; } #mxhpatzpmn .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mxhpatzpmn .gt_spanner_row { border-bottom-style: hidden; } #mxhpatzpmn .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #mxhpatzpmn .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mxhpatzpmn .gt_from_md > :first-child { margin-top: 0; } #mxhpatzpmn .gt_from_md > :last-child { margin-bottom: 0; } #mxhpatzpmn .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mxhpatzpmn .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mxhpatzpmn .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mxhpatzpmn .gt_row_group_first td { border-top-width: 2px; } #mxhpatzpmn .gt_row_group_first th { border-top-width: 2px; } #mxhpatzpmn .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mxhpatzpmn .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mxhpatzpmn .gt_first_summary_row.thick { border-top-width: 2px; } #mxhpatzpmn .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mxhpatzpmn .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mxhpatzpmn .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mxhpatzpmn .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #mxhpatzpmn .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mxhpatzpmn .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mxhpatzpmn .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mxhpatzpmn .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mxhpatzpmn .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mxhpatzpmn .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mxhpatzpmn .gt_left { text-align: left; } #mxhpatzpmn .gt_center { text-align: center; } #mxhpatzpmn .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mxhpatzpmn .gt_font_normal { font-weight: normal; } #mxhpatzpmn .gt_font_bold { font-weight: bold; } #mxhpatzpmn .gt_font_italic { font-style: italic; } #mxhpatzpmn .gt_super { font-size: 65%; } #mxhpatzpmn .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #mxhpatzpmn .gt_asterisk { font-size: 100%; vertical-align: 0; } #mxhpatzpmn .gt_indent_1 { text-indent: 5px; } #mxhpatzpmn .gt_indent_2 { text-indent: 10px; } #mxhpatzpmn .gt_indent_3 { text-indent: 15px; } #mxhpatzpmn .gt_indent_4 { text-indent: 20px; } #mxhpatzpmn .gt_indent_5 { text-indent: 25px; } Poblacion 18.0 38.1 55.1 24.2 24.6 25.6 87.7 15.8 22.7 28.9 185.2 47.1 127.2 "],["ejercicios-n.html", "N Ejercicios N N.1 Ejercicios de tendencia central", " N Ejercicios N N.1 Ejercicios de tendencia central N.1.1 Los datos representan la cantidad de dinero ganado por arttistas (fallecidos) en milliones de dollares N.1.1.1 Calcular el promedio, mediana, moda de los datos de las estrellas más cercana a la tierra Code Dinero_Artista=tribble( ~Artista, ~Dinero, &quot;Kurt Corbain&quot;, 50, &quot;Elvis Presley&quot;,42, &quot;Charles Chultz&quot;, 35, &quot;John Lennon&quot;, 24, &quot;Ray Charles&quot;, 10, &quot;Marilyn Monroe&quot;,8, &quot;Johny Cash&quot;,8, &quot;J.R.R. Tolkein&quot;, 7, &quot;George Harrison&quot;, 7, &quot;Bob Marley&quot;,7, &quot;Albert Einstein&quot; ,20, &quot;And Wharhol&quot;,19 ) gt(Dinero_Artista) #vaqqvburiz table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #vaqqvburiz thead, #vaqqvburiz tbody, #vaqqvburiz tfoot, #vaqqvburiz tr, #vaqqvburiz td, #vaqqvburiz th { border-style: none; } #vaqqvburiz p { margin: 0; padding: 0; } #vaqqvburiz .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #vaqqvburiz .gt_caption { padding-top: 4px; padding-bottom: 4px; } #vaqqvburiz .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #vaqqvburiz .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #vaqqvburiz .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vaqqvburiz .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vaqqvburiz .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vaqqvburiz .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #vaqqvburiz .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #vaqqvburiz .gt_column_spanner_outer:first-child { padding-left: 0; } #vaqqvburiz .gt_column_spanner_outer:last-child { padding-right: 0; } #vaqqvburiz .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #vaqqvburiz .gt_spanner_row { border-bottom-style: hidden; } #vaqqvburiz .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #vaqqvburiz .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #vaqqvburiz .gt_from_md > :first-child { margin-top: 0; } #vaqqvburiz .gt_from_md > :last-child { margin-bottom: 0; } #vaqqvburiz .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #vaqqvburiz .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #vaqqvburiz .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #vaqqvburiz .gt_row_group_first td { border-top-width: 2px; } #vaqqvburiz .gt_row_group_first th { border-top-width: 2px; } #vaqqvburiz .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vaqqvburiz .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #vaqqvburiz .gt_first_summary_row.thick { border-top-width: 2px; } #vaqqvburiz .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vaqqvburiz .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vaqqvburiz .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #vaqqvburiz .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #vaqqvburiz .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #vaqqvburiz .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vaqqvburiz .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vaqqvburiz .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #vaqqvburiz .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vaqqvburiz .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #vaqqvburiz .gt_left { text-align: left; } #vaqqvburiz .gt_center { text-align: center; } #vaqqvburiz .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #vaqqvburiz .gt_font_normal { font-weight: normal; } #vaqqvburiz .gt_font_bold { font-weight: bold; } #vaqqvburiz .gt_font_italic { font-style: italic; } #vaqqvburiz .gt_super { font-size: 65%; } #vaqqvburiz .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #vaqqvburiz .gt_asterisk { font-size: 100%; vertical-align: 0; } #vaqqvburiz .gt_indent_1 { text-indent: 5px; } #vaqqvburiz .gt_indent_2 { text-indent: 10px; } #vaqqvburiz .gt_indent_3 { text-indent: 15px; } #vaqqvburiz .gt_indent_4 { text-indent: 20px; } #vaqqvburiz .gt_indent_5 { text-indent: 25px; } Artista Dinero Kurt Corbain 50 Elvis Presley 42 Charles Chultz 35 John Lennon 24 Ray Charles 10 Marilyn Monroe 8 Johny Cash 8 J.R.R. Tolkein 7 George Harrison 7 Bob Marley 7 Albert Einstein 20 And Wharhol 19 N.1.2 La catidad de personas fallecidos en acidentes de carro en año especifico en los 50 estados. N.1.3 Calcular el rango, varianza, desviación estandard y error estandard N.1.4 Haz un histograma de estos datos Code Fallecidos_Carro=tribble( ~Fallecidos, 778,309,1110,324,705,1067,826,76,205,152,218,492, 65,186,712,193,262,452,875,82, 730,1185,2707,1279,390,305,123,948,343,602, 69,451,951,104,985,155,450,2080,565,875, 414,981,2786,82,793,214,130,396,620,797 ) gt(Fallecidos_Carro) #klznqtwvmr table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #klznqtwvmr thead, #klznqtwvmr tbody, #klznqtwvmr tfoot, #klznqtwvmr tr, #klznqtwvmr td, #klznqtwvmr th { border-style: none; } #klznqtwvmr p { margin: 0; padding: 0; } #klznqtwvmr .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #klznqtwvmr .gt_caption { padding-top: 4px; padding-bottom: 4px; } #klznqtwvmr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #klznqtwvmr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #klznqtwvmr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #klznqtwvmr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #klznqtwvmr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #klznqtwvmr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #klznqtwvmr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #klznqtwvmr .gt_column_spanner_outer:first-child { padding-left: 0; } #klznqtwvmr .gt_column_spanner_outer:last-child { padding-right: 0; } #klznqtwvmr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #klznqtwvmr .gt_spanner_row { border-bottom-style: hidden; } #klznqtwvmr .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #klznqtwvmr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #klznqtwvmr .gt_from_md > :first-child { margin-top: 0; } #klznqtwvmr .gt_from_md > :last-child { margin-bottom: 0; } #klznqtwvmr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #klznqtwvmr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #klznqtwvmr .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #klznqtwvmr .gt_row_group_first td { border-top-width: 2px; } #klznqtwvmr .gt_row_group_first th { border-top-width: 2px; } #klznqtwvmr .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #klznqtwvmr .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #klznqtwvmr .gt_first_summary_row.thick { border-top-width: 2px; } #klznqtwvmr .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #klznqtwvmr .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #klznqtwvmr .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #klznqtwvmr .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #klznqtwvmr .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #klznqtwvmr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #klznqtwvmr .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #klznqtwvmr .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #klznqtwvmr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #klznqtwvmr .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #klznqtwvmr .gt_left { text-align: left; } #klznqtwvmr .gt_center { text-align: center; } #klznqtwvmr .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #klznqtwvmr .gt_font_normal { font-weight: normal; } #klznqtwvmr .gt_font_bold { font-weight: bold; } #klznqtwvmr .gt_font_italic { font-style: italic; } #klznqtwvmr .gt_super { font-size: 65%; } #klznqtwvmr .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #klznqtwvmr .gt_asterisk { font-size: 100%; vertical-align: 0; } #klznqtwvmr .gt_indent_1 { text-indent: 5px; } #klznqtwvmr .gt_indent_2 { text-indent: 10px; } #klznqtwvmr .gt_indent_3 { text-indent: 15px; } #klznqtwvmr .gt_indent_4 { text-indent: 20px; } #klznqtwvmr .gt_indent_5 { text-indent: 25px; } Fallecidos 778 309 1110 324 705 1067 826 76 205 152 218 492 65 186 712 193 262 452 875 82 730 1185 2707 1279 390 305 123 948 343 602 69 451 951 104 985 155 450 2080 565 875 414 981 2786 82 793 214 130 396 620 797 "],["ejercicio-o.html", "O Ejercicio O O.1 Ejercicios de dispersión", " O Ejercicio O O.1 Ejercicios de dispersión Code library(gt) library(tidyverse) O.1.1 Buscar la metadata Code codes&lt;-read.csv(&#39;https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-codebook.csv&#39;) O.1.2 Visualizar la meta data Code gt(codes) #nvxyusxmye table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #nvxyusxmye thead, #nvxyusxmye tbody, #nvxyusxmye tfoot, #nvxyusxmye tr, #nvxyusxmye td, #nvxyusxmye th { border-style: none; } #nvxyusxmye p { margin: 0; padding: 0; } #nvxyusxmye .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #nvxyusxmye .gt_caption { padding-top: 4px; padding-bottom: 4px; } #nvxyusxmye .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #nvxyusxmye .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #nvxyusxmye .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nvxyusxmye .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nvxyusxmye .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #nvxyusxmye .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #nvxyusxmye .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #nvxyusxmye .gt_column_spanner_outer:first-child { padding-left: 0; } #nvxyusxmye .gt_column_spanner_outer:last-child { padding-right: 0; } #nvxyusxmye .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #nvxyusxmye .gt_spanner_row { border-bottom-style: hidden; } #nvxyusxmye .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #nvxyusxmye .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #nvxyusxmye .gt_from_md > :first-child { margin-top: 0; } #nvxyusxmye .gt_from_md > :last-child { margin-bottom: 0; } #nvxyusxmye .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #nvxyusxmye .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #nvxyusxmye .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #nvxyusxmye .gt_row_group_first td { border-top-width: 2px; } #nvxyusxmye .gt_row_group_first th { border-top-width: 2px; } #nvxyusxmye .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nvxyusxmye .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #nvxyusxmye .gt_first_summary_row.thick { border-top-width: 2px; } #nvxyusxmye .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nvxyusxmye .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #nvxyusxmye .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #nvxyusxmye .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #nvxyusxmye .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #nvxyusxmye .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #nvxyusxmye .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nvxyusxmye .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nvxyusxmye .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #nvxyusxmye .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #nvxyusxmye .gt_left { text-align: left; } #nvxyusxmye .gt_center { text-align: center; } #nvxyusxmye .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #nvxyusxmye .gt_font_normal { font-weight: normal; } #nvxyusxmye .gt_font_bold { font-weight: bold; } #nvxyusxmye .gt_font_italic { font-style: italic; } #nvxyusxmye .gt_super { font-size: 65%; } #nvxyusxmye .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #nvxyusxmye .gt_asterisk { font-size: 100%; vertical-align: 0; } #nvxyusxmye .gt_indent_1 { text-indent: 5px; } #nvxyusxmye .gt_indent_2 { text-indent: 10px; } #nvxyusxmye .gt_indent_3 { text-indent: 15px; } #nvxyusxmye .gt_indent_4 { text-indent: 20px; } #nvxyusxmye .gt_indent_5 { text-indent: 25px; } column source category description iso_code International Organization for Standardization Others ISO 3166-1 alpha-3 – three-letter country codes. Note that OWID-defined regions (e.g. continents like 'Europe') contain prefix 'OWID_'. continent Our World in Data Others Continent of the geographical location location Our World in Data Others Geographical location date Our World in Data Others Date of observation total_cases COVID-19 Dashboard by the WHO Confirmed cases Total confirmed cases of COVID-19. Counts can include probable cases, where reported. new_cases COVID-19 Dashboard by the WHO Confirmed cases New confirmed cases of COVID-19. Counts can include probable cases, where reported. In rare cases where our source reports a negative daily change due to a data correction, we set this metric to NA. new_cases_smoothed COVID-19 Dashboard by the WHO Confirmed cases New confirmed cases of COVID-19 (7-day smoothed). Counts can include probable cases, where reported. total_deaths COVID-19 Dashboard by the WHO Confirmed deaths Total deaths attributed to COVID-19. Counts can include probable deaths, where reported. new_deaths COVID-19 Dashboard by the WHO Confirmed deaths New deaths attributed to COVID-19. Counts can include probable deaths, where reported. In rare cases where our source reports a negative daily change due to a data correction, we set this metric to NA. new_deaths_smoothed COVID-19 Dashboard by the WHO Confirmed deaths New deaths attributed to COVID-19 (7-day smoothed). Counts can include probable deaths, where reported. total_cases_per_million COVID-19 Dashboard by the WHO Confirmed cases Total confirmed cases of COVID-19 per 1,000,000 people. Counts can include probable cases, where reported. new_cases_per_million COVID-19 Dashboard by the WHO Confirmed cases New confirmed cases of COVID-19 per 1,000,000 people. Counts can include probable cases, where reported. new_cases_smoothed_per_million COVID-19 Dashboard by the WHO Confirmed cases New confirmed cases of COVID-19 (7-day smoothed) per 1,000,000 people. Counts can include probable cases, where reported. total_deaths_per_million COVID-19 Dashboard by the WHO Confirmed deaths Total deaths attributed to COVID-19 per 1,000,000 people. Counts can include probable deaths, where reported. new_deaths_per_million COVID-19 Dashboard by the WHO Confirmed deaths New deaths attributed to COVID-19 per 1,000,000 people. Counts can include probable deaths, where reported. new_deaths_smoothed_per_million COVID-19 Dashboard by the WHO Confirmed deaths New deaths attributed to COVID-19 (7-day smoothed) per 1,000,000 people. Counts can include probable deaths, where reported. reproduction_rate Arroyo Marioli et al. (2020). https://doi.org/10.2139/ssrn.3581633 Reproduction rate Real-time estimate of the effective reproduction rate (R) of COVID-19. See https://github.com/crondonm/TrackingR/tree/main/Estimates-Database icu_patients National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients in intensive care units (ICUs) on a given day icu_patients_per_million National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients in intensive care units (ICUs) on a given day per 1,000,000 people hosp_patients National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients in hospital on a given day hosp_patients_per_million National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients in hospital on a given day per 1,000,000 people weekly_icu_admissions National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients newly admitted to intensive care units (ICUs) in a given week (reporting date and the preceeding 6 days) weekly_icu_admissions_per_million National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients newly admitted to intensive care units (ICUs) in a given week per 1,000,000 people (reporting date and the preceeding 6 days) weekly_hosp_admissions National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients newly admitted to hospitals in a given week (reporting date and the preceeding 6 days) weekly_hosp_admissions_per_million National government reports and European CDC Hospital &amp; ICU Number of COVID-19 patients newly admitted to hospitals in a given week per 1,000,000 people (reporting date and the preceeding 6 days) total_tests National government reports Tests &amp; positivity Total tests for COVID-19 new_tests National government reports Tests &amp; positivity New tests for COVID-19 (only calculated for consecutive days) total_tests_per_thousand National government reports Tests &amp; positivity Total tests for COVID-19 per 1,000 people new_tests_per_thousand National government reports Tests &amp; positivity New tests for COVID-19 per 1,000 people new_tests_smoothed National government reports Tests &amp; positivity New tests for COVID-19 (7-day smoothed). For countries that don't report testing data on a daily basis, we assume that testing changed equally on a daily basis over any periods in which no data was reported. This produces a complete series of daily figures, which is then averaged over a rolling 7-day window new_tests_smoothed_per_thousand National government reports Tests &amp; positivity New tests for COVID-19 (7-day smoothed) per 1,000 people positive_rate National government reports Tests &amp; positivity The share of COVID-19 tests that are positive, given as a rolling 7-day average (this is the inverse of tests_per_case) tests_per_case National government reports Tests &amp; positivity Tests conducted per new confirmed case of COVID-19, given as a rolling 7-day average (this is the inverse of positive_rate) tests_units National government reports Tests &amp; positivity Units used by the location to report its testing data. A country file can't contain mixed units. All metrics concerning testing data use the specified test unit. Valid units are 'people tested' (number of people tested), 'tests performed' (number of tests performed. a single person can be tested more than once in a given day) and 'samples tested' (number of samples tested. In some cases, more than one sample may be required to perform a given test.) total_vaccinations National government reports Vaccinations Total number of COVID-19 vaccination doses administered people_vaccinated National government reports Vaccinations Total number of people who received at least one vaccine dose people_fully_vaccinated National government reports Vaccinations Total number of people who received all doses prescribed by the initial vaccination protocol total_boosters National government reports Vaccinations Total number of COVID-19 vaccination booster doses administered (doses administered beyond the number prescribed by the vaccination protocol) new_vaccinations National government reports Vaccinations New COVID-19 vaccination doses administered (only calculated for consecutive days) new_vaccinations_smoothed National government reports Vaccinations New COVID-19 vaccination doses administered (7-day smoothed). For countries that don't report vaccination data on a daily basis, we assume that vaccination changed equally on a daily basis over any periods in which no data was reported. This produces a complete series of daily figures, which is then averaged over a rolling 7-day window total_vaccinations_per_hundred National government reports Vaccinations Total number of COVID-19 vaccination doses administered per 100 people in the total population people_vaccinated_per_hundred National government reports Vaccinations Total number of people who received at least one vaccine dose per 100 people in the total population people_fully_vaccinated_per_hundred National government reports Vaccinations Total number of people who received all doses prescribed by the initial vaccination protocol per 100 people in the total population total_boosters_per_hundred National government reports Vaccinations Total number of COVID-19 vaccination booster doses administered per 100 people in the total population new_vaccinations_smoothed_per_million National government reports Vaccinations New COVID-19 vaccination doses administered (7-day smoothed) per 1,000,000 people in the total population new_people_vaccinated_smoothed National government reports Vaccinations Daily number of people receiving their first vaccine dose (7-day smoothed) new_people_vaccinated_smoothed_per_hundred National government reports Vaccinations Daily number of people receiving their first vaccine dose (7-day smoothed) per 100 people in the total population stringency_index Oxford COVID-19 Government Response Tracker, Blavatnik School of Government Policy responses Government Response Stringency Index: composite measure based on 9 response indicators including school closures, workplace closures, and travel bans, rescaled to a value from 0 to 100 (100 = strictest response) population United Nations, Department of Economic and Social Affairs, Population Division, World Population Prospects 2019 Revision Others Population (latest available values). See https://github.com/owid/covid-19-data/blob/master/scripts/input/un/population_latest.csv for full list of sources population_density World Bank World Development Indicators, sourced from Food and Agriculture Organization and World Bank estimates Others Number of people divided by land area, measured in square kilometers, most recent year available median_age UN Population Division, World Population Prospects, 2017 Revision Others Median age of the population, UN projection for 2020 aged_65_older World Bank World Development Indicators based on age/sex distributions of United Nations World Population Prospects 2017 Revision Others Share of the population that is 65 years and older, most recent year available aged_70_older United Nations, Department of Economic and Social Affairs, Population Division (2017), World Population Prospects 2017 Revision Others Share of the population that is 70 years and older in 2015 gdp_per_capita World Bank World Development Indicators, source from World Bank, International Comparison Program database Others Gross domestic product at purchasing power parity (constant 2011 international dollars), most recent year available extreme_poverty World Bank World Development Indicators, sourced from World Bank Development Research Group Others Share of the population living in extreme poverty, most recent year available since 2010 cardiovasc_death_rate Global Burden of Disease Collaborative Network, Global Burden of Disease Study 2017 Results Others Death rate from cardiovascular disease in 2017 (annual number of deaths per 100,000 people) diabetes_prevalence World Bank World Development Indicators, sourced from International Diabetes Federation, Diabetes Atlas Others Diabetes prevalence (% of population aged 20 to 79) in 2017 female_smokers World Bank World Development Indicators, sourced from World Health Organization, Global Health Observatory Data Repository Others Share of women who smoke, most recent year available male_smokers World Bank World Development Indicators, sourced from World Health Organization, Global Health Observatory Data Repository Others Share of men who smoke, most recent year available handwashing_facilities United Nations Statistics Division Others Share of the population with basic handwashing facilities on premises, most recent year available hospital_beds_per_thousand OECD, Eurostat, World Bank, national government records and other sources Others Hospital beds per 1,000 people, most recent year available since 2010 life_expectancy James C. Riley, Clio Infra, United Nations Population Division Others Life expectancy at birth in 2019 human_development_index United Nations Development Programme (UNDP) Others A composite index measuring average achievement in three basic dimensions of human development—a long and healthy life, knowledge and a decent standard of living. Values for 2019, imported from http://hdr.undp.org/en/indicators/137506 excess_mortality Human Mortality Database (2021), World Mortality Dataset (2021) Excess mortality Percentage difference between the reported number of weekly or monthly deaths in 2020–2021 and the projected number of deaths for the same period based on previous years. For more information, see https://github.com/owid/covid-19-data/tree/master/public/data/excess_mortality excess_mortality_cumulative Human Mortality Database (2021), World Mortality Dataset (2021) Excess mortality Percentage difference between the cumulative number of deaths since 1 January 2020 and the cumulative projected deaths for the same period based on previous years. For more information, see https://github.com/owid/covid-19-data/tree/master/public/data/excess_mortality excess_mortality_cumulative_absolute Human Mortality Database (2021), World Mortality Dataset (2021) Excess mortality Cumulative difference between the reported number of deaths since 1 January 2020 and the projected number of deaths for the same period based on previous years. For more information, see https://github.com/owid/covid-19-data/tree/master/public/data/excess_mortality excess_mortality_cumulative_per_million Human Mortality Database (2021), World Mortality Dataset (2021) Excess mortality Cumulative difference between the reported number of deaths since 1 January 2020 and the projected number of deaths for the same period based on previous years, per million people. For more information, see https://github.com/owid/covid-19-data/tree/master/public/data/excess_mortality O.1.3 Buscar los datos Code #mydat&lt;- read.csv(&#39;https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv&#39;) #mydat_compl &lt;- read.csv(&#39;https://covid.ourworldindata.org/data/owid-covid-data.csv&#39;) #mydat=mydat_compl library(readxl) mydat &lt;- read_excel(&quot;Data_files_csv/owid-covid-data.xlsx&quot;) Code head(mydat, 4) Table O.1: iso_codecontinentlocationdatetotal_casesnew_casesnew_cases_smoothedtotal_deathsnew_deathsnew_deaths_smoothedtotal_cases_per_millionnew_cases_per_millionnew_cases_smoothed_per_milliontotal_deaths_per_millionnew_deaths_per_millionnew_deaths_smoothed_per_millionreproduction_rateicu_patientsicu_patients_per_millionhosp_patientshosp_patients_per_millionweekly_icu_admissionsweekly_icu_admissions_per_millionweekly_hosp_admissionsweekly_hosp_admissions_per_milliontotal_testsnew_teststotal_tests_per_thousandnew_tests_per_thousandnew_tests_smoothednew_tests_smoothed_per_thousandpositive_ratetests_per_casetests_unitstotal_vaccinationspeople_vaccinatedpeople_fully_vaccinatedtotal_boostersnew_vaccinationsnew_vaccinations_smoothedtotal_vaccinations_per_hundredpeople_vaccinated_per_hundredpeople_fully_vaccinated_per_hundredtotal_boosters_per_hundrednew_vaccinations_smoothed_per_millionnew_people_vaccinated_smoothednew_people_vaccinated_smoothed_per_hundredstringency_indexpopulationpopulation_densitymedian_ageaged_65_olderaged_70_oldergdp_per_capitaextreme_povertycardiovasc_death_ratediabetes_prevalencefemale_smokersmale_smokershandwashing_facilitieshospital_beds_per_thousandlife_expectancyhuman_development_indexexcess_mortality_cumulative_absoluteexcess_mortality_cumulativeexcess_mortalityexcess_mortality_cumulative_per_million AFGAsiaAfghanistan2020-02-24550.1250.1258.334.01e+0754.418.62.581.341.8e+035979.5937.70.564.80.511 AFGAsiaAfghanistan2020-02-25500.1250&nbsp;&nbsp;&nbsp;&nbsp;8.334.01e+0754.418.62.581.341.8e+035979.5937.70.564.80.511 AFGAsiaAfghanistan2020-02-26500.1250&nbsp;&nbsp;&nbsp;&nbsp;8.334.01e+0754.418.62.581.341.8e+035979.5937.70.564.80.511 AFGAsiaAfghanistan2020-02-27500.1250&nbsp;&nbsp;&nbsp;&nbsp;8.334.01e+0754.418.62.581.341.8e+035979.5937.70.564.80.511 Seleccionar las variables y filtrar los datos para hacer un subgrupo con datos solamente de Puerto Rico Code df1=mydat %&gt;% dplyr::select(location,date, total_cases, new_cases, life_expectancy)%&gt;% filter(location == &quot;Puerto Rico&quot;) %&gt;% head() gt(df1) #mcxrpxmlmr table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #mcxrpxmlmr thead, #mcxrpxmlmr tbody, #mcxrpxmlmr tfoot, #mcxrpxmlmr tr, #mcxrpxmlmr td, #mcxrpxmlmr th { border-style: none; } #mcxrpxmlmr p { margin: 0; padding: 0; } #mcxrpxmlmr .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mcxrpxmlmr .gt_caption { padding-top: 4px; padding-bottom: 4px; } #mcxrpxmlmr .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mcxrpxmlmr .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mcxrpxmlmr .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mcxrpxmlmr .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mcxrpxmlmr .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mcxrpxmlmr .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mcxrpxmlmr .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mcxrpxmlmr .gt_column_spanner_outer:first-child { padding-left: 0; } #mcxrpxmlmr .gt_column_spanner_outer:last-child { padding-right: 0; } #mcxrpxmlmr .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mcxrpxmlmr .gt_spanner_row { border-bottom-style: hidden; } #mcxrpxmlmr .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #mcxrpxmlmr .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mcxrpxmlmr .gt_from_md > :first-child { margin-top: 0; } #mcxrpxmlmr .gt_from_md > :last-child { margin-bottom: 0; } #mcxrpxmlmr .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mcxrpxmlmr .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mcxrpxmlmr .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mcxrpxmlmr .gt_row_group_first td { border-top-width: 2px; } #mcxrpxmlmr .gt_row_group_first th { border-top-width: 2px; } #mcxrpxmlmr .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mcxrpxmlmr .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mcxrpxmlmr .gt_first_summary_row.thick { border-top-width: 2px; } #mcxrpxmlmr .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mcxrpxmlmr .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mcxrpxmlmr .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mcxrpxmlmr .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #mcxrpxmlmr .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mcxrpxmlmr .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mcxrpxmlmr .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mcxrpxmlmr .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mcxrpxmlmr .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mcxrpxmlmr .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mcxrpxmlmr .gt_left { text-align: left; } #mcxrpxmlmr .gt_center { text-align: center; } #mcxrpxmlmr .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mcxrpxmlmr .gt_font_normal { font-weight: normal; } #mcxrpxmlmr .gt_font_bold { font-weight: bold; } #mcxrpxmlmr .gt_font_italic { font-style: italic; } #mcxrpxmlmr .gt_super { font-size: 65%; } #mcxrpxmlmr .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #mcxrpxmlmr .gt_asterisk { font-size: 100%; vertical-align: 0; } #mcxrpxmlmr .gt_indent_1 { text-indent: 5px; } #mcxrpxmlmr .gt_indent_2 { text-indent: 10px; } #mcxrpxmlmr .gt_indent_3 { text-indent: 15px; } #mcxrpxmlmr .gt_indent_4 { text-indent: 20px; } #mcxrpxmlmr .gt_indent_5 { text-indent: 25px; } location date total_cases new_cases life_expectancy Puerto Rico 2020-03-01 NA NA 80.1 Puerto Rico 2020-03-02 NA NA 80.1 Puerto Rico 2020-03-03 NA NA 80.1 Puerto Rico 2020-03-04 NA NA 80.1 Puerto Rico 2020-03-05 NA NA 80.1 Puerto Rico 2020-03-06 NA NA 80.1 O.1.4 Ver el nombre de todos los paises incluido en el archivo Code unique(mydat$location) # la función &quot;unique&quot; es para saber los valores únicos un una columna ## [1] &quot;Afghanistan&quot; &quot;Africa&quot; ## [3] &quot;Albania&quot; &quot;Algeria&quot; ## [5] &quot;Andorra&quot; &quot;Angola&quot; ## [7] &quot;Anguilla&quot; &quot;Antigua and Barbuda&quot; ## [9] &quot;Argentina&quot; &quot;Armenia&quot; ## [11] &quot;Aruba&quot; &quot;Asia&quot; ## [13] &quot;Australia&quot; &quot;Austria&quot; ## [15] &quot;Azerbaijan&quot; &quot;Bahamas&quot; ## [17] &quot;Bahrain&quot; &quot;Bangladesh&quot; ## [19] &quot;Barbados&quot; &quot;Belarus&quot; ## [21] &quot;Belgium&quot; &quot;Belize&quot; ## [23] &quot;Benin&quot; &quot;Bermuda&quot; ## [25] &quot;Bhutan&quot; &quot;Bolivia&quot; ## [27] &quot;Bonaire Sint Eustatius and Saba&quot; &quot;Bosnia and Herzegovina&quot; ## [29] &quot;Botswana&quot; &quot;Brazil&quot; ## [31] &quot;British Virgin Islands&quot; &quot;Brunei&quot; ## [33] &quot;Bulgaria&quot; &quot;Burkina Faso&quot; ## [35] &quot;Burundi&quot; &quot;Cambodia&quot; ## [37] &quot;Cameroon&quot; &quot;Canada&quot; ## [39] &quot;Cape Verde&quot; &quot;Cayman Islands&quot; ## [41] &quot;Central African Republic&quot; &quot;Chad&quot; ## [43] &quot;Chile&quot; &quot;China&quot; ## [45] &quot;Colombia&quot; &quot;Comoros&quot; ## [47] &quot;Congo&quot; &quot;Cook Islands&quot; ## [49] &quot;Costa Rica&quot; &quot;Cote d&#39;Ivoire&quot; ## [51] &quot;Croatia&quot; &quot;Cuba&quot; ## [53] &quot;Curacao&quot; &quot;Cyprus&quot; ## [55] &quot;Czechia&quot; &quot;Democratic Republic of Congo&quot; ## [57] &quot;Denmark&quot; &quot;Djibouti&quot; ## [59] &quot;Dominica&quot; &quot;Dominican Republic&quot; ## [61] &quot;Ecuador&quot; &quot;Egypt&quot; ## [63] &quot;El Salvador&quot; &quot;Equatorial Guinea&quot; ## [65] &quot;Eritrea&quot; &quot;Estonia&quot; ## [67] &quot;Eswatini&quot; &quot;Ethiopia&quot; ## [69] &quot;Europe&quot; &quot;European Union&quot; ## [71] &quot;Faeroe Islands&quot; &quot;Falkland Islands&quot; ## [73] &quot;Fiji&quot; &quot;Finland&quot; ## [75] &quot;France&quot; &quot;French Polynesia&quot; ## [77] &quot;Gabon&quot; &quot;Gambia&quot; ## [79] &quot;Georgia&quot; &quot;Germany&quot; ## [81] &quot;Ghana&quot; &quot;Gibraltar&quot; ## [83] &quot;Greece&quot; &quot;Greenland&quot; ## [85] &quot;Grenada&quot; &quot;Guam&quot; ## [87] &quot;Guatemala&quot; &quot;Guernsey&quot; ## [89] &quot;Guinea&quot; &quot;Guinea-Bissau&quot; ## [91] &quot;Guyana&quot; &quot;Haiti&quot; ## [93] &quot;High income&quot; &quot;Honduras&quot; ## [95] &quot;Hong Kong&quot; &quot;Hungary&quot; ## [97] &quot;Iceland&quot; &quot;India&quot; ## [99] &quot;Indonesia&quot; &quot;International&quot; ## [101] &quot;Iran&quot; &quot;Iraq&quot; ## [103] &quot;Ireland&quot; &quot;Isle of Man&quot; ## [105] &quot;Israel&quot; &quot;Italy&quot; ## [107] &quot;Jamaica&quot; &quot;Japan&quot; ## [109] &quot;Jersey&quot; &quot;Jordan&quot; ## [111] &quot;Kazakhstan&quot; &quot;Kenya&quot; ## [113] &quot;Kiribati&quot; &quot;Kosovo&quot; ## [115] &quot;Kuwait&quot; &quot;Kyrgyzstan&quot; ## [117] &quot;Laos&quot; &quot;Latvia&quot; ## [119] &quot;Lebanon&quot; &quot;Lesotho&quot; ## [121] &quot;Liberia&quot; &quot;Libya&quot; ## [123] &quot;Liechtenstein&quot; &quot;Lithuania&quot; ## [125] &quot;Low income&quot; &quot;Lower middle income&quot; ## [127] &quot;Luxembourg&quot; &quot;Macao&quot; ## [129] &quot;Madagascar&quot; &quot;Malawi&quot; ## [131] &quot;Malaysia&quot; &quot;Maldives&quot; ## [133] &quot;Mali&quot; &quot;Malta&quot; ## [135] &quot;Marshall Islands&quot; &quot;Mauritania&quot; ## [137] &quot;Mauritius&quot; &quot;Mexico&quot; ## [139] &quot;Micronesia (country)&quot; &quot;Moldova&quot; ## [141] &quot;Monaco&quot; &quot;Mongolia&quot; ## [143] &quot;Montenegro&quot; &quot;Montserrat&quot; ## [145] &quot;Morocco&quot; &quot;Mozambique&quot; ## [147] &quot;Myanmar&quot; &quot;Namibia&quot; ## [149] &quot;Nauru&quot; &quot;Nepal&quot; ## [151] &quot;Netherlands&quot; &quot;New Caledonia&quot; ## [153] &quot;New Zealand&quot; &quot;Nicaragua&quot; ## [155] &quot;Niger&quot; &quot;Nigeria&quot; ## [157] &quot;Niue&quot; &quot;North America&quot; ## [159] &quot;North Korea&quot; &quot;North Macedonia&quot; ## [161] &quot;Northern Cyprus&quot; &quot;Northern Mariana Islands&quot; ## [163] &quot;Norway&quot; &quot;Oceania&quot; ## [165] &quot;Oman&quot; &quot;Pakistan&quot; ## [167] &quot;Palau&quot; &quot;Palestine&quot; ## [169] &quot;Panama&quot; &quot;Papua New Guinea&quot; ## [171] &quot;Paraguay&quot; &quot;Peru&quot; ## [173] &quot;Philippines&quot; &quot;Pitcairn&quot; ## [175] &quot;Poland&quot; &quot;Portugal&quot; ## [177] &quot;Puerto Rico&quot; &quot;Qatar&quot; ## [179] &quot;Romania&quot; &quot;Russia&quot; ## [181] &quot;Rwanda&quot; &quot;Saint Helena&quot; ## [183] &quot;Saint Kitts and Nevis&quot; &quot;Saint Lucia&quot; ## [185] &quot;Saint Pierre and Miquelon&quot; &quot;Saint Vincent and the Grenadines&quot; ## [187] &quot;Samoa&quot; &quot;San Marino&quot; ## [189] &quot;Sao Tome and Principe&quot; &quot;Saudi Arabia&quot; ## [191] &quot;Senegal&quot; &quot;Serbia&quot; ## [193] &quot;Seychelles&quot; &quot;Sierra Leone&quot; ## [195] &quot;Singapore&quot; &quot;Sint Maarten (Dutch part)&quot; ## [197] &quot;Slovakia&quot; &quot;Slovenia&quot; ## [199] &quot;Solomon Islands&quot; &quot;Somalia&quot; ## [201] &quot;South Africa&quot; &quot;South America&quot; ## [203] &quot;South Korea&quot; &quot;South Sudan&quot; ## [205] &quot;Spain&quot; &quot;Sri Lanka&quot; ## [207] &quot;Sudan&quot; &quot;Suriname&quot; ## [209] &quot;Sweden&quot; &quot;Switzerland&quot; ## [211] &quot;Syria&quot; &quot;Taiwan&quot; ## [213] &quot;Tajikistan&quot; &quot;Tanzania&quot; ## [215] &quot;Thailand&quot; &quot;Timor&quot; ## [217] &quot;Togo&quot; &quot;Tokelau&quot; ## [219] &quot;Tonga&quot; &quot;Trinidad and Tobago&quot; ## [221] &quot;Tunisia&quot; &quot;Turkey&quot; ## [223] &quot;Turkmenistan&quot; &quot;Turks and Caicos Islands&quot; ## [225] &quot;Tuvalu&quot; &quot;Uganda&quot; ## [227] &quot;Ukraine&quot; &quot;United Arab Emirates&quot; ## [229] &quot;United Kingdom&quot; &quot;United States&quot; ## [231] &quot;United States Virgin Islands&quot; &quot;Upper middle income&quot; ## [233] &quot;Uruguay&quot; &quot;Uzbekistan&quot; ## [235] &quot;Vanuatu&quot; &quot;Vatican&quot; ## [237] &quot;Venezuela&quot; &quot;Vietnam&quot; ## [239] &quot;Wallis and Futuna&quot; &quot;Western Sahara&quot; ## [241] &quot;World&quot; &quot;Yemen&quot; ## [243] &quot;Zambia&quot; &quot;Zimbabwe&quot; O.1.5 Importante Favor tener un documento bien organizado y fácil de leer, añadir solamente la información necesaria. O.1.6 Ejercicio 1 (5 puntos) Calcula los siguientes parámetros de números de nuevos casos de COVID-19 por día en Puerto Rico - el promedio - la mediana - la moda - la desviación estándar - el error estándar - los cuartiles O.1.7 Ejercicio 2 (5 puntos) Selecciona otro país del Caribe y calcula los mismo parámetros Code mydat%&gt;% dplyr::select(location,date, total_cases, new_cases, life_expectancy)%&gt;% filter(location %in% c(&quot;Puerto Rico&quot;, &quot;Cuba&quot;))%&gt;% head(3)%&gt;% gt() #qxpjbzozcb table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #qxpjbzozcb thead, #qxpjbzozcb tbody, #qxpjbzozcb tfoot, #qxpjbzozcb tr, #qxpjbzozcb td, #qxpjbzozcb th { border-style: none; } #qxpjbzozcb p { margin: 0; padding: 0; } #qxpjbzozcb .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qxpjbzozcb .gt_caption { padding-top: 4px; padding-bottom: 4px; } #qxpjbzozcb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qxpjbzozcb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #qxpjbzozcb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qxpjbzozcb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qxpjbzozcb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qxpjbzozcb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qxpjbzozcb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qxpjbzozcb .gt_column_spanner_outer:first-child { padding-left: 0; } #qxpjbzozcb .gt_column_spanner_outer:last-child { padding-right: 0; } #qxpjbzozcb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qxpjbzozcb .gt_spanner_row { border-bottom-style: hidden; } #qxpjbzozcb .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #qxpjbzozcb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qxpjbzozcb .gt_from_md > :first-child { margin-top: 0; } #qxpjbzozcb .gt_from_md > :last-child { margin-bottom: 0; } #qxpjbzozcb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qxpjbzozcb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #qxpjbzozcb .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #qxpjbzozcb .gt_row_group_first td { border-top-width: 2px; } #qxpjbzozcb .gt_row_group_first th { border-top-width: 2px; } #qxpjbzozcb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qxpjbzozcb .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #qxpjbzozcb .gt_first_summary_row.thick { border-top-width: 2px; } #qxpjbzozcb .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qxpjbzozcb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qxpjbzozcb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qxpjbzozcb .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #qxpjbzozcb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qxpjbzozcb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qxpjbzozcb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qxpjbzozcb .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qxpjbzozcb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qxpjbzozcb .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qxpjbzozcb .gt_left { text-align: left; } #qxpjbzozcb .gt_center { text-align: center; } #qxpjbzozcb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qxpjbzozcb .gt_font_normal { font-weight: normal; } #qxpjbzozcb .gt_font_bold { font-weight: bold; } #qxpjbzozcb .gt_font_italic { font-style: italic; } #qxpjbzozcb .gt_super { font-size: 65%; } #qxpjbzozcb .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #qxpjbzozcb .gt_asterisk { font-size: 100%; vertical-align: 0; } #qxpjbzozcb .gt_indent_1 { text-indent: 5px; } #qxpjbzozcb .gt_indent_2 { text-indent: 10px; } #qxpjbzozcb .gt_indent_3 { text-indent: 15px; } #qxpjbzozcb .gt_indent_4 { text-indent: 20px; } #qxpjbzozcb .gt_indent_5 { text-indent: 25px; } location date total_cases new_cases life_expectancy Cuba 2020-03-12 3 3 78.8 Cuba 2020-03-13 4 1 78.8 Cuba 2020-03-14 4 0 78.8 Code library(statip) mydat %&gt;% dplyr::select(location,date, total_cases, new_cases, life_expectancy)%&gt;% filter(location %in% c(&quot;Puerto Rico&quot;, &quot;Cuba&quot;, &quot;Jamaica&quot;, &quot;Costa Rica&quot;, &quot;Haiti&quot;, &quot;Bahamas&quot;))%&gt;% group_by(location) %&gt;% summarize(mean=mean(new_cases, na.rm=T), median=median(new_cases, na.rm=T), de=sd(new_cases, na.rm=T)) %&gt;% gt() #sgcaoifuiq table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #sgcaoifuiq thead, #sgcaoifuiq tbody, #sgcaoifuiq tfoot, #sgcaoifuiq tr, #sgcaoifuiq td, #sgcaoifuiq th { border-style: none; } #sgcaoifuiq p { margin: 0; padding: 0; } #sgcaoifuiq .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #sgcaoifuiq .gt_caption { padding-top: 4px; padding-bottom: 4px; } #sgcaoifuiq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #sgcaoifuiq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #sgcaoifuiq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #sgcaoifuiq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #sgcaoifuiq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #sgcaoifuiq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #sgcaoifuiq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #sgcaoifuiq .gt_column_spanner_outer:first-child { padding-left: 0; } #sgcaoifuiq .gt_column_spanner_outer:last-child { padding-right: 0; } #sgcaoifuiq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #sgcaoifuiq .gt_spanner_row { border-bottom-style: hidden; } #sgcaoifuiq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #sgcaoifuiq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #sgcaoifuiq .gt_from_md > :first-child { margin-top: 0; } #sgcaoifuiq .gt_from_md > :last-child { margin-bottom: 0; } #sgcaoifuiq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #sgcaoifuiq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #sgcaoifuiq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #sgcaoifuiq .gt_row_group_first td { border-top-width: 2px; } #sgcaoifuiq .gt_row_group_first th { border-top-width: 2px; } #sgcaoifuiq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #sgcaoifuiq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #sgcaoifuiq .gt_first_summary_row.thick { border-top-width: 2px; } #sgcaoifuiq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #sgcaoifuiq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #sgcaoifuiq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #sgcaoifuiq .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #sgcaoifuiq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #sgcaoifuiq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #sgcaoifuiq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #sgcaoifuiq .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #sgcaoifuiq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #sgcaoifuiq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #sgcaoifuiq .gt_left { text-align: left; } #sgcaoifuiq .gt_center { text-align: center; } #sgcaoifuiq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #sgcaoifuiq .gt_font_normal { font-weight: normal; } #sgcaoifuiq .gt_font_bold { font-weight: bold; } #sgcaoifuiq .gt_font_italic { font-style: italic; } #sgcaoifuiq .gt_super { font-size: 65%; } #sgcaoifuiq .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #sgcaoifuiq .gt_asterisk { font-size: 100%; vertical-align: 0; } #sgcaoifuiq .gt_indent_1 { text-indent: 5px; } #sgcaoifuiq .gt_indent_2 { text-indent: 10px; } #sgcaoifuiq .gt_indent_3 { text-indent: 15px; } #sgcaoifuiq .gt_indent_4 { text-indent: 20px; } #sgcaoifuiq .gt_indent_5 { text-indent: 25px; } mean median de 540.3386 43 1805.497 Code mydat%&gt;% dplyr::select(location,date, total_cases, new_cases, life_expectancy)%&gt;% filter(location %in% c(&quot;Puerto Rico&quot;, &quot;Cuba&quot;, &quot;Jamaica&quot;, &quot;Costa Rica&quot;, &quot;Haiti&quot;, &quot;Bahamas&quot;))%&gt;% group_by(location)%&gt;% summarize(mode=statip::mfv(new_cases)) Table O.2: mode 0 Pregunta 1 (5 puntos) promedio mediana moda desviación estándar error estándar cuantiles Pregunta 2 (5 puntos) promedio mediana moda desviación estándar error estándar cuantiles O.1.8 Discusión (5 puntos) Comparando los valores de los dos países considerando la biología de COVID-19 y la diferencias entre estos dos países. Discute porque cree que hay similitud o diferencia en los parámetros. (4 puntos) Discutir y comparar los datos. En el pais #1 se observó un promedio diario de xx casos nuevos por dia y el pais #2 se observo tal cantidad. La mediana en los dos paises eran similar/ diferentes ….., de los valores. Tanto la desviación estándar y los cuantiles eran más grande en el pais 1 versus el pais 2. Uno ejemplos de temas que se podría haber tomado encuenta tamaño poblacional la fecha de cuando comenzó la pandemía en los países la conexión social la reacción del gobierno a imponer o no componentes sociales a reducir el proceso de contagiosos la densidad poblacional la educación de la población el respeto de la población a las reglas impuesto del gobierno la importancia del turismo exterior y interior (movimiento espacial de la gente). Qué otros parámetros pudiese ser considerando en los análisis que no fue tomado en cuenta para entender la biología de propagación este virus. (1 puntos) Aquí se debería haber discutido componentes sociales que podría explicar como se propaga el virus. "],["ejercicios-p.html", "P Ejercicios P P.1 Ejercicios de Pruebas de Frecuencia", " P Ejercicios P P.1 Ejercicios de Pruebas de Frecuencia P.1.1 Capitulo 7 Los ejercicio provienen del Capitulo 7 del libro de la clase Havel et al 2019. Introductory Biological Ststistics, 4th Edition, Waveland Press, Inc. Long Grove, Illinois. P.1.2 Ejericico de Práctica (no para someter) Los ejercicio de 7.1 al 7.13. son para practicar. Se encuentra las respuestas al final del libro. P.1.3 Ejercicio para someter. Ud. someterán los las repuestas a los siguientes ejercicios en un documento .html. Para cada ejercicio siempre tiene que aclarar cual son las hipótesis nula y alterna. Tiene que explicar el concepto biológico si la pregunta menciona uno. Enseñar los cálculos/script para hacer los análisis. Interpretar los resultados basado en la pregunta que se hace en el ejercicio. Ejercicio 7.17 (5 puntos) Ejercicio 7.18 (5 puntos) Ejercicio 7.21 (5 puntos) Ejercicio 7.27 (5 puntos) 5 puntos para un trabajo bien presentado y organizado "],["quiz-1.html", "Q Quiz 1", " Q Quiz 1 Q.0.1 Quiz 1 de tendencia central y de dispersión Q.0.2 Usando los datos siguientes calcula los siguientes estadísticos Q.0.2.1 Evalua cada uno y despues abrá MSTeam para contestar las preguntas promedio mediana moda varianza los cuantiles (2.5, 25, 50, 75, 97.5) desviación estandar error estandard el intervalo de confianza de 95% del promedio Haz un histograma de los datos incluir un color de su preferencia cambiar los nombres de los ejes Los Datos: Los datos muestran el número de “homerun” al bate de la liga Americana de baseball en los ultimos 30 años. Cada número es la cantidad máxima de Homerun en uno de los años. Code HOMERUN =tribble( ~&quot;Numeros_Homerum&quot;, 40, 43, 40, 53, 47, 46, 44, 57, 43, 43, 52, 44, 54, 47, 51, 39, 48, 36, 37, 56, 42, 54, 56, 49, 54, 52, 40, 48, 50, 40 ) HOMERUN Table Q.1: Numeros_Homerum 40 43 40 53 47 46 44 57 43 43 52 44 54 47 51 39 48 36 37 56 42 54 56 49 54 52 40 48 50 40 "]]
